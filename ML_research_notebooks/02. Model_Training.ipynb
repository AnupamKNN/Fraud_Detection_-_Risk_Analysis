{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e719d53",
   "metadata": {},
   "source": [
    "## Model Training for Fraud Detection & Risk Analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163c85c6",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9871bd",
   "metadata": {},
   "source": [
    "Let us import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47a358bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d57c5434",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Cleaned_Data/creditcard_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fc97bf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "      <th>TransactionDate</th>\n",
       "      <th>Hour</th>\n",
       "      <th>ElapsedDays</th>\n",
       "      <th>Hour_sin</th>\n",
       "      <th>Hour_cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-01 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-01 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-01 00:00:01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-01 00:00:01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-01 00:00:02</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V26       V27       V28  Amount  Class  \\\n",
       "0  0.098698  0.363787  ... -0.189115  0.133558 -0.021053  149.62      0   \n",
       "1  0.085102 -0.255425  ...  0.125895 -0.008983  0.014724    2.69      0   \n",
       "2  0.247676 -1.514654  ... -0.139097 -0.055353 -0.059752  378.66      0   \n",
       "3  0.377436 -1.387024  ... -0.221929  0.062723  0.061458  123.50      0   \n",
       "4 -0.270533  0.817739  ...  0.502292  0.219422  0.215153   69.99      0   \n",
       "\n",
       "       TransactionDate  Hour  ElapsedDays  Hour_sin  Hour_cos  \n",
       "0  2020-01-01 00:00:00     0            0       0.0       1.0  \n",
       "1  2020-01-01 00:00:00     0            0       0.0       1.0  \n",
       "2  2020-01-01 00:00:01     0            0       0.0       1.0  \n",
       "3  2020-01-01 00:00:01     0            0       0.0       1.0  \n",
       "4  2020-01-01 00:00:02     0            0       0.0       1.0  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02f317a",
   "metadata": {},
   "source": [
    "### Scale the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6dcd339e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df[['Amount', 'ElapsedDays', 'Time']] = scaler.fit_transform(df[['Amount', 'ElapsedDays', 'Time']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58c2bcd",
   "metadata": {},
   "source": [
    "### Split the data into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97aeb1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop(columns=['Class', 'TransactionDate'])  # exclude target and datetime\n",
    "y = df['Class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6f202e",
   "metadata": {},
   "source": [
    "### Handling class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6122769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before SMOTE: Class\n",
      "0    227451\n",
      "1       394\n",
      "Name: count, dtype: int64\n",
      "After SMOTE: Class\n",
      "0    227451\n",
      "1    227451\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "sm = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"Before SMOTE:\", y_train.value_counts())\n",
    "print(\"After SMOTE:\", y_train_resampled.value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca16378c",
   "metadata": {},
   "source": [
    "## Now, we can proceed towards model training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24270f20",
   "metadata": {},
   "source": [
    "### Base Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e3d226a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.combine import SMOTETomek\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4808980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('Cleaned_Data/creditcard_cleaned.csv')\n",
    "\n",
    "# Define feature columns\n",
    "numeric_features = ['Time', 'ElapsedDays', 'Amount']\n",
    "pcs_features = [f'V{i}' for i in range(1, 29)]\n",
    "cyclic_features = ['Hour_sin', 'Hour_cos']\n",
    "\n",
    "feature_cols = numeric_features + pcs_features + cyclic_features\n",
    "\n",
    "X = df[feature_cols]\n",
    "y = df['Class']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24a7c5f",
   "metadata": {},
   "source": [
    "### Let us split the data into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a6804cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Test Split with Stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44baed0f",
   "metadata": {},
   "source": [
    "### Next step, preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e094ee8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing pipeline for numeric features\n",
    "numeric_transformer = StandardScaler()\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers= [\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('pass_pca', 'passthrough', pcs_features),\n",
    "        ('pass_cyclic', 'passthrough', cyclic_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Preprocess the data\n",
    "X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
    "X_test_preprocessed = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6599029b",
   "metadata": {},
   "source": [
    "### Handline class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e30c4636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before SMOTE: Class\n",
      "0    227451\n",
      "1       394\n",
      "Name: count, dtype: int64\n",
      "After SMOTE: Class\n",
      "0    227451\n",
      "1    227451\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "## Use SMOTETomek to balance the classes\n",
    "\n",
    "sm = SMOTETomek(random_state=42)\n",
    "X_train_resampled, y_train_resampled = sm.fit_resample(X_train_preprocessed, y_train)\n",
    "\n",
    "print(\"Before SMOTE:\", y_train.value_counts())\n",
    "print(\"After SMOTE:\", y_train_resampled.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f073d860",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(true, predicted, proba=None):\n",
    "    acc = accuracy_score(true, predicted)\n",
    "    f1 = f1_score(true, predicted)\n",
    "    roc = roc_auc_score(true, proba if proba is not None else predicted)\n",
    "    fpr, tpr, thresholds = roc_curve(true, proba if proba is not None else predicted)\n",
    "    return acc, f1, roc, fpr, tpr, thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ac48333",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "# Define classification models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"KNeighborsClassifier\": KNeighborsClassifier(),\n",
    "    \"RandomForestClassifier\": RandomForestClassifier(),\n",
    "    \"AdaBoost\": AdaBoostClassifier(),\n",
    "    \"GradientBoostingClassifier\": GradientBoostingClassifier(),\n",
    "    \"XGBClassifier\": XGBClassifier(tree_method='gpu_hist', device = 'cuda'),\n",
    "    \"DecisionTreeClassifier\": DecisionTreeClassifier(),\n",
    "    \"CatBoostClassifier\": CatBoostClassifier(task_type=\"GPU\", devices='0')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26f83a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression...\n",
      "Training KNeighborsClassifier...\n",
      "Training RandomForestClassifier...\n",
      "Training AdaBoost...\n",
      "Training GradientBoostingClassifier...\n",
      "Training XGBClassifier...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [12:19:33] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/core.py:2676: UserWarning: [12:19:34] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/core.py:729: UserWarning: [12:19:34] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  return func(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training DecisionTreeClassifier...\n",
      "Training CatBoostClassifier...\n",
      "Learning rate set to 0.024076\n",
      "0:\tlearn: 0.6411828\ttotal: 93.5ms\tremaining: 1m 33s\n",
      "1:\tlearn: 0.5940659\ttotal: 104ms\tremaining: 51.8s\n",
      "2:\tlearn: 0.5540995\ttotal: 114ms\tremaining: 37.9s\n",
      "3:\tlearn: 0.5173892\ttotal: 123ms\tremaining: 30.7s\n",
      "4:\tlearn: 0.4795679\ttotal: 133ms\tremaining: 26.5s\n",
      "5:\tlearn: 0.4497770\ttotal: 144ms\tremaining: 23.9s\n",
      "6:\tlearn: 0.4189222\ttotal: 154ms\tremaining: 21.8s\n",
      "7:\tlearn: 0.3939220\ttotal: 163ms\tremaining: 20.2s\n",
      "8:\tlearn: 0.3736126\ttotal: 172ms\tremaining: 19s\n",
      "9:\tlearn: 0.3511105\ttotal: 182ms\tremaining: 18s\n",
      "10:\tlearn: 0.3335631\ttotal: 190ms\tremaining: 17.1s\n",
      "11:\tlearn: 0.3100146\ttotal: 200ms\tremaining: 16.5s\n",
      "12:\tlearn: 0.2935624\ttotal: 211ms\tremaining: 16s\n",
      "13:\tlearn: 0.2813377\ttotal: 219ms\tremaining: 15.4s\n",
      "14:\tlearn: 0.2668378\ttotal: 229ms\tremaining: 15.1s\n",
      "15:\tlearn: 0.2549400\ttotal: 238ms\tremaining: 14.6s\n",
      "16:\tlearn: 0.2446517\ttotal: 247ms\tremaining: 14.3s\n",
      "17:\tlearn: 0.2353389\ttotal: 256ms\tremaining: 13.9s\n",
      "18:\tlearn: 0.2256643\ttotal: 265ms\tremaining: 13.7s\n",
      "19:\tlearn: 0.2186915\ttotal: 280ms\tremaining: 13.7s\n",
      "20:\tlearn: 0.2117400\ttotal: 292ms\tremaining: 13.6s\n",
      "21:\tlearn: 0.2058145\ttotal: 300ms\tremaining: 13.3s\n",
      "22:\tlearn: 0.1995475\ttotal: 310ms\tremaining: 13.2s\n",
      "23:\tlearn: 0.1932416\ttotal: 320ms\tremaining: 13s\n",
      "24:\tlearn: 0.1875024\ttotal: 332ms\tremaining: 13s\n",
      "25:\tlearn: 0.1822721\ttotal: 342ms\tremaining: 12.8s\n",
      "26:\tlearn: 0.1777449\ttotal: 352ms\tremaining: 12.7s\n",
      "27:\tlearn: 0.1738666\ttotal: 362ms\tremaining: 12.6s\n",
      "28:\tlearn: 0.1701248\ttotal: 370ms\tremaining: 12.4s\n",
      "29:\tlearn: 0.1634389\ttotal: 381ms\tremaining: 12.3s\n",
      "30:\tlearn: 0.1605176\ttotal: 389ms\tremaining: 12.1s\n",
      "31:\tlearn: 0.1576692\ttotal: 397ms\tremaining: 12s\n",
      "32:\tlearn: 0.1541058\ttotal: 405ms\tremaining: 11.9s\n",
      "33:\tlearn: 0.1517854\ttotal: 414ms\tremaining: 11.8s\n",
      "34:\tlearn: 0.1494241\ttotal: 422ms\tremaining: 11.6s\n",
      "35:\tlearn: 0.1464758\ttotal: 431ms\tremaining: 11.6s\n",
      "36:\tlearn: 0.1433954\ttotal: 440ms\tremaining: 11.5s\n",
      "37:\tlearn: 0.1412805\ttotal: 448ms\tremaining: 11.3s\n",
      "38:\tlearn: 0.1382446\ttotal: 456ms\tremaining: 11.2s\n",
      "39:\tlearn: 0.1358592\ttotal: 464ms\tremaining: 11.1s\n",
      "40:\tlearn: 0.1334453\ttotal: 473ms\tremaining: 11.1s\n",
      "41:\tlearn: 0.1311835\ttotal: 481ms\tremaining: 11s\n",
      "42:\tlearn: 0.1284455\ttotal: 489ms\tremaining: 10.9s\n",
      "43:\tlearn: 0.1263801\ttotal: 498ms\tremaining: 10.8s\n",
      "44:\tlearn: 0.1239904\ttotal: 506ms\tremaining: 10.7s\n",
      "45:\tlearn: 0.1224811\ttotal: 515ms\tremaining: 10.7s\n",
      "46:\tlearn: 0.1211067\ttotal: 523ms\tremaining: 10.6s\n",
      "47:\tlearn: 0.1194690\ttotal: 532ms\tremaining: 10.6s\n",
      "48:\tlearn: 0.1173543\ttotal: 540ms\tremaining: 10.5s\n",
      "49:\tlearn: 0.1161603\ttotal: 549ms\tremaining: 10.4s\n",
      "50:\tlearn: 0.1147300\ttotal: 557ms\tremaining: 10.4s\n",
      "51:\tlearn: 0.1124147\ttotal: 566ms\tremaining: 10.3s\n",
      "52:\tlearn: 0.1112090\ttotal: 575ms\tremaining: 10.3s\n",
      "53:\tlearn: 0.1096002\ttotal: 583ms\tremaining: 10.2s\n",
      "54:\tlearn: 0.1084981\ttotal: 591ms\tremaining: 10.2s\n",
      "55:\tlearn: 0.1072057\ttotal: 599ms\tremaining: 10.1s\n",
      "56:\tlearn: 0.1053486\ttotal: 608ms\tremaining: 10.1s\n",
      "57:\tlearn: 0.1036372\ttotal: 616ms\tremaining: 10s\n",
      "58:\tlearn: 0.1022414\ttotal: 625ms\tremaining: 9.97s\n",
      "59:\tlearn: 0.1009162\ttotal: 634ms\tremaining: 9.93s\n",
      "60:\tlearn: 0.0993644\ttotal: 643ms\tremaining: 9.89s\n",
      "61:\tlearn: 0.0978703\ttotal: 651ms\tremaining: 9.85s\n",
      "62:\tlearn: 0.0967083\ttotal: 659ms\tremaining: 9.8s\n",
      "63:\tlearn: 0.0957411\ttotal: 668ms\tremaining: 9.78s\n",
      "64:\tlearn: 0.0945678\ttotal: 677ms\tremaining: 9.73s\n",
      "65:\tlearn: 0.0932928\ttotal: 685ms\tremaining: 9.69s\n",
      "66:\tlearn: 0.0920726\ttotal: 693ms\tremaining: 9.65s\n",
      "67:\tlearn: 0.0909447\ttotal: 702ms\tremaining: 9.62s\n",
      "68:\tlearn: 0.0901914\ttotal: 710ms\tremaining: 9.58s\n",
      "69:\tlearn: 0.0887886\ttotal: 718ms\tremaining: 9.54s\n",
      "70:\tlearn: 0.0878922\ttotal: 727ms\tremaining: 9.52s\n",
      "71:\tlearn: 0.0864601\ttotal: 736ms\tremaining: 9.49s\n",
      "72:\tlearn: 0.0851001\ttotal: 745ms\tremaining: 9.46s\n",
      "73:\tlearn: 0.0841673\ttotal: 753ms\tremaining: 9.42s\n",
      "74:\tlearn: 0.0813895\ttotal: 761ms\tremaining: 9.39s\n",
      "75:\tlearn: 0.0785917\ttotal: 769ms\tremaining: 9.35s\n",
      "76:\tlearn: 0.0778896\ttotal: 777ms\tremaining: 9.32s\n",
      "77:\tlearn: 0.0766414\ttotal: 785ms\tremaining: 9.28s\n",
      "78:\tlearn: 0.0755582\ttotal: 793ms\tremaining: 9.25s\n",
      "79:\tlearn: 0.0747795\ttotal: 802ms\tremaining: 9.22s\n",
      "80:\tlearn: 0.0738943\ttotal: 810ms\tremaining: 9.19s\n",
      "81:\tlearn: 0.0717366\ttotal: 819ms\tremaining: 9.17s\n",
      "82:\tlearn: 0.0712093\ttotal: 827ms\tremaining: 9.14s\n",
      "83:\tlearn: 0.0702909\ttotal: 836ms\tremaining: 9.12s\n",
      "84:\tlearn: 0.0698210\ttotal: 844ms\tremaining: 9.09s\n",
      "85:\tlearn: 0.0691966\ttotal: 858ms\tremaining: 9.12s\n",
      "86:\tlearn: 0.0683877\ttotal: 875ms\tremaining: 9.18s\n",
      "87:\tlearn: 0.0672637\ttotal: 892ms\tremaining: 9.24s\n",
      "88:\tlearn: 0.0666571\ttotal: 909ms\tremaining: 9.3s\n",
      "89:\tlearn: 0.0656419\ttotal: 922ms\tremaining: 9.33s\n",
      "90:\tlearn: 0.0646310\ttotal: 931ms\tremaining: 9.3s\n",
      "91:\tlearn: 0.0637430\ttotal: 941ms\tremaining: 9.29s\n",
      "92:\tlearn: 0.0632315\ttotal: 950ms\tremaining: 9.27s\n",
      "93:\tlearn: 0.0624213\ttotal: 958ms\tremaining: 9.24s\n",
      "94:\tlearn: 0.0617805\ttotal: 967ms\tremaining: 9.21s\n",
      "95:\tlearn: 0.0609694\ttotal: 975ms\tremaining: 9.18s\n",
      "96:\tlearn: 0.0604962\ttotal: 983ms\tremaining: 9.15s\n",
      "97:\tlearn: 0.0600210\ttotal: 991ms\tremaining: 9.12s\n",
      "98:\tlearn: 0.0583881\ttotal: 999ms\tremaining: 9.09s\n",
      "99:\tlearn: 0.0577617\ttotal: 1.01s\tremaining: 9.06s\n",
      "100:\tlearn: 0.0573572\ttotal: 1.02s\tremaining: 9.05s\n",
      "101:\tlearn: 0.0569177\ttotal: 1.02s\tremaining: 9.02s\n",
      "102:\tlearn: 0.0560462\ttotal: 1.03s\tremaining: 9s\n",
      "103:\tlearn: 0.0552670\ttotal: 1.04s\tremaining: 8.97s\n",
      "104:\tlearn: 0.0546665\ttotal: 1.05s\tremaining: 8.95s\n",
      "105:\tlearn: 0.0542718\ttotal: 1.06s\tremaining: 8.92s\n",
      "106:\tlearn: 0.0538347\ttotal: 1.07s\tremaining: 8.9s\n",
      "107:\tlearn: 0.0533484\ttotal: 1.07s\tremaining: 8.88s\n",
      "108:\tlearn: 0.0529134\ttotal: 1.09s\tremaining: 8.88s\n",
      "109:\tlearn: 0.0522682\ttotal: 1.1s\tremaining: 8.87s\n",
      "110:\tlearn: 0.0517259\ttotal: 1.1s\tremaining: 8.85s\n",
      "111:\tlearn: 0.0513965\ttotal: 1.11s\tremaining: 8.82s\n",
      "112:\tlearn: 0.0510030\ttotal: 1.12s\tremaining: 8.81s\n",
      "113:\tlearn: 0.0504741\ttotal: 1.13s\tremaining: 8.81s\n",
      "114:\tlearn: 0.0500967\ttotal: 1.15s\tremaining: 8.86s\n",
      "115:\tlearn: 0.0496596\ttotal: 1.16s\tremaining: 8.84s\n",
      "116:\tlearn: 0.0489766\ttotal: 1.17s\tremaining: 8.81s\n",
      "117:\tlearn: 0.0483085\ttotal: 1.18s\tremaining: 8.79s\n",
      "118:\tlearn: 0.0477261\ttotal: 1.19s\tremaining: 8.77s\n",
      "119:\tlearn: 0.0474855\ttotal: 1.19s\tremaining: 8.76s\n",
      "120:\tlearn: 0.0471270\ttotal: 1.2s\tremaining: 8.74s\n",
      "121:\tlearn: 0.0468381\ttotal: 1.21s\tremaining: 8.72s\n",
      "122:\tlearn: 0.0465711\ttotal: 1.22s\tremaining: 8.71s\n",
      "123:\tlearn: 0.0462702\ttotal: 1.23s\tremaining: 8.69s\n",
      "124:\tlearn: 0.0457026\ttotal: 1.24s\tremaining: 8.67s\n",
      "125:\tlearn: 0.0452702\ttotal: 1.25s\tremaining: 8.65s\n",
      "126:\tlearn: 0.0446093\ttotal: 1.25s\tremaining: 8.63s\n",
      "127:\tlearn: 0.0443749\ttotal: 1.26s\tremaining: 8.62s\n",
      "128:\tlearn: 0.0440743\ttotal: 1.27s\tremaining: 8.6s\n",
      "129:\tlearn: 0.0438658\ttotal: 1.28s\tremaining: 8.58s\n",
      "130:\tlearn: 0.0433136\ttotal: 1.29s\tremaining: 8.56s\n",
      "131:\tlearn: 0.0428074\ttotal: 1.3s\tremaining: 8.54s\n",
      "132:\tlearn: 0.0423966\ttotal: 1.31s\tremaining: 8.53s\n",
      "133:\tlearn: 0.0417803\ttotal: 1.32s\tremaining: 8.52s\n",
      "134:\tlearn: 0.0413904\ttotal: 1.33s\tremaining: 8.5s\n",
      "135:\tlearn: 0.0411565\ttotal: 1.33s\tremaining: 8.48s\n",
      "136:\tlearn: 0.0407564\ttotal: 1.34s\tremaining: 8.47s\n",
      "137:\tlearn: 0.0404279\ttotal: 1.35s\tremaining: 8.45s\n",
      "138:\tlearn: 0.0400766\ttotal: 1.36s\tremaining: 8.44s\n",
      "139:\tlearn: 0.0398431\ttotal: 1.37s\tremaining: 8.42s\n",
      "140:\tlearn: 0.0395936\ttotal: 1.38s\tremaining: 8.4s\n",
      "141:\tlearn: 0.0394171\ttotal: 1.39s\tremaining: 8.38s\n",
      "142:\tlearn: 0.0384193\ttotal: 1.4s\tremaining: 8.36s\n",
      "143:\tlearn: 0.0382152\ttotal: 1.41s\tremaining: 8.36s\n",
      "144:\tlearn: 0.0379650\ttotal: 1.42s\tremaining: 8.35s\n",
      "145:\tlearn: 0.0375483\ttotal: 1.42s\tremaining: 8.33s\n",
      "146:\tlearn: 0.0373128\ttotal: 1.43s\tremaining: 8.31s\n",
      "147:\tlearn: 0.0368478\ttotal: 1.44s\tremaining: 8.29s\n",
      "148:\tlearn: 0.0366241\ttotal: 1.45s\tremaining: 8.28s\n",
      "149:\tlearn: 0.0357917\ttotal: 1.46s\tremaining: 8.26s\n",
      "150:\tlearn: 0.0355842\ttotal: 1.47s\tremaining: 8.24s\n",
      "151:\tlearn: 0.0354020\ttotal: 1.48s\tremaining: 8.23s\n",
      "152:\tlearn: 0.0351572\ttotal: 1.48s\tremaining: 8.21s\n",
      "153:\tlearn: 0.0348680\ttotal: 1.49s\tremaining: 8.2s\n",
      "154:\tlearn: 0.0346558\ttotal: 1.5s\tremaining: 8.19s\n",
      "155:\tlearn: 0.0341080\ttotal: 1.51s\tremaining: 8.17s\n",
      "156:\tlearn: 0.0339136\ttotal: 1.52s\tremaining: 8.16s\n",
      "157:\tlearn: 0.0336626\ttotal: 1.53s\tremaining: 8.15s\n",
      "158:\tlearn: 0.0334658\ttotal: 1.54s\tremaining: 8.13s\n",
      "159:\tlearn: 0.0332695\ttotal: 1.55s\tremaining: 8.12s\n",
      "160:\tlearn: 0.0331251\ttotal: 1.56s\tremaining: 8.11s\n",
      "161:\tlearn: 0.0327517\ttotal: 1.57s\tremaining: 8.11s\n",
      "162:\tlearn: 0.0324662\ttotal: 1.58s\tremaining: 8.1s\n",
      "163:\tlearn: 0.0323430\ttotal: 1.58s\tremaining: 8.08s\n",
      "164:\tlearn: 0.0321530\ttotal: 1.59s\tremaining: 8.06s\n",
      "165:\tlearn: 0.0319643\ttotal: 1.6s\tremaining: 8.05s\n",
      "166:\tlearn: 0.0318324\ttotal: 1.61s\tremaining: 8.03s\n",
      "167:\tlearn: 0.0315846\ttotal: 1.62s\tremaining: 8.03s\n",
      "168:\tlearn: 0.0313982\ttotal: 1.63s\tremaining: 8.03s\n",
      "169:\tlearn: 0.0311373\ttotal: 1.65s\tremaining: 8.04s\n",
      "170:\tlearn: 0.0309623\ttotal: 1.66s\tremaining: 8.04s\n",
      "171:\tlearn: 0.0306024\ttotal: 1.67s\tremaining: 8.03s\n",
      "172:\tlearn: 0.0304464\ttotal: 1.68s\tremaining: 8.01s\n",
      "173:\tlearn: 0.0301048\ttotal: 1.68s\tremaining: 7.99s\n",
      "174:\tlearn: 0.0298877\ttotal: 1.69s\tremaining: 7.98s\n",
      "175:\tlearn: 0.0297368\ttotal: 1.7s\tremaining: 7.96s\n",
      "176:\tlearn: 0.0294921\ttotal: 1.71s\tremaining: 7.95s\n",
      "177:\tlearn: 0.0293362\ttotal: 1.72s\tremaining: 7.93s\n",
      "178:\tlearn: 0.0292032\ttotal: 1.73s\tremaining: 7.92s\n",
      "179:\tlearn: 0.0290669\ttotal: 1.74s\tremaining: 7.91s\n",
      "180:\tlearn: 0.0288115\ttotal: 1.75s\tremaining: 7.9s\n",
      "181:\tlearn: 0.0286455\ttotal: 1.76s\tremaining: 7.89s\n",
      "182:\tlearn: 0.0284404\ttotal: 1.77s\tremaining: 7.89s\n",
      "183:\tlearn: 0.0282340\ttotal: 1.78s\tremaining: 7.88s\n",
      "184:\tlearn: 0.0274981\ttotal: 1.78s\tremaining: 7.86s\n",
      "185:\tlearn: 0.0273062\ttotal: 1.79s\tremaining: 7.85s\n",
      "186:\tlearn: 0.0271482\ttotal: 1.8s\tremaining: 7.84s\n",
      "187:\tlearn: 0.0270035\ttotal: 1.81s\tremaining: 7.83s\n",
      "188:\tlearn: 0.0267886\ttotal: 1.82s\tremaining: 7.83s\n",
      "189:\tlearn: 0.0266139\ttotal: 1.83s\tremaining: 7.82s\n",
      "190:\tlearn: 0.0264470\ttotal: 1.84s\tremaining: 7.81s\n",
      "191:\tlearn: 0.0263097\ttotal: 1.85s\tremaining: 7.8s\n",
      "192:\tlearn: 0.0261978\ttotal: 1.86s\tremaining: 7.79s\n",
      "193:\tlearn: 0.0259792\ttotal: 1.87s\tremaining: 7.78s\n",
      "194:\tlearn: 0.0258409\ttotal: 1.88s\tremaining: 7.77s\n",
      "195:\tlearn: 0.0257067\ttotal: 1.89s\tremaining: 7.76s\n",
      "196:\tlearn: 0.0255982\ttotal: 1.9s\tremaining: 7.75s\n",
      "197:\tlearn: 0.0253519\ttotal: 1.91s\tremaining: 7.74s\n",
      "198:\tlearn: 0.0251648\ttotal: 1.92s\tremaining: 7.73s\n",
      "199:\tlearn: 0.0250123\ttotal: 1.93s\tremaining: 7.72s\n",
      "200:\tlearn: 0.0247476\ttotal: 1.94s\tremaining: 7.71s\n",
      "201:\tlearn: 0.0245931\ttotal: 1.95s\tremaining: 7.7s\n",
      "202:\tlearn: 0.0243243\ttotal: 1.96s\tremaining: 7.7s\n",
      "203:\tlearn: 0.0240017\ttotal: 1.97s\tremaining: 7.69s\n",
      "204:\tlearn: 0.0239160\ttotal: 1.98s\tremaining: 7.68s\n",
      "205:\tlearn: 0.0237672\ttotal: 1.99s\tremaining: 7.67s\n",
      "206:\tlearn: 0.0236307\ttotal: 2s\tremaining: 7.66s\n",
      "207:\tlearn: 0.0235135\ttotal: 2.01s\tremaining: 7.64s\n",
      "208:\tlearn: 0.0233974\ttotal: 2.02s\tremaining: 7.63s\n",
      "209:\tlearn: 0.0232588\ttotal: 2.02s\tremaining: 7.62s\n",
      "210:\tlearn: 0.0231763\ttotal: 2.04s\tremaining: 7.61s\n",
      "211:\tlearn: 0.0230934\ttotal: 2.04s\tremaining: 7.6s\n",
      "212:\tlearn: 0.0229783\ttotal: 2.06s\tremaining: 7.6s\n",
      "213:\tlearn: 0.0228335\ttotal: 2.06s\tremaining: 7.59s\n",
      "214:\tlearn: 0.0227083\ttotal: 2.07s\tremaining: 7.57s\n",
      "215:\tlearn: 0.0225732\ttotal: 2.08s\tremaining: 7.56s\n",
      "216:\tlearn: 0.0223563\ttotal: 2.09s\tremaining: 7.55s\n",
      "217:\tlearn: 0.0222643\ttotal: 2.1s\tremaining: 7.54s\n",
      "218:\tlearn: 0.0220641\ttotal: 2.11s\tremaining: 7.53s\n",
      "219:\tlearn: 0.0216337\ttotal: 2.12s\tremaining: 7.51s\n",
      "220:\tlearn: 0.0214147\ttotal: 2.13s\tremaining: 7.5s\n",
      "221:\tlearn: 0.0213444\ttotal: 2.14s\tremaining: 7.49s\n",
      "222:\tlearn: 0.0212505\ttotal: 2.15s\tremaining: 7.49s\n",
      "223:\tlearn: 0.0211444\ttotal: 2.16s\tremaining: 7.48s\n",
      "224:\tlearn: 0.0210905\ttotal: 2.17s\tremaining: 7.47s\n",
      "225:\tlearn: 0.0209897\ttotal: 2.18s\tremaining: 7.46s\n",
      "226:\tlearn: 0.0208215\ttotal: 2.19s\tremaining: 7.45s\n",
      "227:\tlearn: 0.0207318\ttotal: 2.2s\tremaining: 7.44s\n",
      "228:\tlearn: 0.0206410\ttotal: 2.21s\tremaining: 7.43s\n",
      "229:\tlearn: 0.0205339\ttotal: 2.22s\tremaining: 7.42s\n",
      "230:\tlearn: 0.0203344\ttotal: 2.23s\tremaining: 7.41s\n",
      "231:\tlearn: 0.0201114\ttotal: 2.23s\tremaining: 7.4s\n",
      "232:\tlearn: 0.0200275\ttotal: 2.25s\tremaining: 7.39s\n",
      "233:\tlearn: 0.0199277\ttotal: 2.25s\tremaining: 7.38s\n",
      "234:\tlearn: 0.0197219\ttotal: 2.26s\tremaining: 7.37s\n",
      "235:\tlearn: 0.0196400\ttotal: 2.27s\tremaining: 7.35s\n",
      "236:\tlearn: 0.0194572\ttotal: 2.28s\tremaining: 7.34s\n",
      "237:\tlearn: 0.0194044\ttotal: 2.29s\tremaining: 7.34s\n",
      "238:\tlearn: 0.0193319\ttotal: 2.3s\tremaining: 7.33s\n",
      "239:\tlearn: 0.0191734\ttotal: 2.31s\tremaining: 7.32s\n",
      "240:\tlearn: 0.0190204\ttotal: 2.32s\tremaining: 7.31s\n",
      "241:\tlearn: 0.0189573\ttotal: 2.33s\tremaining: 7.3s\n",
      "242:\tlearn: 0.0188829\ttotal: 2.34s\tremaining: 7.29s\n",
      "243:\tlearn: 0.0188300\ttotal: 2.35s\tremaining: 7.28s\n",
      "244:\tlearn: 0.0187495\ttotal: 2.36s\tremaining: 7.26s\n",
      "245:\tlearn: 0.0187102\ttotal: 2.37s\tremaining: 7.25s\n",
      "246:\tlearn: 0.0186466\ttotal: 2.38s\tremaining: 7.24s\n",
      "247:\tlearn: 0.0185396\ttotal: 2.38s\tremaining: 7.23s\n",
      "248:\tlearn: 0.0184617\ttotal: 2.39s\tremaining: 7.22s\n",
      "249:\tlearn: 0.0183882\ttotal: 2.4s\tremaining: 7.21s\n",
      "250:\tlearn: 0.0182398\ttotal: 2.41s\tremaining: 7.2s\n",
      "251:\tlearn: 0.0181560\ttotal: 2.42s\tremaining: 7.19s\n",
      "252:\tlearn: 0.0180536\ttotal: 2.43s\tremaining: 7.18s\n",
      "253:\tlearn: 0.0178890\ttotal: 2.44s\tremaining: 7.17s\n",
      "254:\tlearn: 0.0177732\ttotal: 2.45s\tremaining: 7.16s\n",
      "255:\tlearn: 0.0176623\ttotal: 2.46s\tremaining: 7.14s\n",
      "256:\tlearn: 0.0175660\ttotal: 2.47s\tremaining: 7.14s\n",
      "257:\tlearn: 0.0172167\ttotal: 2.48s\tremaining: 7.13s\n",
      "258:\tlearn: 0.0171215\ttotal: 2.49s\tremaining: 7.13s\n",
      "259:\tlearn: 0.0169898\ttotal: 2.5s\tremaining: 7.12s\n",
      "260:\tlearn: 0.0169122\ttotal: 2.51s\tremaining: 7.11s\n",
      "261:\tlearn: 0.0168092\ttotal: 2.52s\tremaining: 7.1s\n",
      "262:\tlearn: 0.0166811\ttotal: 2.53s\tremaining: 7.09s\n",
      "263:\tlearn: 0.0164470\ttotal: 2.54s\tremaining: 7.08s\n",
      "264:\tlearn: 0.0163884\ttotal: 2.55s\tremaining: 7.07s\n",
      "265:\tlearn: 0.0162699\ttotal: 2.56s\tremaining: 7.06s\n",
      "266:\tlearn: 0.0161877\ttotal: 2.57s\tremaining: 7.05s\n",
      "267:\tlearn: 0.0161259\ttotal: 2.58s\tremaining: 7.04s\n",
      "268:\tlearn: 0.0160796\ttotal: 2.59s\tremaining: 7.03s\n",
      "269:\tlearn: 0.0159957\ttotal: 2.6s\tremaining: 7.02s\n",
      "270:\tlearn: 0.0159084\ttotal: 2.6s\tremaining: 7s\n",
      "271:\tlearn: 0.0158277\ttotal: 2.61s\tremaining: 6.99s\n",
      "272:\tlearn: 0.0157332\ttotal: 2.62s\tremaining: 6.99s\n",
      "273:\tlearn: 0.0156569\ttotal: 2.64s\tremaining: 6.99s\n",
      "274:\tlearn: 0.0154401\ttotal: 2.65s\tremaining: 6.99s\n",
      "275:\tlearn: 0.0153084\ttotal: 2.66s\tremaining: 6.98s\n",
      "276:\tlearn: 0.0152254\ttotal: 2.67s\tremaining: 6.98s\n",
      "277:\tlearn: 0.0151254\ttotal: 2.69s\tremaining: 6.98s\n",
      "278:\tlearn: 0.0149672\ttotal: 2.7s\tremaining: 6.97s\n",
      "279:\tlearn: 0.0149293\ttotal: 2.71s\tremaining: 6.96s\n",
      "280:\tlearn: 0.0148533\ttotal: 2.72s\tremaining: 6.96s\n",
      "281:\tlearn: 0.0147602\ttotal: 2.73s\tremaining: 6.95s\n",
      "282:\tlearn: 0.0147214\ttotal: 2.74s\tremaining: 6.94s\n",
      "283:\tlearn: 0.0146005\ttotal: 2.75s\tremaining: 6.93s\n",
      "284:\tlearn: 0.0144873\ttotal: 2.76s\tremaining: 6.92s\n",
      "285:\tlearn: 0.0144098\ttotal: 2.77s\tremaining: 6.92s\n",
      "286:\tlearn: 0.0143166\ttotal: 2.78s\tremaining: 6.91s\n",
      "287:\tlearn: 0.0142593\ttotal: 2.79s\tremaining: 6.9s\n",
      "288:\tlearn: 0.0141891\ttotal: 2.8s\tremaining: 6.89s\n",
      "289:\tlearn: 0.0141327\ttotal: 2.81s\tremaining: 6.89s\n",
      "290:\tlearn: 0.0140756\ttotal: 2.82s\tremaining: 6.88s\n",
      "291:\tlearn: 0.0140154\ttotal: 2.83s\tremaining: 6.87s\n",
      "292:\tlearn: 0.0139308\ttotal: 2.84s\tremaining: 6.86s\n",
      "293:\tlearn: 0.0138801\ttotal: 2.85s\tremaining: 6.85s\n",
      "294:\tlearn: 0.0138354\ttotal: 2.86s\tremaining: 6.84s\n",
      "295:\tlearn: 0.0137625\ttotal: 2.87s\tremaining: 6.83s\n",
      "296:\tlearn: 0.0137133\ttotal: 2.88s\tremaining: 6.82s\n",
      "297:\tlearn: 0.0136760\ttotal: 2.89s\tremaining: 6.81s\n",
      "298:\tlearn: 0.0135705\ttotal: 2.9s\tremaining: 6.8s\n",
      "299:\tlearn: 0.0134883\ttotal: 2.91s\tremaining: 6.79s\n",
      "300:\tlearn: 0.0134218\ttotal: 2.92s\tremaining: 6.78s\n",
      "301:\tlearn: 0.0133327\ttotal: 2.93s\tremaining: 6.77s\n",
      "302:\tlearn: 0.0132635\ttotal: 2.94s\tremaining: 6.76s\n",
      "303:\tlearn: 0.0132056\ttotal: 2.95s\tremaining: 6.75s\n",
      "304:\tlearn: 0.0131618\ttotal: 2.96s\tremaining: 6.74s\n",
      "305:\tlearn: 0.0130647\ttotal: 2.97s\tremaining: 6.74s\n",
      "306:\tlearn: 0.0129954\ttotal: 2.98s\tremaining: 6.72s\n",
      "307:\tlearn: 0.0129519\ttotal: 2.99s\tremaining: 6.71s\n",
      "308:\tlearn: 0.0129024\ttotal: 3s\tremaining: 6.71s\n",
      "309:\tlearn: 0.0128663\ttotal: 3.01s\tremaining: 6.69s\n",
      "310:\tlearn: 0.0127794\ttotal: 3.02s\tremaining: 6.68s\n",
      "311:\tlearn: 0.0127377\ttotal: 3.03s\tremaining: 6.68s\n",
      "312:\tlearn: 0.0126715\ttotal: 3.04s\tremaining: 6.66s\n",
      "313:\tlearn: 0.0126323\ttotal: 3.04s\tremaining: 6.65s\n",
      "314:\tlearn: 0.0125304\ttotal: 3.06s\tremaining: 6.64s\n",
      "315:\tlearn: 0.0125097\ttotal: 3.06s\tremaining: 6.63s\n",
      "316:\tlearn: 0.0124140\ttotal: 3.07s\tremaining: 6.62s\n",
      "317:\tlearn: 0.0123736\ttotal: 3.08s\tremaining: 6.61s\n",
      "318:\tlearn: 0.0123099\ttotal: 3.09s\tremaining: 6.6s\n",
      "319:\tlearn: 0.0122700\ttotal: 3.1s\tremaining: 6.59s\n",
      "320:\tlearn: 0.0122225\ttotal: 3.11s\tremaining: 6.58s\n",
      "321:\tlearn: 0.0121644\ttotal: 3.12s\tremaining: 6.57s\n",
      "322:\tlearn: 0.0120929\ttotal: 3.13s\tremaining: 6.56s\n",
      "323:\tlearn: 0.0120384\ttotal: 3.14s\tremaining: 6.56s\n",
      "324:\tlearn: 0.0119480\ttotal: 3.15s\tremaining: 6.55s\n",
      "325:\tlearn: 0.0119190\ttotal: 3.16s\tremaining: 6.54s\n",
      "326:\tlearn: 0.0118606\ttotal: 3.17s\tremaining: 6.53s\n",
      "327:\tlearn: 0.0116152\ttotal: 3.18s\tremaining: 6.51s\n",
      "328:\tlearn: 0.0115736\ttotal: 3.19s\tremaining: 6.51s\n",
      "329:\tlearn: 0.0115245\ttotal: 3.2s\tremaining: 6.5s\n",
      "330:\tlearn: 0.0115051\ttotal: 3.21s\tremaining: 6.48s\n",
      "331:\tlearn: 0.0114329\ttotal: 3.22s\tremaining: 6.47s\n",
      "332:\tlearn: 0.0113970\ttotal: 3.22s\tremaining: 6.46s\n",
      "333:\tlearn: 0.0112675\ttotal: 3.23s\tremaining: 6.45s\n",
      "334:\tlearn: 0.0112267\ttotal: 3.24s\tremaining: 6.44s\n",
      "335:\tlearn: 0.0111906\ttotal: 3.25s\tremaining: 6.43s\n",
      "336:\tlearn: 0.0111549\ttotal: 3.26s\tremaining: 6.42s\n",
      "337:\tlearn: 0.0111145\ttotal: 3.27s\tremaining: 6.41s\n",
      "338:\tlearn: 0.0110713\ttotal: 3.29s\tremaining: 6.42s\n",
      "339:\tlearn: 0.0110205\ttotal: 3.31s\tremaining: 6.42s\n",
      "340:\tlearn: 0.0109845\ttotal: 3.31s\tremaining: 6.4s\n",
      "341:\tlearn: 0.0109587\ttotal: 3.32s\tremaining: 6.39s\n",
      "342:\tlearn: 0.0108291\ttotal: 3.33s\tremaining: 6.39s\n",
      "343:\tlearn: 0.0107929\ttotal: 3.34s\tremaining: 6.38s\n",
      "344:\tlearn: 0.0107662\ttotal: 3.35s\tremaining: 6.37s\n",
      "345:\tlearn: 0.0106964\ttotal: 3.36s\tremaining: 6.36s\n",
      "346:\tlearn: 0.0106536\ttotal: 3.37s\tremaining: 6.35s\n",
      "347:\tlearn: 0.0105701\ttotal: 3.38s\tremaining: 6.34s\n",
      "348:\tlearn: 0.0105086\ttotal: 3.39s\tremaining: 6.33s\n",
      "349:\tlearn: 0.0104324\ttotal: 3.4s\tremaining: 6.32s\n",
      "350:\tlearn: 0.0103823\ttotal: 3.41s\tremaining: 6.31s\n",
      "351:\tlearn: 0.0103274\ttotal: 3.42s\tremaining: 6.3s\n",
      "352:\tlearn: 0.0102900\ttotal: 3.43s\tremaining: 6.29s\n",
      "353:\tlearn: 0.0102333\ttotal: 3.44s\tremaining: 6.28s\n",
      "354:\tlearn: 0.0102034\ttotal: 3.45s\tremaining: 6.27s\n",
      "355:\tlearn: 0.0101715\ttotal: 3.46s\tremaining: 6.27s\n",
      "356:\tlearn: 0.0101474\ttotal: 3.47s\tremaining: 6.25s\n",
      "357:\tlearn: 0.0100776\ttotal: 3.48s\tremaining: 6.25s\n",
      "358:\tlearn: 0.0100341\ttotal: 3.49s\tremaining: 6.24s\n",
      "359:\tlearn: 0.0099950\ttotal: 3.5s\tremaining: 6.22s\n",
      "360:\tlearn: 0.0099716\ttotal: 3.51s\tremaining: 6.22s\n",
      "361:\tlearn: 0.0099494\ttotal: 3.52s\tremaining: 6.21s\n",
      "362:\tlearn: 0.0098930\ttotal: 3.53s\tremaining: 6.2s\n",
      "363:\tlearn: 0.0098598\ttotal: 3.54s\tremaining: 6.19s\n",
      "364:\tlearn: 0.0098098\ttotal: 3.55s\tremaining: 6.18s\n",
      "365:\tlearn: 0.0097980\ttotal: 3.56s\tremaining: 6.17s\n",
      "366:\tlearn: 0.0097433\ttotal: 3.58s\tremaining: 6.17s\n",
      "367:\tlearn: 0.0097146\ttotal: 3.59s\tremaining: 6.17s\n",
      "368:\tlearn: 0.0096575\ttotal: 3.6s\tremaining: 6.16s\n",
      "369:\tlearn: 0.0096154\ttotal: 3.61s\tremaining: 6.15s\n",
      "370:\tlearn: 0.0095890\ttotal: 3.62s\tremaining: 6.14s\n",
      "371:\tlearn: 0.0095504\ttotal: 3.63s\tremaining: 6.13s\n",
      "372:\tlearn: 0.0095321\ttotal: 3.65s\tremaining: 6.13s\n",
      "373:\tlearn: 0.0095041\ttotal: 3.66s\tremaining: 6.12s\n",
      "374:\tlearn: 0.0094617\ttotal: 3.67s\tremaining: 6.11s\n",
      "375:\tlearn: 0.0094195\ttotal: 3.68s\tremaining: 6.1s\n",
      "376:\tlearn: 0.0093920\ttotal: 3.69s\tremaining: 6.1s\n",
      "377:\tlearn: 0.0093071\ttotal: 3.7s\tremaining: 6.09s\n",
      "378:\tlearn: 0.0092563\ttotal: 3.71s\tremaining: 6.08s\n",
      "379:\tlearn: 0.0091919\ttotal: 3.72s\tremaining: 6.07s\n",
      "380:\tlearn: 0.0091405\ttotal: 3.73s\tremaining: 6.06s\n",
      "381:\tlearn: 0.0089741\ttotal: 3.74s\tremaining: 6.05s\n",
      "382:\tlearn: 0.0089437\ttotal: 3.75s\tremaining: 6.05s\n",
      "383:\tlearn: 0.0089093\ttotal: 3.76s\tremaining: 6.04s\n",
      "384:\tlearn: 0.0088779\ttotal: 3.77s\tremaining: 6.03s\n",
      "385:\tlearn: 0.0088604\ttotal: 3.78s\tremaining: 6.02s\n",
      "386:\tlearn: 0.0088225\ttotal: 3.79s\tremaining: 6.01s\n",
      "387:\tlearn: 0.0087819\ttotal: 3.81s\tremaining: 6s\n",
      "388:\tlearn: 0.0087479\ttotal: 3.81s\tremaining: 5.99s\n",
      "389:\tlearn: 0.0087350\ttotal: 3.83s\tremaining: 5.98s\n",
      "390:\tlearn: 0.0087113\ttotal: 3.84s\tremaining: 5.98s\n",
      "391:\tlearn: 0.0086867\ttotal: 3.85s\tremaining: 5.97s\n",
      "392:\tlearn: 0.0086688\ttotal: 3.86s\tremaining: 5.96s\n",
      "393:\tlearn: 0.0086463\ttotal: 3.87s\tremaining: 5.95s\n",
      "394:\tlearn: 0.0085967\ttotal: 3.88s\tremaining: 5.94s\n",
      "395:\tlearn: 0.0085702\ttotal: 3.89s\tremaining: 5.94s\n",
      "396:\tlearn: 0.0085510\ttotal: 3.9s\tremaining: 5.93s\n",
      "397:\tlearn: 0.0085382\ttotal: 3.92s\tremaining: 5.92s\n",
      "398:\tlearn: 0.0085217\ttotal: 3.93s\tremaining: 5.91s\n",
      "399:\tlearn: 0.0084989\ttotal: 3.94s\tremaining: 5.91s\n",
      "400:\tlearn: 0.0084775\ttotal: 3.95s\tremaining: 5.9s\n",
      "401:\tlearn: 0.0084540\ttotal: 3.96s\tremaining: 5.89s\n",
      "402:\tlearn: 0.0084290\ttotal: 3.97s\tremaining: 5.88s\n",
      "403:\tlearn: 0.0084096\ttotal: 3.98s\tremaining: 5.87s\n",
      "404:\tlearn: 0.0083695\ttotal: 3.99s\tremaining: 5.86s\n",
      "405:\tlearn: 0.0083491\ttotal: 4s\tremaining: 5.85s\n",
      "406:\tlearn: 0.0082947\ttotal: 4.01s\tremaining: 5.84s\n",
      "407:\tlearn: 0.0082725\ttotal: 4.02s\tremaining: 5.83s\n",
      "408:\tlearn: 0.0082465\ttotal: 4.03s\tremaining: 5.83s\n",
      "409:\tlearn: 0.0082142\ttotal: 4.04s\tremaining: 5.81s\n",
      "410:\tlearn: 0.0082004\ttotal: 4.05s\tremaining: 5.8s\n",
      "411:\tlearn: 0.0081606\ttotal: 4.06s\tremaining: 5.79s\n",
      "412:\tlearn: 0.0081166\ttotal: 4.07s\tremaining: 5.78s\n",
      "413:\tlearn: 0.0080929\ttotal: 4.08s\tremaining: 5.78s\n",
      "414:\tlearn: 0.0080614\ttotal: 4.09s\tremaining: 5.76s\n",
      "415:\tlearn: 0.0080361\ttotal: 4.1s\tremaining: 5.76s\n",
      "416:\tlearn: 0.0080145\ttotal: 4.11s\tremaining: 5.75s\n",
      "417:\tlearn: 0.0079855\ttotal: 4.12s\tremaining: 5.74s\n",
      "418:\tlearn: 0.0079608\ttotal: 4.13s\tremaining: 5.73s\n",
      "419:\tlearn: 0.0079249\ttotal: 4.14s\tremaining: 5.72s\n",
      "420:\tlearn: 0.0078513\ttotal: 4.15s\tremaining: 5.71s\n",
      "421:\tlearn: 0.0078124\ttotal: 4.16s\tremaining: 5.7s\n",
      "422:\tlearn: 0.0077448\ttotal: 4.18s\tremaining: 5.7s\n",
      "423:\tlearn: 0.0077315\ttotal: 4.18s\tremaining: 5.69s\n",
      "424:\tlearn: 0.0077103\ttotal: 4.2s\tremaining: 5.68s\n",
      "425:\tlearn: 0.0076900\ttotal: 4.21s\tremaining: 5.67s\n",
      "426:\tlearn: 0.0076490\ttotal: 4.21s\tremaining: 5.66s\n",
      "427:\tlearn: 0.0076327\ttotal: 4.22s\tremaining: 5.65s\n",
      "428:\tlearn: 0.0075870\ttotal: 4.24s\tremaining: 5.64s\n",
      "429:\tlearn: 0.0075729\ttotal: 4.24s\tremaining: 5.63s\n",
      "430:\tlearn: 0.0075355\ttotal: 4.25s\tremaining: 5.62s\n",
      "431:\tlearn: 0.0075197\ttotal: 4.26s\tremaining: 5.61s\n",
      "432:\tlearn: 0.0075000\ttotal: 4.28s\tremaining: 5.6s\n",
      "433:\tlearn: 0.0074825\ttotal: 4.29s\tremaining: 5.59s\n",
      "434:\tlearn: 0.0074535\ttotal: 4.3s\tremaining: 5.58s\n",
      "435:\tlearn: 0.0074384\ttotal: 4.31s\tremaining: 5.57s\n",
      "436:\tlearn: 0.0074079\ttotal: 4.32s\tremaining: 5.57s\n",
      "437:\tlearn: 0.0073691\ttotal: 4.33s\tremaining: 5.56s\n",
      "438:\tlearn: 0.0073521\ttotal: 4.34s\tremaining: 5.55s\n",
      "439:\tlearn: 0.0073387\ttotal: 4.35s\tremaining: 5.54s\n",
      "440:\tlearn: 0.0072131\ttotal: 4.36s\tremaining: 5.53s\n",
      "441:\tlearn: 0.0071993\ttotal: 4.37s\tremaining: 5.52s\n",
      "442:\tlearn: 0.0071754\ttotal: 4.38s\tremaining: 5.51s\n",
      "443:\tlearn: 0.0071466\ttotal: 4.39s\tremaining: 5.5s\n",
      "444:\tlearn: 0.0071169\ttotal: 4.4s\tremaining: 5.49s\n",
      "445:\tlearn: 0.0071006\ttotal: 4.41s\tremaining: 5.48s\n",
      "446:\tlearn: 0.0070853\ttotal: 4.42s\tremaining: 5.47s\n",
      "447:\tlearn: 0.0070665\ttotal: 4.43s\tremaining: 5.46s\n",
      "448:\tlearn: 0.0070538\ttotal: 4.44s\tremaining: 5.45s\n",
      "449:\tlearn: 0.0070230\ttotal: 4.45s\tremaining: 5.44s\n",
      "450:\tlearn: 0.0069973\ttotal: 4.46s\tremaining: 5.43s\n",
      "451:\tlearn: 0.0069740\ttotal: 4.47s\tremaining: 5.42s\n",
      "452:\tlearn: 0.0069559\ttotal: 4.48s\tremaining: 5.41s\n",
      "453:\tlearn: 0.0069330\ttotal: 4.49s\tremaining: 5.4s\n",
      "454:\tlearn: 0.0069225\ttotal: 4.5s\tremaining: 5.39s\n",
      "455:\tlearn: 0.0069074\ttotal: 4.51s\tremaining: 5.38s\n",
      "456:\tlearn: 0.0068890\ttotal: 4.52s\tremaining: 5.37s\n",
      "457:\tlearn: 0.0068698\ttotal: 4.53s\tremaining: 5.37s\n",
      "458:\tlearn: 0.0068376\ttotal: 4.54s\tremaining: 5.35s\n",
      "459:\tlearn: 0.0068178\ttotal: 4.55s\tremaining: 5.34s\n",
      "460:\tlearn: 0.0067813\ttotal: 4.56s\tremaining: 5.33s\n",
      "461:\tlearn: 0.0067499\ttotal: 4.57s\tremaining: 5.32s\n",
      "462:\tlearn: 0.0067348\ttotal: 4.58s\tremaining: 5.31s\n",
      "463:\tlearn: 0.0067103\ttotal: 4.59s\tremaining: 5.3s\n",
      "464:\tlearn: 0.0067003\ttotal: 4.6s\tremaining: 5.29s\n",
      "465:\tlearn: 0.0066706\ttotal: 4.61s\tremaining: 5.28s\n",
      "466:\tlearn: 0.0066537\ttotal: 4.62s\tremaining: 5.27s\n",
      "467:\tlearn: 0.0066446\ttotal: 4.63s\tremaining: 5.26s\n",
      "468:\tlearn: 0.0066324\ttotal: 4.64s\tremaining: 5.25s\n",
      "469:\tlearn: 0.0066134\ttotal: 4.65s\tremaining: 5.24s\n",
      "470:\tlearn: 0.0065790\ttotal: 4.66s\tremaining: 5.23s\n",
      "471:\tlearn: 0.0065523\ttotal: 4.67s\tremaining: 5.22s\n",
      "472:\tlearn: 0.0065287\ttotal: 4.68s\tremaining: 5.22s\n",
      "473:\tlearn: 0.0065192\ttotal: 4.69s\tremaining: 5.21s\n",
      "474:\tlearn: 0.0065084\ttotal: 4.7s\tremaining: 5.2s\n",
      "475:\tlearn: 0.0064997\ttotal: 4.71s\tremaining: 5.19s\n",
      "476:\tlearn: 0.0064766\ttotal: 4.72s\tremaining: 5.18s\n",
      "477:\tlearn: 0.0064560\ttotal: 4.73s\tremaining: 5.17s\n",
      "478:\tlearn: 0.0064365\ttotal: 4.74s\tremaining: 5.16s\n",
      "479:\tlearn: 0.0064161\ttotal: 4.75s\tremaining: 5.15s\n",
      "480:\tlearn: 0.0063912\ttotal: 4.76s\tremaining: 5.14s\n",
      "481:\tlearn: 0.0063789\ttotal: 4.77s\tremaining: 5.13s\n",
      "482:\tlearn: 0.0063519\ttotal: 4.78s\tremaining: 5.12s\n",
      "483:\tlearn: 0.0063299\ttotal: 4.79s\tremaining: 5.11s\n",
      "484:\tlearn: 0.0062794\ttotal: 4.8s\tremaining: 5.1s\n",
      "485:\tlearn: 0.0062539\ttotal: 4.81s\tremaining: 5.09s\n",
      "486:\tlearn: 0.0062405\ttotal: 4.83s\tremaining: 5.08s\n",
      "487:\tlearn: 0.0062129\ttotal: 4.83s\tremaining: 5.07s\n",
      "488:\tlearn: 0.0061997\ttotal: 4.85s\tremaining: 5.06s\n",
      "489:\tlearn: 0.0061769\ttotal: 4.86s\tremaining: 5.05s\n",
      "490:\tlearn: 0.0061544\ttotal: 4.87s\tremaining: 5.05s\n",
      "491:\tlearn: 0.0061432\ttotal: 4.88s\tremaining: 5.04s\n",
      "492:\tlearn: 0.0061099\ttotal: 4.89s\tremaining: 5.03s\n",
      "493:\tlearn: 0.0060948\ttotal: 4.9s\tremaining: 5.02s\n",
      "494:\tlearn: 0.0060742\ttotal: 4.91s\tremaining: 5.01s\n",
      "495:\tlearn: 0.0060506\ttotal: 4.92s\tremaining: 5s\n",
      "496:\tlearn: 0.0060318\ttotal: 4.93s\tremaining: 4.99s\n",
      "497:\tlearn: 0.0060201\ttotal: 4.94s\tremaining: 4.98s\n",
      "498:\tlearn: 0.0059896\ttotal: 4.95s\tremaining: 4.97s\n",
      "499:\tlearn: 0.0059668\ttotal: 4.96s\tremaining: 4.96s\n",
      "500:\tlearn: 0.0059432\ttotal: 4.97s\tremaining: 4.95s\n",
      "501:\tlearn: 0.0059115\ttotal: 4.98s\tremaining: 4.94s\n",
      "502:\tlearn: 0.0058855\ttotal: 4.99s\tremaining: 4.93s\n",
      "503:\tlearn: 0.0058742\ttotal: 5s\tremaining: 4.92s\n",
      "504:\tlearn: 0.0058589\ttotal: 5.01s\tremaining: 4.91s\n",
      "505:\tlearn: 0.0058316\ttotal: 5.02s\tremaining: 4.9s\n",
      "506:\tlearn: 0.0058096\ttotal: 5.03s\tremaining: 4.89s\n",
      "507:\tlearn: 0.0058002\ttotal: 5.04s\tremaining: 4.88s\n",
      "508:\tlearn: 0.0057849\ttotal: 5.05s\tremaining: 4.87s\n",
      "509:\tlearn: 0.0057554\ttotal: 5.06s\tremaining: 4.86s\n",
      "510:\tlearn: 0.0057389\ttotal: 5.07s\tremaining: 4.85s\n",
      "511:\tlearn: 0.0057225\ttotal: 5.08s\tremaining: 4.84s\n",
      "512:\tlearn: 0.0057049\ttotal: 5.09s\tremaining: 4.83s\n",
      "513:\tlearn: 0.0056876\ttotal: 5.1s\tremaining: 4.82s\n",
      "514:\tlearn: 0.0056764\ttotal: 5.11s\tremaining: 4.81s\n",
      "515:\tlearn: 0.0056520\ttotal: 5.12s\tremaining: 4.8s\n",
      "516:\tlearn: 0.0056354\ttotal: 5.13s\tremaining: 4.79s\n",
      "517:\tlearn: 0.0056280\ttotal: 5.14s\tremaining: 4.78s\n",
      "518:\tlearn: 0.0055998\ttotal: 5.15s\tremaining: 4.77s\n",
      "519:\tlearn: 0.0055915\ttotal: 5.16s\tremaining: 4.76s\n",
      "520:\tlearn: 0.0055644\ttotal: 5.17s\tremaining: 4.75s\n",
      "521:\tlearn: 0.0055533\ttotal: 5.18s\tremaining: 4.75s\n",
      "522:\tlearn: 0.0055298\ttotal: 5.19s\tremaining: 4.74s\n",
      "523:\tlearn: 0.0055089\ttotal: 5.2s\tremaining: 4.73s\n",
      "524:\tlearn: 0.0054787\ttotal: 5.21s\tremaining: 4.72s\n",
      "525:\tlearn: 0.0054548\ttotal: 5.22s\tremaining: 4.71s\n",
      "526:\tlearn: 0.0054426\ttotal: 5.23s\tremaining: 4.7s\n",
      "527:\tlearn: 0.0054239\ttotal: 5.24s\tremaining: 4.69s\n",
      "528:\tlearn: 0.0054181\ttotal: 5.25s\tremaining: 4.68s\n",
      "529:\tlearn: 0.0054040\ttotal: 5.26s\tremaining: 4.67s\n",
      "530:\tlearn: 0.0053912\ttotal: 5.28s\tremaining: 4.66s\n",
      "531:\tlearn: 0.0053700\ttotal: 5.29s\tremaining: 4.65s\n",
      "532:\tlearn: 0.0053546\ttotal: 5.3s\tremaining: 4.64s\n",
      "533:\tlearn: 0.0053418\ttotal: 5.31s\tremaining: 4.63s\n",
      "534:\tlearn: 0.0053267\ttotal: 5.32s\tremaining: 4.62s\n",
      "535:\tlearn: 0.0053073\ttotal: 5.33s\tremaining: 4.61s\n",
      "536:\tlearn: 0.0052864\ttotal: 5.34s\tremaining: 4.6s\n",
      "537:\tlearn: 0.0052641\ttotal: 5.35s\tremaining: 4.59s\n",
      "538:\tlearn: 0.0052496\ttotal: 5.36s\tremaining: 4.58s\n",
      "539:\tlearn: 0.0052423\ttotal: 5.37s\tremaining: 4.57s\n",
      "540:\tlearn: 0.0052192\ttotal: 5.38s\tremaining: 4.56s\n",
      "541:\tlearn: 0.0052125\ttotal: 5.39s\tremaining: 4.55s\n",
      "542:\tlearn: 0.0051893\ttotal: 5.39s\tremaining: 4.54s\n",
      "543:\tlearn: 0.0051826\ttotal: 5.4s\tremaining: 4.53s\n",
      "544:\tlearn: 0.0051538\ttotal: 5.41s\tremaining: 4.52s\n",
      "545:\tlearn: 0.0051434\ttotal: 5.42s\tremaining: 4.51s\n",
      "546:\tlearn: 0.0051289\ttotal: 5.43s\tremaining: 4.5s\n",
      "547:\tlearn: 0.0051121\ttotal: 5.44s\tremaining: 4.49s\n",
      "548:\tlearn: 0.0050921\ttotal: 5.45s\tremaining: 4.48s\n",
      "549:\tlearn: 0.0050840\ttotal: 5.46s\tremaining: 4.47s\n",
      "550:\tlearn: 0.0050746\ttotal: 5.47s\tremaining: 4.46s\n",
      "551:\tlearn: 0.0050373\ttotal: 5.48s\tremaining: 4.45s\n",
      "552:\tlearn: 0.0050171\ttotal: 5.49s\tremaining: 4.44s\n",
      "553:\tlearn: 0.0049889\ttotal: 5.51s\tremaining: 4.43s\n",
      "554:\tlearn: 0.0049775\ttotal: 5.52s\tremaining: 4.42s\n",
      "555:\tlearn: 0.0049627\ttotal: 5.53s\tremaining: 4.41s\n",
      "556:\tlearn: 0.0049513\ttotal: 5.54s\tremaining: 4.4s\n",
      "557:\tlearn: 0.0049285\ttotal: 5.55s\tremaining: 4.39s\n",
      "558:\tlearn: 0.0049219\ttotal: 5.56s\tremaining: 4.38s\n",
      "559:\tlearn: 0.0048909\ttotal: 5.57s\tremaining: 4.38s\n",
      "560:\tlearn: 0.0048794\ttotal: 5.58s\tremaining: 4.37s\n",
      "561:\tlearn: 0.0048701\ttotal: 5.59s\tremaining: 4.36s\n",
      "562:\tlearn: 0.0048475\ttotal: 5.6s\tremaining: 4.35s\n",
      "563:\tlearn: 0.0048391\ttotal: 5.61s\tremaining: 4.34s\n",
      "564:\tlearn: 0.0048226\ttotal: 5.62s\tremaining: 4.33s\n",
      "565:\tlearn: 0.0048019\ttotal: 5.63s\tremaining: 4.32s\n",
      "566:\tlearn: 0.0047929\ttotal: 5.64s\tremaining: 4.31s\n",
      "567:\tlearn: 0.0047766\ttotal: 5.65s\tremaining: 4.3s\n",
      "568:\tlearn: 0.0047562\ttotal: 5.66s\tremaining: 4.29s\n",
      "569:\tlearn: 0.0047484\ttotal: 5.67s\tremaining: 4.28s\n",
      "570:\tlearn: 0.0047383\ttotal: 5.68s\tremaining: 4.27s\n",
      "571:\tlearn: 0.0047169\ttotal: 5.69s\tremaining: 4.26s\n",
      "572:\tlearn: 0.0047089\ttotal: 5.7s\tremaining: 4.25s\n",
      "573:\tlearn: 0.0046971\ttotal: 5.71s\tremaining: 4.24s\n",
      "574:\tlearn: 0.0046919\ttotal: 5.72s\tremaining: 4.23s\n",
      "575:\tlearn: 0.0046764\ttotal: 5.73s\tremaining: 4.22s\n",
      "576:\tlearn: 0.0046596\ttotal: 5.74s\tremaining: 4.21s\n",
      "577:\tlearn: 0.0046345\ttotal: 5.75s\tremaining: 4.2s\n",
      "578:\tlearn: 0.0046215\ttotal: 5.76s\tremaining: 4.19s\n",
      "579:\tlearn: 0.0046084\ttotal: 5.77s\tremaining: 4.18s\n",
      "580:\tlearn: 0.0045715\ttotal: 5.78s\tremaining: 4.17s\n",
      "581:\tlearn: 0.0045524\ttotal: 5.79s\tremaining: 4.16s\n",
      "582:\tlearn: 0.0045163\ttotal: 5.8s\tremaining: 4.15s\n",
      "583:\tlearn: 0.0045077\ttotal: 5.81s\tremaining: 4.14s\n",
      "584:\tlearn: 0.0044947\ttotal: 5.82s\tremaining: 4.13s\n",
      "585:\tlearn: 0.0044772\ttotal: 5.83s\tremaining: 4.12s\n",
      "586:\tlearn: 0.0044655\ttotal: 5.84s\tremaining: 4.11s\n",
      "587:\tlearn: 0.0044587\ttotal: 5.85s\tremaining: 4.1s\n",
      "588:\tlearn: 0.0044259\ttotal: 5.86s\tremaining: 4.09s\n",
      "589:\tlearn: 0.0044112\ttotal: 5.87s\tremaining: 4.08s\n",
      "590:\tlearn: 0.0044041\ttotal: 5.88s\tremaining: 4.07s\n",
      "591:\tlearn: 0.0043980\ttotal: 5.89s\tremaining: 4.06s\n",
      "592:\tlearn: 0.0043866\ttotal: 5.9s\tremaining: 4.05s\n",
      "593:\tlearn: 0.0043785\ttotal: 5.91s\tremaining: 4.04s\n",
      "594:\tlearn: 0.0043677\ttotal: 5.92s\tremaining: 4.03s\n",
      "595:\tlearn: 0.0043588\ttotal: 5.93s\tremaining: 4.02s\n",
      "596:\tlearn: 0.0043460\ttotal: 5.94s\tremaining: 4.01s\n",
      "597:\tlearn: 0.0043380\ttotal: 5.96s\tremaining: 4s\n",
      "598:\tlearn: 0.0043243\ttotal: 5.97s\tremaining: 3.99s\n",
      "599:\tlearn: 0.0043024\ttotal: 5.98s\tremaining: 3.98s\n",
      "600:\tlearn: 0.0042929\ttotal: 5.99s\tremaining: 3.98s\n",
      "601:\tlearn: 0.0042794\ttotal: 6s\tremaining: 3.96s\n",
      "602:\tlearn: 0.0042356\ttotal: 6.01s\tremaining: 3.96s\n",
      "603:\tlearn: 0.0042195\ttotal: 6.02s\tremaining: 3.94s\n",
      "604:\tlearn: 0.0041980\ttotal: 6.03s\tremaining: 3.94s\n",
      "605:\tlearn: 0.0041898\ttotal: 6.04s\tremaining: 3.92s\n",
      "606:\tlearn: 0.0041830\ttotal: 6.05s\tremaining: 3.91s\n",
      "607:\tlearn: 0.0041606\ttotal: 6.06s\tremaining: 3.9s\n",
      "608:\tlearn: 0.0041517\ttotal: 6.07s\tremaining: 3.9s\n",
      "609:\tlearn: 0.0041362\ttotal: 6.08s\tremaining: 3.89s\n",
      "610:\tlearn: 0.0041147\ttotal: 6.09s\tremaining: 3.88s\n",
      "611:\tlearn: 0.0041040\ttotal: 6.1s\tremaining: 3.87s\n",
      "612:\tlearn: 0.0040973\ttotal: 6.11s\tremaining: 3.86s\n",
      "613:\tlearn: 0.0040895\ttotal: 6.12s\tremaining: 3.85s\n",
      "614:\tlearn: 0.0040805\ttotal: 6.13s\tremaining: 3.84s\n",
      "615:\tlearn: 0.0040613\ttotal: 6.14s\tremaining: 3.83s\n",
      "616:\tlearn: 0.0040541\ttotal: 6.15s\tremaining: 3.82s\n",
      "617:\tlearn: 0.0040419\ttotal: 6.16s\tremaining: 3.81s\n",
      "618:\tlearn: 0.0040216\ttotal: 6.17s\tremaining: 3.8s\n",
      "619:\tlearn: 0.0040084\ttotal: 6.18s\tremaining: 3.79s\n",
      "620:\tlearn: 0.0040033\ttotal: 6.19s\tremaining: 3.78s\n",
      "621:\tlearn: 0.0039982\ttotal: 6.2s\tremaining: 3.77s\n",
      "622:\tlearn: 0.0039833\ttotal: 6.21s\tremaining: 3.76s\n",
      "623:\tlearn: 0.0039729\ttotal: 6.22s\tremaining: 3.75s\n",
      "624:\tlearn: 0.0039558\ttotal: 6.23s\tremaining: 3.74s\n",
      "625:\tlearn: 0.0039409\ttotal: 6.24s\tremaining: 3.73s\n",
      "626:\tlearn: 0.0039302\ttotal: 6.25s\tremaining: 3.72s\n",
      "627:\tlearn: 0.0039251\ttotal: 6.27s\tremaining: 3.71s\n",
      "628:\tlearn: 0.0039202\ttotal: 6.28s\tremaining: 3.7s\n",
      "629:\tlearn: 0.0039114\ttotal: 6.29s\tremaining: 3.69s\n",
      "630:\tlearn: 0.0039060\ttotal: 6.3s\tremaining: 3.68s\n",
      "631:\tlearn: 0.0038974\ttotal: 6.31s\tremaining: 3.67s\n",
      "632:\tlearn: 0.0038856\ttotal: 6.32s\tremaining: 3.67s\n",
      "633:\tlearn: 0.0038754\ttotal: 6.33s\tremaining: 3.65s\n",
      "634:\tlearn: 0.0038624\ttotal: 6.34s\tremaining: 3.65s\n",
      "635:\tlearn: 0.0038521\ttotal: 6.35s\tremaining: 3.63s\n",
      "636:\tlearn: 0.0038390\ttotal: 6.36s\tremaining: 3.62s\n",
      "637:\tlearn: 0.0038289\ttotal: 6.37s\tremaining: 3.61s\n",
      "638:\tlearn: 0.0038217\ttotal: 6.38s\tremaining: 3.6s\n",
      "639:\tlearn: 0.0038064\ttotal: 6.39s\tremaining: 3.59s\n",
      "640:\tlearn: 0.0037874\ttotal: 6.39s\tremaining: 3.58s\n",
      "641:\tlearn: 0.0037825\ttotal: 6.4s\tremaining: 3.57s\n",
      "642:\tlearn: 0.0037742\ttotal: 6.42s\tremaining: 3.56s\n",
      "643:\tlearn: 0.0037704\ttotal: 6.43s\tremaining: 3.55s\n",
      "644:\tlearn: 0.0037383\ttotal: 6.44s\tremaining: 3.54s\n",
      "645:\tlearn: 0.0037230\ttotal: 6.44s\tremaining: 3.53s\n",
      "646:\tlearn: 0.0037060\ttotal: 6.45s\tremaining: 3.52s\n",
      "647:\tlearn: 0.0036957\ttotal: 6.46s\tremaining: 3.51s\n",
      "648:\tlearn: 0.0036834\ttotal: 6.47s\tremaining: 3.5s\n",
      "649:\tlearn: 0.0036731\ttotal: 6.49s\tremaining: 3.49s\n",
      "650:\tlearn: 0.0036658\ttotal: 6.5s\tremaining: 3.48s\n",
      "651:\tlearn: 0.0036513\ttotal: 6.5s\tremaining: 3.47s\n",
      "652:\tlearn: 0.0036258\ttotal: 6.51s\tremaining: 3.46s\n",
      "653:\tlearn: 0.0036140\ttotal: 6.53s\tremaining: 3.45s\n",
      "654:\tlearn: 0.0036063\ttotal: 6.54s\tremaining: 3.44s\n",
      "655:\tlearn: 0.0036011\ttotal: 6.54s\tremaining: 3.43s\n",
      "656:\tlearn: 0.0035849\ttotal: 6.55s\tremaining: 3.42s\n",
      "657:\tlearn: 0.0035754\ttotal: 6.56s\tremaining: 3.41s\n",
      "658:\tlearn: 0.0035575\ttotal: 6.57s\tremaining: 3.4s\n",
      "659:\tlearn: 0.0035520\ttotal: 6.58s\tremaining: 3.39s\n",
      "660:\tlearn: 0.0035460\ttotal: 6.59s\tremaining: 3.38s\n",
      "661:\tlearn: 0.0035344\ttotal: 6.6s\tremaining: 3.37s\n",
      "662:\tlearn: 0.0035278\ttotal: 6.61s\tremaining: 3.36s\n",
      "663:\tlearn: 0.0035223\ttotal: 6.62s\tremaining: 3.35s\n",
      "664:\tlearn: 0.0035089\ttotal: 6.63s\tremaining: 3.34s\n",
      "665:\tlearn: 0.0034933\ttotal: 6.64s\tremaining: 3.33s\n",
      "666:\tlearn: 0.0034821\ttotal: 6.65s\tremaining: 3.32s\n",
      "667:\tlearn: 0.0034750\ttotal: 6.66s\tremaining: 3.31s\n",
      "668:\tlearn: 0.0034677\ttotal: 6.68s\tremaining: 3.3s\n",
      "669:\tlearn: 0.0034376\ttotal: 6.68s\tremaining: 3.29s\n",
      "670:\tlearn: 0.0034265\ttotal: 6.69s\tremaining: 3.28s\n",
      "671:\tlearn: 0.0034171\ttotal: 6.7s\tremaining: 3.27s\n",
      "672:\tlearn: 0.0034026\ttotal: 6.71s\tremaining: 3.26s\n",
      "673:\tlearn: 0.0033937\ttotal: 6.72s\tremaining: 3.25s\n",
      "674:\tlearn: 0.0033860\ttotal: 6.73s\tremaining: 3.24s\n",
      "675:\tlearn: 0.0033764\ttotal: 6.74s\tremaining: 3.23s\n",
      "676:\tlearn: 0.0033669\ttotal: 6.76s\tremaining: 3.22s\n",
      "677:\tlearn: 0.0033556\ttotal: 6.77s\tremaining: 3.22s\n",
      "678:\tlearn: 0.0033498\ttotal: 6.78s\tremaining: 3.21s\n",
      "679:\tlearn: 0.0033388\ttotal: 6.79s\tremaining: 3.2s\n",
      "680:\tlearn: 0.0033322\ttotal: 6.81s\tremaining: 3.19s\n",
      "681:\tlearn: 0.0033231\ttotal: 6.82s\tremaining: 3.18s\n",
      "682:\tlearn: 0.0033164\ttotal: 6.83s\tremaining: 3.17s\n",
      "683:\tlearn: 0.0033025\ttotal: 6.85s\tremaining: 3.16s\n",
      "684:\tlearn: 0.0032958\ttotal: 6.86s\tremaining: 3.15s\n",
      "685:\tlearn: 0.0032915\ttotal: 6.86s\tremaining: 3.14s\n",
      "686:\tlearn: 0.0032825\ttotal: 6.88s\tremaining: 3.13s\n",
      "687:\tlearn: 0.0032654\ttotal: 6.88s\tremaining: 3.12s\n",
      "688:\tlearn: 0.0032619\ttotal: 6.9s\tremaining: 3.11s\n",
      "689:\tlearn: 0.0032565\ttotal: 6.91s\tremaining: 3.1s\n",
      "690:\tlearn: 0.0032507\ttotal: 6.92s\tremaining: 3.09s\n",
      "691:\tlearn: 0.0032471\ttotal: 6.92s\tremaining: 3.08s\n",
      "692:\tlearn: 0.0032446\ttotal: 6.93s\tremaining: 3.07s\n",
      "693:\tlearn: 0.0032375\ttotal: 6.94s\tremaining: 3.06s\n",
      "694:\tlearn: 0.0032319\ttotal: 6.95s\tremaining: 3.05s\n",
      "695:\tlearn: 0.0032178\ttotal: 6.96s\tremaining: 3.04s\n",
      "696:\tlearn: 0.0032106\ttotal: 6.97s\tremaining: 3.03s\n",
      "697:\tlearn: 0.0032036\ttotal: 6.98s\tremaining: 3.02s\n",
      "698:\tlearn: 0.0031997\ttotal: 6.99s\tremaining: 3.01s\n",
      "699:\tlearn: 0.0031929\ttotal: 7s\tremaining: 3s\n",
      "700:\tlearn: 0.0031870\ttotal: 7.01s\tremaining: 2.99s\n",
      "701:\tlearn: 0.0031802\ttotal: 7.02s\tremaining: 2.98s\n",
      "702:\tlearn: 0.0031761\ttotal: 7.04s\tremaining: 2.97s\n",
      "703:\tlearn: 0.0031677\ttotal: 7.05s\tremaining: 2.96s\n",
      "704:\tlearn: 0.0031592\ttotal: 7.06s\tremaining: 2.95s\n",
      "705:\tlearn: 0.0031454\ttotal: 7.07s\tremaining: 2.94s\n",
      "706:\tlearn: 0.0031328\ttotal: 7.08s\tremaining: 2.93s\n",
      "707:\tlearn: 0.0031210\ttotal: 7.09s\tremaining: 2.92s\n",
      "708:\tlearn: 0.0031158\ttotal: 7.1s\tremaining: 2.91s\n",
      "709:\tlearn: 0.0031092\ttotal: 7.11s\tremaining: 2.9s\n",
      "710:\tlearn: 0.0031047\ttotal: 7.12s\tremaining: 2.89s\n",
      "711:\tlearn: 0.0030985\ttotal: 7.12s\tremaining: 2.88s\n",
      "712:\tlearn: 0.0030945\ttotal: 7.13s\tremaining: 2.87s\n",
      "713:\tlearn: 0.0030813\ttotal: 7.14s\tremaining: 2.86s\n",
      "714:\tlearn: 0.0030756\ttotal: 7.15s\tremaining: 2.85s\n",
      "715:\tlearn: 0.0030713\ttotal: 7.16s\tremaining: 2.84s\n",
      "716:\tlearn: 0.0030653\ttotal: 7.17s\tremaining: 2.83s\n",
      "717:\tlearn: 0.0030611\ttotal: 7.18s\tremaining: 2.82s\n",
      "718:\tlearn: 0.0030466\ttotal: 7.19s\tremaining: 2.81s\n",
      "719:\tlearn: 0.0030347\ttotal: 7.21s\tremaining: 2.8s\n",
      "720:\tlearn: 0.0030312\ttotal: 7.23s\tremaining: 2.8s\n",
      "721:\tlearn: 0.0030207\ttotal: 7.24s\tremaining: 2.79s\n",
      "722:\tlearn: 0.0030143\ttotal: 7.24s\tremaining: 2.77s\n",
      "723:\tlearn: 0.0030051\ttotal: 7.25s\tremaining: 2.77s\n",
      "724:\tlearn: 0.0029980\ttotal: 7.26s\tremaining: 2.75s\n",
      "725:\tlearn: 0.0029939\ttotal: 7.27s\tremaining: 2.74s\n",
      "726:\tlearn: 0.0029867\ttotal: 7.28s\tremaining: 2.73s\n",
      "727:\tlearn: 0.0029782\ttotal: 7.29s\tremaining: 2.72s\n",
      "728:\tlearn: 0.0029749\ttotal: 7.3s\tremaining: 2.71s\n",
      "729:\tlearn: 0.0029693\ttotal: 7.31s\tremaining: 2.7s\n",
      "730:\tlearn: 0.0029593\ttotal: 7.32s\tremaining: 2.69s\n",
      "731:\tlearn: 0.0029508\ttotal: 7.33s\tremaining: 2.68s\n",
      "732:\tlearn: 0.0029466\ttotal: 7.34s\tremaining: 2.67s\n",
      "733:\tlearn: 0.0029412\ttotal: 7.35s\tremaining: 2.66s\n",
      "734:\tlearn: 0.0029308\ttotal: 7.36s\tremaining: 2.65s\n",
      "735:\tlearn: 0.0029287\ttotal: 7.37s\tremaining: 2.64s\n",
      "736:\tlearn: 0.0029214\ttotal: 7.38s\tremaining: 2.63s\n",
      "737:\tlearn: 0.0029197\ttotal: 7.39s\tremaining: 2.62s\n",
      "738:\tlearn: 0.0029154\ttotal: 7.4s\tremaining: 2.61s\n",
      "739:\tlearn: 0.0029119\ttotal: 7.41s\tremaining: 2.6s\n",
      "740:\tlearn: 0.0029050\ttotal: 7.42s\tremaining: 2.59s\n",
      "741:\tlearn: 0.0028990\ttotal: 7.42s\tremaining: 2.58s\n",
      "742:\tlearn: 0.0028912\ttotal: 7.43s\tremaining: 2.57s\n",
      "743:\tlearn: 0.0028872\ttotal: 7.44s\tremaining: 2.56s\n",
      "744:\tlearn: 0.0028816\ttotal: 7.45s\tremaining: 2.55s\n",
      "745:\tlearn: 0.0028765\ttotal: 7.46s\tremaining: 2.54s\n",
      "746:\tlearn: 0.0028649\ttotal: 7.47s\tremaining: 2.53s\n",
      "747:\tlearn: 0.0028597\ttotal: 7.48s\tremaining: 2.52s\n",
      "748:\tlearn: 0.0028532\ttotal: 7.49s\tremaining: 2.51s\n",
      "749:\tlearn: 0.0028474\ttotal: 7.5s\tremaining: 2.5s\n",
      "750:\tlearn: 0.0028455\ttotal: 7.51s\tremaining: 2.49s\n",
      "751:\tlearn: 0.0028424\ttotal: 7.52s\tremaining: 2.48s\n",
      "752:\tlearn: 0.0028360\ttotal: 7.53s\tremaining: 2.47s\n",
      "753:\tlearn: 0.0028332\ttotal: 7.54s\tremaining: 2.46s\n",
      "754:\tlearn: 0.0028263\ttotal: 7.54s\tremaining: 2.45s\n",
      "755:\tlearn: 0.0028239\ttotal: 7.55s\tremaining: 2.44s\n",
      "756:\tlearn: 0.0028099\ttotal: 7.56s\tremaining: 2.43s\n",
      "757:\tlearn: 0.0028014\ttotal: 7.57s\tremaining: 2.42s\n",
      "758:\tlearn: 0.0027945\ttotal: 7.58s\tremaining: 2.41s\n",
      "759:\tlearn: 0.0027909\ttotal: 7.59s\tremaining: 2.4s\n",
      "760:\tlearn: 0.0027831\ttotal: 7.6s\tremaining: 2.39s\n",
      "761:\tlearn: 0.0027764\ttotal: 7.61s\tremaining: 2.38s\n",
      "762:\tlearn: 0.0027741\ttotal: 7.62s\tremaining: 2.37s\n",
      "763:\tlearn: 0.0027704\ttotal: 7.63s\tremaining: 2.36s\n",
      "764:\tlearn: 0.0027642\ttotal: 7.64s\tremaining: 2.35s\n",
      "765:\tlearn: 0.0027559\ttotal: 7.65s\tremaining: 2.34s\n",
      "766:\tlearn: 0.0027494\ttotal: 7.66s\tremaining: 2.33s\n",
      "767:\tlearn: 0.0027451\ttotal: 7.67s\tremaining: 2.31s\n",
      "768:\tlearn: 0.0027381\ttotal: 7.67s\tremaining: 2.31s\n",
      "769:\tlearn: 0.0027289\ttotal: 7.68s\tremaining: 2.29s\n",
      "770:\tlearn: 0.0027164\ttotal: 7.69s\tremaining: 2.28s\n",
      "771:\tlearn: 0.0027104\ttotal: 7.7s\tremaining: 2.27s\n",
      "772:\tlearn: 0.0027023\ttotal: 7.71s\tremaining: 2.26s\n",
      "773:\tlearn: 0.0026936\ttotal: 7.72s\tremaining: 2.25s\n",
      "774:\tlearn: 0.0026871\ttotal: 7.73s\tremaining: 2.24s\n",
      "775:\tlearn: 0.0026725\ttotal: 7.74s\tremaining: 2.23s\n",
      "776:\tlearn: 0.0026670\ttotal: 7.75s\tremaining: 2.22s\n",
      "777:\tlearn: 0.0026565\ttotal: 7.75s\tremaining: 2.21s\n",
      "778:\tlearn: 0.0026488\ttotal: 7.76s\tremaining: 2.2s\n",
      "779:\tlearn: 0.0026374\ttotal: 7.78s\tremaining: 2.19s\n",
      "780:\tlearn: 0.0026316\ttotal: 7.79s\tremaining: 2.18s\n",
      "781:\tlearn: 0.0026280\ttotal: 7.79s\tremaining: 2.17s\n",
      "782:\tlearn: 0.0026257\ttotal: 7.8s\tremaining: 2.16s\n",
      "783:\tlearn: 0.0026218\ttotal: 7.81s\tremaining: 2.15s\n",
      "784:\tlearn: 0.0026160\ttotal: 7.82s\tremaining: 2.14s\n",
      "785:\tlearn: 0.0026099\ttotal: 7.83s\tremaining: 2.13s\n",
      "786:\tlearn: 0.0026050\ttotal: 7.84s\tremaining: 2.12s\n",
      "787:\tlearn: 0.0025888\ttotal: 7.84s\tremaining: 2.11s\n",
      "788:\tlearn: 0.0025813\ttotal: 7.85s\tremaining: 2.1s\n",
      "789:\tlearn: 0.0025791\ttotal: 7.86s\tremaining: 2.09s\n",
      "790:\tlearn: 0.0025718\ttotal: 7.87s\tremaining: 2.08s\n",
      "791:\tlearn: 0.0025677\ttotal: 7.88s\tremaining: 2.07s\n",
      "792:\tlearn: 0.0025654\ttotal: 7.89s\tremaining: 2.06s\n",
      "793:\tlearn: 0.0025538\ttotal: 7.9s\tremaining: 2.05s\n",
      "794:\tlearn: 0.0025501\ttotal: 7.91s\tremaining: 2.04s\n",
      "795:\tlearn: 0.0025423\ttotal: 7.92s\tremaining: 2.03s\n",
      "796:\tlearn: 0.0025376\ttotal: 7.92s\tremaining: 2.02s\n",
      "797:\tlearn: 0.0025306\ttotal: 7.93s\tremaining: 2.01s\n",
      "798:\tlearn: 0.0025265\ttotal: 7.94s\tremaining: 2s\n",
      "799:\tlearn: 0.0025241\ttotal: 7.95s\tremaining: 1.99s\n",
      "800:\tlearn: 0.0025171\ttotal: 7.96s\tremaining: 1.98s\n",
      "801:\tlearn: 0.0025118\ttotal: 7.97s\tremaining: 1.97s\n",
      "802:\tlearn: 0.0025044\ttotal: 7.98s\tremaining: 1.96s\n",
      "803:\tlearn: 0.0025012\ttotal: 7.99s\tremaining: 1.95s\n",
      "804:\tlearn: 0.0024986\ttotal: 8s\tremaining: 1.94s\n",
      "805:\tlearn: 0.0024921\ttotal: 8s\tremaining: 1.93s\n",
      "806:\tlearn: 0.0024851\ttotal: 8.01s\tremaining: 1.92s\n",
      "807:\tlearn: 0.0024792\ttotal: 8.02s\tremaining: 1.91s\n",
      "808:\tlearn: 0.0024747\ttotal: 8.03s\tremaining: 1.9s\n",
      "809:\tlearn: 0.0024654\ttotal: 8.04s\tremaining: 1.89s\n",
      "810:\tlearn: 0.0024616\ttotal: 8.05s\tremaining: 1.88s\n",
      "811:\tlearn: 0.0024492\ttotal: 8.06s\tremaining: 1.87s\n",
      "812:\tlearn: 0.0024420\ttotal: 8.07s\tremaining: 1.85s\n",
      "813:\tlearn: 0.0024398\ttotal: 8.08s\tremaining: 1.84s\n",
      "814:\tlearn: 0.0024308\ttotal: 8.09s\tremaining: 1.83s\n",
      "815:\tlearn: 0.0024218\ttotal: 8.09s\tremaining: 1.82s\n",
      "816:\tlearn: 0.0024146\ttotal: 8.1s\tremaining: 1.81s\n",
      "817:\tlearn: 0.0024094\ttotal: 8.11s\tremaining: 1.8s\n",
      "818:\tlearn: 0.0024067\ttotal: 8.12s\tremaining: 1.79s\n",
      "819:\tlearn: 0.0024029\ttotal: 8.13s\tremaining: 1.78s\n",
      "820:\tlearn: 0.0023994\ttotal: 8.14s\tremaining: 1.77s\n",
      "821:\tlearn: 0.0023931\ttotal: 8.15s\tremaining: 1.76s\n",
      "822:\tlearn: 0.0023904\ttotal: 8.16s\tremaining: 1.75s\n",
      "823:\tlearn: 0.0023888\ttotal: 8.16s\tremaining: 1.74s\n",
      "824:\tlearn: 0.0023859\ttotal: 8.17s\tremaining: 1.73s\n",
      "825:\tlearn: 0.0023805\ttotal: 8.18s\tremaining: 1.72s\n",
      "826:\tlearn: 0.0023732\ttotal: 8.19s\tremaining: 1.71s\n",
      "827:\tlearn: 0.0023696\ttotal: 8.2s\tremaining: 1.7s\n",
      "828:\tlearn: 0.0023646\ttotal: 8.21s\tremaining: 1.69s\n",
      "829:\tlearn: 0.0023618\ttotal: 8.22s\tremaining: 1.68s\n",
      "830:\tlearn: 0.0023537\ttotal: 8.24s\tremaining: 1.68s\n",
      "831:\tlearn: 0.0023483\ttotal: 8.25s\tremaining: 1.67s\n",
      "832:\tlearn: 0.0023461\ttotal: 8.26s\tremaining: 1.66s\n",
      "833:\tlearn: 0.0023379\ttotal: 8.27s\tremaining: 1.65s\n",
      "834:\tlearn: 0.0023352\ttotal: 8.28s\tremaining: 1.64s\n",
      "835:\tlearn: 0.0023304\ttotal: 8.29s\tremaining: 1.63s\n",
      "836:\tlearn: 0.0023251\ttotal: 8.29s\tremaining: 1.61s\n",
      "837:\tlearn: 0.0023198\ttotal: 8.3s\tremaining: 1.6s\n",
      "838:\tlearn: 0.0023146\ttotal: 8.31s\tremaining: 1.59s\n",
      "839:\tlearn: 0.0023125\ttotal: 8.32s\tremaining: 1.58s\n",
      "840:\tlearn: 0.0023092\ttotal: 8.33s\tremaining: 1.57s\n",
      "841:\tlearn: 0.0023055\ttotal: 8.34s\tremaining: 1.56s\n",
      "842:\tlearn: 0.0022993\ttotal: 8.35s\tremaining: 1.55s\n",
      "843:\tlearn: 0.0022946\ttotal: 8.36s\tremaining: 1.54s\n",
      "844:\tlearn: 0.0022912\ttotal: 8.37s\tremaining: 1.53s\n",
      "845:\tlearn: 0.0022886\ttotal: 8.38s\tremaining: 1.52s\n",
      "846:\tlearn: 0.0022853\ttotal: 8.4s\tremaining: 1.52s\n",
      "847:\tlearn: 0.0022792\ttotal: 8.41s\tremaining: 1.51s\n",
      "848:\tlearn: 0.0022731\ttotal: 8.43s\tremaining: 1.5s\n",
      "849:\tlearn: 0.0022688\ttotal: 8.44s\tremaining: 1.49s\n",
      "850:\tlearn: 0.0022658\ttotal: 8.45s\tremaining: 1.48s\n",
      "851:\tlearn: 0.0022587\ttotal: 8.46s\tremaining: 1.47s\n",
      "852:\tlearn: 0.0022549\ttotal: 8.47s\tremaining: 1.46s\n",
      "853:\tlearn: 0.0022528\ttotal: 8.48s\tremaining: 1.45s\n",
      "854:\tlearn: 0.0022513\ttotal: 8.48s\tremaining: 1.44s\n",
      "855:\tlearn: 0.0022499\ttotal: 8.49s\tremaining: 1.43s\n",
      "856:\tlearn: 0.0022463\ttotal: 8.5s\tremaining: 1.42s\n",
      "857:\tlearn: 0.0022418\ttotal: 8.51s\tremaining: 1.41s\n",
      "858:\tlearn: 0.0022388\ttotal: 8.52s\tremaining: 1.4s\n",
      "859:\tlearn: 0.0022353\ttotal: 8.53s\tremaining: 1.39s\n",
      "860:\tlearn: 0.0022328\ttotal: 8.54s\tremaining: 1.38s\n",
      "861:\tlearn: 0.0022251\ttotal: 8.54s\tremaining: 1.37s\n",
      "862:\tlearn: 0.0022149\ttotal: 8.55s\tremaining: 1.36s\n",
      "863:\tlearn: 0.0022108\ttotal: 8.56s\tremaining: 1.35s\n",
      "864:\tlearn: 0.0022040\ttotal: 8.57s\tremaining: 1.34s\n",
      "865:\tlearn: 0.0021913\ttotal: 8.58s\tremaining: 1.33s\n",
      "866:\tlearn: 0.0021850\ttotal: 8.59s\tremaining: 1.32s\n",
      "867:\tlearn: 0.0021840\ttotal: 8.6s\tremaining: 1.31s\n",
      "868:\tlearn: 0.0021790\ttotal: 8.61s\tremaining: 1.3s\n",
      "869:\tlearn: 0.0021763\ttotal: 8.62s\tremaining: 1.29s\n",
      "870:\tlearn: 0.0021608\ttotal: 8.63s\tremaining: 1.28s\n",
      "871:\tlearn: 0.0021581\ttotal: 8.64s\tremaining: 1.27s\n",
      "872:\tlearn: 0.0021537\ttotal: 8.65s\tremaining: 1.26s\n",
      "873:\tlearn: 0.0021488\ttotal: 8.66s\tremaining: 1.25s\n",
      "874:\tlearn: 0.0021483\ttotal: 8.67s\tremaining: 1.24s\n",
      "875:\tlearn: 0.0021418\ttotal: 8.68s\tremaining: 1.23s\n",
      "876:\tlearn: 0.0021368\ttotal: 8.68s\tremaining: 1.22s\n",
      "877:\tlearn: 0.0021353\ttotal: 8.69s\tremaining: 1.21s\n",
      "878:\tlearn: 0.0021327\ttotal: 8.7s\tremaining: 1.2s\n",
      "879:\tlearn: 0.0021272\ttotal: 8.71s\tremaining: 1.19s\n",
      "880:\tlearn: 0.0021217\ttotal: 8.72s\tremaining: 1.18s\n",
      "881:\tlearn: 0.0021172\ttotal: 8.73s\tremaining: 1.17s\n",
      "882:\tlearn: 0.0021123\ttotal: 8.73s\tremaining: 1.16s\n",
      "883:\tlearn: 0.0021090\ttotal: 8.74s\tremaining: 1.15s\n",
      "884:\tlearn: 0.0021052\ttotal: 8.75s\tremaining: 1.14s\n",
      "885:\tlearn: 0.0020929\ttotal: 8.76s\tremaining: 1.13s\n",
      "886:\tlearn: 0.0020876\ttotal: 8.77s\tremaining: 1.12s\n",
      "887:\tlearn: 0.0020810\ttotal: 8.78s\tremaining: 1.11s\n",
      "888:\tlearn: 0.0020737\ttotal: 8.79s\tremaining: 1.1s\n",
      "889:\tlearn: 0.0020714\ttotal: 8.8s\tremaining: 1.09s\n",
      "890:\tlearn: 0.0020693\ttotal: 8.81s\tremaining: 1.08s\n",
      "891:\tlearn: 0.0020640\ttotal: 8.81s\tremaining: 1.07s\n",
      "892:\tlearn: 0.0020560\ttotal: 8.82s\tremaining: 1.06s\n",
      "893:\tlearn: 0.0020535\ttotal: 8.83s\tremaining: 1.05s\n",
      "894:\tlearn: 0.0020499\ttotal: 8.84s\tremaining: 1.04s\n",
      "895:\tlearn: 0.0020417\ttotal: 8.85s\tremaining: 1.03s\n",
      "896:\tlearn: 0.0020303\ttotal: 8.86s\tremaining: 1.02s\n",
      "897:\tlearn: 0.0020285\ttotal: 8.87s\tremaining: 1.01s\n",
      "898:\tlearn: 0.0020255\ttotal: 8.88s\tremaining: 997ms\n",
      "899:\tlearn: 0.0020175\ttotal: 8.88s\tremaining: 987ms\n",
      "900:\tlearn: 0.0020128\ttotal: 8.89s\tremaining: 977ms\n",
      "901:\tlearn: 0.0020114\ttotal: 8.9s\tremaining: 967ms\n",
      "902:\tlearn: 0.0020072\ttotal: 8.91s\tremaining: 958ms\n",
      "903:\tlearn: 0.0020026\ttotal: 8.93s\tremaining: 948ms\n",
      "904:\tlearn: 0.0019975\ttotal: 8.93s\tremaining: 938ms\n",
      "905:\tlearn: 0.0019950\ttotal: 8.94s\tremaining: 928ms\n",
      "906:\tlearn: 0.0019865\ttotal: 8.96s\tremaining: 918ms\n",
      "907:\tlearn: 0.0019792\ttotal: 8.96s\tremaining: 908ms\n",
      "908:\tlearn: 0.0019719\ttotal: 8.97s\tremaining: 898ms\n",
      "909:\tlearn: 0.0019658\ttotal: 8.98s\tremaining: 888ms\n",
      "910:\tlearn: 0.0019614\ttotal: 8.99s\tremaining: 879ms\n",
      "911:\tlearn: 0.0019596\ttotal: 9s\tremaining: 868ms\n",
      "912:\tlearn: 0.0019519\ttotal: 9.01s\tremaining: 859ms\n",
      "913:\tlearn: 0.0019504\ttotal: 9.03s\tremaining: 849ms\n",
      "914:\tlearn: 0.0019449\ttotal: 9.04s\tremaining: 840ms\n",
      "915:\tlearn: 0.0019383\ttotal: 9.05s\tremaining: 830ms\n",
      "916:\tlearn: 0.0019338\ttotal: 9.06s\tremaining: 820ms\n",
      "917:\tlearn: 0.0019277\ttotal: 9.07s\tremaining: 810ms\n",
      "918:\tlearn: 0.0019242\ttotal: 9.08s\tremaining: 800ms\n",
      "919:\tlearn: 0.0019214\ttotal: 9.09s\tremaining: 791ms\n",
      "920:\tlearn: 0.0019158\ttotal: 9.1s\tremaining: 781ms\n",
      "921:\tlearn: 0.0019088\ttotal: 9.11s\tremaining: 771ms\n",
      "922:\tlearn: 0.0019028\ttotal: 9.12s\tremaining: 761ms\n",
      "923:\tlearn: 0.0019008\ttotal: 9.13s\tremaining: 751ms\n",
      "924:\tlearn: 0.0018942\ttotal: 9.15s\tremaining: 742ms\n",
      "925:\tlearn: 0.0018920\ttotal: 9.16s\tremaining: 732ms\n",
      "926:\tlearn: 0.0018894\ttotal: 9.17s\tremaining: 722ms\n",
      "927:\tlearn: 0.0018840\ttotal: 9.18s\tremaining: 712ms\n",
      "928:\tlearn: 0.0018787\ttotal: 9.19s\tremaining: 702ms\n",
      "929:\tlearn: 0.0018745\ttotal: 9.19s\tremaining: 692ms\n",
      "930:\tlearn: 0.0018727\ttotal: 9.2s\tremaining: 682ms\n",
      "931:\tlearn: 0.0018716\ttotal: 9.21s\tremaining: 672ms\n",
      "932:\tlearn: 0.0018667\ttotal: 9.22s\tremaining: 662ms\n",
      "933:\tlearn: 0.0018633\ttotal: 9.23s\tremaining: 652ms\n",
      "934:\tlearn: 0.0018589\ttotal: 9.25s\tremaining: 643ms\n",
      "935:\tlearn: 0.0018572\ttotal: 9.26s\tremaining: 633ms\n",
      "936:\tlearn: 0.0018492\ttotal: 9.27s\tremaining: 623ms\n",
      "937:\tlearn: 0.0018477\ttotal: 9.28s\tremaining: 613ms\n",
      "938:\tlearn: 0.0018441\ttotal: 9.28s\tremaining: 603ms\n",
      "939:\tlearn: 0.0018411\ttotal: 9.29s\tremaining: 593ms\n",
      "940:\tlearn: 0.0018390\ttotal: 9.3s\tremaining: 583ms\n",
      "941:\tlearn: 0.0018364\ttotal: 9.31s\tremaining: 573ms\n",
      "942:\tlearn: 0.0018313\ttotal: 9.32s\tremaining: 563ms\n",
      "943:\tlearn: 0.0018261\ttotal: 9.33s\tremaining: 553ms\n",
      "944:\tlearn: 0.0018250\ttotal: 9.34s\tremaining: 543ms\n",
      "945:\tlearn: 0.0018222\ttotal: 9.35s\tremaining: 534ms\n",
      "946:\tlearn: 0.0018196\ttotal: 9.36s\tremaining: 524ms\n",
      "947:\tlearn: 0.0018129\ttotal: 9.37s\tremaining: 514ms\n",
      "948:\tlearn: 0.0018083\ttotal: 9.38s\tremaining: 504ms\n",
      "949:\tlearn: 0.0018040\ttotal: 9.39s\tremaining: 494ms\n",
      "950:\tlearn: 0.0017989\ttotal: 9.4s\tremaining: 484ms\n",
      "951:\tlearn: 0.0017977\ttotal: 9.42s\tremaining: 475ms\n",
      "952:\tlearn: 0.0017958\ttotal: 9.43s\tremaining: 465ms\n",
      "953:\tlearn: 0.0017939\ttotal: 9.44s\tremaining: 455ms\n",
      "954:\tlearn: 0.0017928\ttotal: 9.45s\tremaining: 445ms\n",
      "955:\tlearn: 0.0017917\ttotal: 9.46s\tremaining: 435ms\n",
      "956:\tlearn: 0.0017897\ttotal: 9.48s\tremaining: 426ms\n",
      "957:\tlearn: 0.0017861\ttotal: 9.49s\tremaining: 416ms\n",
      "958:\tlearn: 0.0017837\ttotal: 9.5s\tremaining: 406ms\n",
      "959:\tlearn: 0.0017815\ttotal: 9.51s\tremaining: 396ms\n",
      "960:\tlearn: 0.0017787\ttotal: 9.52s\tremaining: 386ms\n",
      "961:\tlearn: 0.0017765\ttotal: 9.53s\tremaining: 376ms\n",
      "962:\tlearn: 0.0017729\ttotal: 9.54s\tremaining: 366ms\n",
      "963:\tlearn: 0.0017668\ttotal: 9.55s\tremaining: 357ms\n",
      "964:\tlearn: 0.0017629\ttotal: 9.55s\tremaining: 347ms\n",
      "965:\tlearn: 0.0017595\ttotal: 9.56s\tremaining: 337ms\n",
      "966:\tlearn: 0.0017582\ttotal: 9.57s\tremaining: 327ms\n",
      "967:\tlearn: 0.0017527\ttotal: 9.58s\tremaining: 317ms\n",
      "968:\tlearn: 0.0017498\ttotal: 9.59s\tremaining: 307ms\n",
      "969:\tlearn: 0.0017467\ttotal: 9.6s\tremaining: 297ms\n",
      "970:\tlearn: 0.0017412\ttotal: 9.61s\tremaining: 287ms\n",
      "971:\tlearn: 0.0017373\ttotal: 9.62s\tremaining: 277ms\n",
      "972:\tlearn: 0.0017320\ttotal: 9.63s\tremaining: 267ms\n",
      "973:\tlearn: 0.0017299\ttotal: 9.64s\tremaining: 257ms\n",
      "974:\tlearn: 0.0017231\ttotal: 9.65s\tremaining: 247ms\n",
      "975:\tlearn: 0.0017202\ttotal: 9.66s\tremaining: 237ms\n",
      "976:\tlearn: 0.0017170\ttotal: 9.67s\tremaining: 228ms\n",
      "977:\tlearn: 0.0017104\ttotal: 9.68s\tremaining: 218ms\n",
      "978:\tlearn: 0.0017069\ttotal: 9.68s\tremaining: 208ms\n",
      "979:\tlearn: 0.0017047\ttotal: 9.69s\tremaining: 198ms\n",
      "980:\tlearn: 0.0016985\ttotal: 9.7s\tremaining: 188ms\n",
      "981:\tlearn: 0.0016941\ttotal: 9.71s\tremaining: 178ms\n",
      "982:\tlearn: 0.0016917\ttotal: 9.72s\tremaining: 168ms\n",
      "983:\tlearn: 0.0016898\ttotal: 9.73s\tremaining: 158ms\n",
      "984:\tlearn: 0.0016874\ttotal: 9.74s\tremaining: 148ms\n",
      "985:\tlearn: 0.0016845\ttotal: 9.76s\tremaining: 139ms\n",
      "986:\tlearn: 0.0016832\ttotal: 9.77s\tremaining: 129ms\n",
      "987:\tlearn: 0.0016806\ttotal: 9.78s\tremaining: 119ms\n",
      "988:\tlearn: 0.0016794\ttotal: 9.78s\tremaining: 109ms\n",
      "989:\tlearn: 0.0016755\ttotal: 9.79s\tremaining: 98.9ms\n",
      "990:\tlearn: 0.0016732\ttotal: 9.8s\tremaining: 89ms\n",
      "991:\tlearn: 0.0016718\ttotal: 9.81s\tremaining: 79.1ms\n",
      "992:\tlearn: 0.0016698\ttotal: 9.82s\tremaining: 69.2ms\n",
      "993:\tlearn: 0.0016646\ttotal: 9.83s\tremaining: 59.3ms\n",
      "994:\tlearn: 0.0016618\ttotal: 9.84s\tremaining: 49.5ms\n",
      "995:\tlearn: 0.0016580\ttotal: 9.85s\tremaining: 39.6ms\n",
      "996:\tlearn: 0.0016569\ttotal: 9.86s\tremaining: 29.7ms\n",
      "997:\tlearn: 0.0016528\ttotal: 9.87s\tremaining: 19.8ms\n",
      "998:\tlearn: 0.0016496\ttotal: 9.88s\tremaining: 9.89ms\n",
      "999:\tlearn: 0.0016470\ttotal: 9.88s\tremaining: 0us\n"
     ]
    }
   ],
   "source": [
    "# Create DataFrames to store the results\n",
    "train_results = pd.DataFrame(columns=['Model', 'F1 Score', 'ROC AUC', 'Accuracy'])\n",
    "test_results = pd.DataFrame(columns=['Model', 'F1 Score', 'ROC AUC', 'Accuracy'])\n",
    "\n",
    "# Train and evaluate models\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Training {model_name}...\")\n",
    "\n",
    "    model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "    train_pred = model.predict(X_train_resampled)\n",
    "    test_pred = model.predict(X_test_preprocessed)\n",
    "\n",
    "    # Use predicted probabilities for ROC AUC\n",
    "    train_proba = model.predict_proba(X_train_resampled)[:, 1] if hasattr(model, 'predict_proba') else None\n",
    "    test_proba = model.predict_proba(X_test_preprocessed)[:, 1] if hasattr(model, 'predict_proba') else None\n",
    "\n",
    "    train_acc, train_f1, train_roc, train_fpr, train_tpr, train_tresh = evaluate_model(y_train_resampled, train_pred, train_proba)\n",
    "    test_acc, test_f1, test_roc, test_fpr, test_tpr, test_tresh = evaluate_model(y_test, test_pred, test_proba)\n",
    "\n",
    "    train_results.loc[len(train_results)] = [model_name, train_f1, train_roc, train_acc]\n",
    "    test_results.loc[len(test_results)] = [model_name, test_f1, test_roc, test_acc]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281f1c60",
   "metadata": {},
   "source": [
    "#### These are the training results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b460ef6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CatBoostClassifier</td>\n",
       "      <td>0.999881</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.999881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.999411</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.989296</td>\n",
       "      <td>0.999500</td>\n",
       "      <td>0.989336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.955448</td>\n",
       "      <td>0.993085</td>\n",
       "      <td>0.956208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.952426</td>\n",
       "      <td>0.993332</td>\n",
       "      <td>0.953425</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Model  F1 Score   ROC AUC  Accuracy\n",
       "0      RandomForestClassifier  1.000000  1.000000  1.000000\n",
       "1               XGBClassifier  1.000000  1.000000  1.000000\n",
       "2      DecisionTreeClassifier  1.000000  1.000000  1.000000\n",
       "3          CatBoostClassifier  0.999881  0.999999  0.999881\n",
       "4        KNeighborsClassifier  0.999411  1.000000  0.999411\n",
       "5  GradientBoostingClassifier  0.989296  0.999500  0.989336\n",
       "6         Logistic Regression  0.955448  0.993085  0.956208\n",
       "7                    AdaBoost  0.952426  0.993332  0.953425"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_results = train_results.sort_values(by = \"Accuracy\", ascending=False).reset_index(drop = True)\n",
    "train_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3665fc91",
   "metadata": {},
   "source": [
    "#### These are the test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ebf63571",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.882051</td>\n",
       "      <td>0.976249</td>\n",
       "      <td>0.999596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.835979</td>\n",
       "      <td>0.973223</td>\n",
       "      <td>0.999456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CatBoostClassifier</td>\n",
       "      <td>0.825871</td>\n",
       "      <td>0.978708</td>\n",
       "      <td>0.999386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.605634</td>\n",
       "      <td>0.948472</td>\n",
       "      <td>0.998034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.473186</td>\n",
       "      <td>0.881387</td>\n",
       "      <td>0.997068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.286645</td>\n",
       "      <td>0.982742</td>\n",
       "      <td>0.992311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.102385</td>\n",
       "      <td>0.967503</td>\n",
       "      <td>0.972912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.101010</td>\n",
       "      <td>0.973968</td>\n",
       "      <td>0.971876</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Model  F1 Score   ROC AUC  Accuracy\n",
       "0               XGBClassifier  0.882051  0.976249  0.999596\n",
       "1      RandomForestClassifier  0.835979  0.973223  0.999456\n",
       "2          CatBoostClassifier  0.825871  0.978708  0.999386\n",
       "3        KNeighborsClassifier  0.605634  0.948472  0.998034\n",
       "4      DecisionTreeClassifier  0.473186  0.881387  0.997068\n",
       "5  GradientBoostingClassifier  0.286645  0.982742  0.992311\n",
       "6                    AdaBoost  0.102385  0.967503  0.972912\n",
       "7         Logistic Regression  0.101010  0.973968  0.971876"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results = test_results.sort_values(by = \"Accuracy\", ascending=False).reset_index(drop = True)\n",
    "test_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49388cc3",
   "metadata": {},
   "source": [
    "#### Looking at the above results, some modles like XGBClassifier, RandomForestClassifier and CatBoostClassifier are overfitting the model. Let us try to tune the hyperparameters of these models and see if we can improve their performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c01495f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_grid = {\n",
    "    \"Logistic Regression\": {\n",
    "        'model': LogisticRegression(max_iter=200),  # max_iter default raised for better convergence\n",
    "        'params': [\n",
    "            # liblinear solver with l1 or l2 penalties (elasticnet not supported)\n",
    "            {\n",
    "                'solver': ['liblinear'],\n",
    "                'penalty': ['l1', 'l2'],\n",
    "                'C': [0.1, 1, 10],\n",
    "                'max_iter': [100, 200]\n",
    "            },\n",
    "            # lbfgs solver with l2 or None penalty only\n",
    "            {\n",
    "                'solver': ['lbfgs'],\n",
    "                'penalty': ['l2', None],\n",
    "                'C': [0.1, 1, 10],\n",
    "                'max_iter': [100, 200]\n",
    "            },\n",
    "            # saga solver with l1, l2, elasticnet penalties\n",
    "            {\n",
    "                'solver': ['saga'],\n",
    "                'penalty': ['l1', 'l2', 'elasticnet'],\n",
    "                'l1_ratio': [0, 0.5, 1],  # used only for elasticnet penalty\n",
    "                'C': [0.1, 1, 10],\n",
    "                'max_iter': [100, 200]\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "\n",
    "    \"K-Neighbors Classifier\": {\n",
    "        'model': KNeighborsClassifier(),\n",
    "        'params': {\n",
    "            'n_neighbors': [3, 5, 7],\n",
    "            'weights': ['uniform', 'distance'],\n",
    "            'metric': ['euclidean', 'manhattan'],  # remove 'minkowski' to reduce complexity\n",
    "            'p': [1, 2]\n",
    "        }\n",
    "    },\n",
    "\n",
    "    \"Decision Tree Classifier\": {\n",
    "        'model': DecisionTreeClassifier(),\n",
    "        'params': {\n",
    "            'max_depth': [5, 10, 15],\n",
    "            'criterion': ['gini', 'entropy'],  # remove 'log_loss' for speed\n",
    "            'splitter': ['best'],  # avoid 'random' to reduce variability/speed up\n",
    "            'min_samples_split': [2, 5],\n",
    "            'min_samples_leaf': [1, 2]\n",
    "        }\n",
    "    },\n",
    "\n",
    "    \"Random Forest Classifier\": {\n",
    "        'model': RandomForestClassifier(),\n",
    "        'params': {\n",
    "            'n_estimators': [100, 200],\n",
    "            'max_depth': [10, 20, None],\n",
    "            'min_samples_split': [2, 5],\n",
    "            'min_samples_leaf': [1, 2],\n",
    "            'bootstrap': [True]  # keep only 'True' for faster experiments\n",
    "        }\n",
    "    },\n",
    "\n",
    "    \"AdaBoost Classifier\": {\n",
    "        'model': AdaBoostClassifier(),\n",
    "        'params': {\n",
    "            'n_estimators': [50, 100],\n",
    "            'learning_rate': [0.01, 0.1]\n",
    "        }\n",
    "    },\n",
    "\n",
    "    \"Gradient Boosting Classifier\": {\n",
    "        'model': GradientBoostingClassifier(),\n",
    "        'params': {\n",
    "            'n_estimators': [100, 150],\n",
    "            'learning_rate': [0.01, 0.1],\n",
    "            'max_depth': [3, 5],\n",
    "            'subsample': [0.8, 1.0],\n",
    "            'min_samples_split': [2, 5]\n",
    "        }\n",
    "    },\n",
    "\n",
    "    \"XGB-Classifier\": {\n",
    "        'model': XGBClassifier(tree_method='gpu_hist', device='cuda', use_label_encoder=False, eval_metric='logloss'),\n",
    "        'params': {\n",
    "            'n_estimators': [100, 200],\n",
    "            'learning_rate': [0.05, 0.1],\n",
    "            'max_depth': [3, 5],\n",
    "            'subsample': [0.8, 1.0],\n",
    "            'colsample_bytree': [0.8, 1.0],\n",
    "            'gamma': [0, 0.1]\n",
    "        }\n",
    "    },\n",
    "\n",
    "    \"CatBoostClassifier\": {\n",
    "        'model': CatBoostClassifier(task_type=\"GPU\", devices='0', verbose=0),\n",
    "        'params': {\n",
    "            'iterations': [100, 200],     # CatBoost uses 'iterations' instead of n_estimators\n",
    "            'learning_rate': [0.05, 0.1],\n",
    "            'depth': [4, 6],              # 'depth' instead of 'max_depth'\n",
    "            'l2_leaf_reg': [3, 5]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1496d051",
   "metadata": {},
   "source": [
    "### Now, we will hyperparameter tune the models using GridSearchCV to find the best hyperparameters for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "709844ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Tuning and training Logistic Regression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1207: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Best Parameters for Logistic Regression: {'solver': 'lbfgs', 'penalty': None, 'max_iter': 100, 'C': 0.1}\n",
      "\n",
      "🔍 Tuning and training K-Neighbors Classifier...\n",
      "✅ Best Parameters for K-Neighbors Classifier: {'weights': 'distance', 'p': 2, 'n_neighbors': 3, 'metric': 'manhattan'}\n",
      "\n",
      "🔍 Tuning and training Decision Tree Classifier...\n",
      "✅ Best Parameters for Decision Tree Classifier: {'splitter': 'best', 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_depth': 15, 'criterion': 'entropy'}\n",
      "\n",
      "🔍 Tuning and training Random Forest Classifier...\n",
      "✅ Best Parameters for Random Forest Classifier: {'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': None, 'bootstrap': True}\n",
      "\n",
      "🔍 Tuning and training AdaBoost Classifier...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/sklearn/model_selection/_search.py:317: UserWarning: The total space of parameters 4 is smaller than n_iter=10. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Best Parameters for AdaBoost Classifier: {'n_estimators': 100, 'learning_rate': 0.1}\n",
      "\n",
      "🔍 Tuning and training Gradient Boosting Classifier...\n",
      "✅ Best Parameters for Gradient Boosting Classifier: {'subsample': 1.0, 'n_estimators': 150, 'min_samples_split': 2, 'max_depth': 5, 'learning_rate': 0.1}\n",
      "\n",
      "🔍 Tuning and training XGB-Classifier...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:01:33] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:01:34] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/core.py:2676: UserWarning: [19:01:35] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:01:35] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:01:35] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/core.py:2676: UserWarning: [19:01:37] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:01:37] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:01:37] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/core.py:2676: UserWarning: [19:01:38] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:01:38] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:01:38] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/core.py:2676: UserWarning: [19:01:39] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:01:40] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:01:40] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/core.py:2676: UserWarning: [19:01:41] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:01:41] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:01:41] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/core.py:2676: UserWarning: [19:01:42] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:01:42] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:01:42] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/core.py:2676: UserWarning: [19:01:43] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:01:43] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:01:43] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/core.py:2676: UserWarning: [19:01:44] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:01:44] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:01:44] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/core.py:2676: UserWarning: [19:01:45] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:01:45] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:01:45] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/core.py:2676: UserWarning: [19:01:46] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:01:46] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:01:46] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/core.py:2676: UserWarning: [19:01:46] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:01:47] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:01:47] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/core.py:2676: UserWarning: [19:01:47] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:01:47] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:01:47] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/core.py:2676: UserWarning: [19:01:48] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:01:48] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:01:48] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/core.py:2676: UserWarning: [19:01:48] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:01:49] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:01:49] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/core.py:2676: UserWarning: [19:01:49] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:01:49] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:01:49] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/core.py:2676: UserWarning: [19:01:50] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:01:50] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:01:50] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/core.py:2676: UserWarning: [19:01:51] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:01:51] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:01:51] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/core.py:2676: UserWarning: [19:01:52] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:01:52] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:01:52] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/core.py:2676: UserWarning: [19:01:53] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:01:54] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:01:54] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/core.py:2676: UserWarning: [19:01:54] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:01:55] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:01:55] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/core.py:2676: UserWarning: [19:01:55] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:01:55] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:01:55] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/core.py:2676: UserWarning: [19:01:56] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:01:56] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:01:56] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/core.py:2676: UserWarning: [19:01:56] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:01:57] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:01:57] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/core.py:2676: UserWarning: [19:01:57] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:01:57] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:01:57] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/core.py:2676: UserWarning: [19:01:58] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:01:58] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:01:58] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/core.py:2676: UserWarning: [19:01:59] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:01:59] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:01:59] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/core.py:2676: UserWarning: [19:02:00] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:02:00] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:02:00] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/core.py:2676: UserWarning: [19:02:01] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:02:01] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:02:01] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/core.py:2676: UserWarning: [19:02:02] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:02:02] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:02:02] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/core.py:2676: UserWarning: [19:02:03] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:02:03] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:02:03] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/core.py:2676: UserWarning: [19:02:04] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:02:04] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:02:04] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/core.py:2676: UserWarning: [19:02:05] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:02:05] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:02:05] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/core.py:2676: UserWarning: [19:02:05] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:02:06] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:02:06] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/core.py:2676: UserWarning: [19:02:06] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:02:06] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:02:06] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/core.py:2676: UserWarning: [19:02:07] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:02:07] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:02:07] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/core.py:2676: UserWarning: [19:02:08] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:02:08] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:02:08] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/core.py:2676: UserWarning: [19:02:09] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:02:09] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:02:09] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/core.py:2676: UserWarning: [19:02:10] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:02:10] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:02:10] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/core.py:2676: UserWarning: [19:02:11] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:02:11] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:02:11] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/core.py:2676: UserWarning: [19:02:11] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:02:12] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:02:12] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/core.py:2676: UserWarning: [19:02:12] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:02:13] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:02:13] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/core.py:2676: UserWarning: [19:02:13] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:02:14] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:02:14] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/core.py:2676: UserWarning: [19:02:14] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:02:14] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:02:14] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/core.py:2676: UserWarning: [19:02:15] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:02:16] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:02:16] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/core.py:2676: UserWarning: [19:02:17] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:02:17] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:02:17] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/core.py:2676: UserWarning: [19:02:18] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:02:18] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:02:18] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/core.py:2676: UserWarning: [19:02:19] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:02:20] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:02:20] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/core.py:2676: UserWarning: [19:02:21] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:02:21] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:02:21] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/core.py:2676: UserWarning: [19:02:22] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:02:22] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:02:22] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/core.py:2676: UserWarning: [19:02:23] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:02:24] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [19:02:24] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Best Parameters for XGB-Classifier: {'subsample': 0.8, 'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.1, 'gamma': 0.1, 'colsample_bytree': 0.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anupam9k/AI_Resume_Projects/Fraud_Detection_&_Risk_Analytics_for_FinTehcs_&_SMEs/fdenv/lib/python3.10/site-packages/xgboost/core.py:2676: UserWarning: [19:02:25] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Tuning and training CatBoostClassifier...\n",
      "✅ Best Parameters for CatBoostClassifier: {'learning_rate': 0.1, 'l2_leaf_reg': 3, 'iterations': 200, 'depth': 6}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV\n",
    "\n",
    "# Create results DataFrames\n",
    "train_results = pd.DataFrame(columns=['Model', 'F1 Score', 'ROC AUC', 'Accuracy'])\n",
    "test_results = pd.DataFrame(columns=['Model', 'F1 Score', 'ROC AUC', 'Accuracy'])\n",
    "best_params_df = pd.DataFrame(columns=['Model', 'Best Parameters'])\n",
    "\n",
    "# Loop through each model in the prarms_grid dictionary\n",
    "for model_name, config in params_grid.items():\n",
    "    print(f\"\\n🔍 Tuning and training {model_name}...\")\n",
    "\n",
    "    model = config['model']\n",
    "    param_grid = config['params']\n",
    "\n",
    "    cv = StratifiedKFold(n_splits = 5, shuffle = True, random_state=42)\n",
    "    if model_name in [\"CatBoostClassifier\", \"XGB-Classifier\"]:\n",
    "        n_jobs = 1\n",
    "    else:\n",
    "        n_jobs = 6\n",
    "    grid = RandomizedSearchCV(estimator = model, param_distributions = param_grid, cv=cv, n_jobs = n_jobs, verbose = 0)\n",
    "    grid.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "    best_model = grid.best_estimator_\n",
    "    best_params = grid.best_params_\n",
    "    print(f\"✅ Best Parameters for {model_name}: {best_params}\")\n",
    "\n",
    "    # Predictions\n",
    "    train_pred = best_model.predict(X_train_resampled)\n",
    "    test_pred = best_model.predict(X_test_preprocessed)\n",
    "\n",
    "    # Probabilities for ROC AUC\n",
    "    train_proba = best_model.predict_proba(X_train_resampled)[:, 1] if hasattr(best_model, \"predict_proba\") else None\n",
    "    test_proba = best_model.predict_proba(X_test_preprocessed)[:, -1] if hasattr(best_model, \"predict_proba\") else None\n",
    "\n",
    "    train_acc, train_f1, train_roc, train_fpr, train_tpr, train_tresh = evaluate_model(y_train_resampled, train_pred, train_proba)\n",
    "    test_acc, test_f1, test_roc, test_fpr, test_tpr, test_tresh = evaluate_model(y_test, test_pred, test_proba)\n",
    "\n",
    "    train_results.loc[len(train_results)] = [model_name, train_f1, train_roc, train_acc]\n",
    "    test_results.loc[len(test_results)] = [model_name, test_f1, test_roc, test_acc]\n",
    "    best_params_df.loc[len(best_params_df)] = [model_name, best_params]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2290076",
   "metadata": {},
   "source": [
    "#### These are the training results after hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f64a7511",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>K-Neighbors Classifier</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGB-Classifier</td>\n",
       "      <td>0.999892</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.999892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boosting Classifier</td>\n",
       "      <td>0.999846</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.999846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CatBoostClassifier</td>\n",
       "      <td>0.999842</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.999842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>0.996836</td>\n",
       "      <td>0.999841</td>\n",
       "      <td>0.996828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.955513</td>\n",
       "      <td>0.993098</td>\n",
       "      <td>0.956270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AdaBoost Classifier</td>\n",
       "      <td>0.927050</td>\n",
       "      <td>0.985500</td>\n",
       "      <td>0.930910</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Model  F1 Score   ROC AUC  Accuracy\n",
       "0        K-Neighbors Classifier  1.000000  1.000000  1.000000\n",
       "1      Random Forest Classifier  1.000000  1.000000  1.000000\n",
       "2                XGB-Classifier  0.999892  0.999999  0.999892\n",
       "3  Gradient Boosting Classifier  0.999846  0.999979  0.999846\n",
       "4            CatBoostClassifier  0.999842  0.999997  0.999842\n",
       "5      Decision Tree Classifier  0.996836  0.999841  0.996828\n",
       "6           Logistic Regression  0.955513  0.993098  0.956270\n",
       "7           AdaBoost Classifier  0.927050  0.985500  0.930910"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_results = train_results.sort_values(by='Accuracy', ascending=False).reset_index(drop=True)\n",
    "train_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a038e44",
   "metadata": {},
   "source": [
    "#### These are the test results after hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "165f8d3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>0.843243</td>\n",
       "      <td>0.963436</td>\n",
       "      <td>0.999491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CatBoostClassifier</td>\n",
       "      <td>0.809756</td>\n",
       "      <td>0.975732</td>\n",
       "      <td>0.999315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGB-Classifier</td>\n",
       "      <td>0.809756</td>\n",
       "      <td>0.982712</td>\n",
       "      <td>0.999315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boosting Classifier</td>\n",
       "      <td>0.783019</td>\n",
       "      <td>0.968568</td>\n",
       "      <td>0.999192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K-Neighbors Classifier</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.943512</td>\n",
       "      <td>0.998736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>0.278075</td>\n",
       "      <td>0.906905</td>\n",
       "      <td>0.992890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AdaBoost Classifier</td>\n",
       "      <td>0.154386</td>\n",
       "      <td>0.967600</td>\n",
       "      <td>0.983076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.100727</td>\n",
       "      <td>0.973997</td>\n",
       "      <td>0.971788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Model  F1 Score   ROC AUC  Accuracy\n",
       "0      Random Forest Classifier  0.843243  0.963436  0.999491\n",
       "1            CatBoostClassifier  0.809756  0.975732  0.999315\n",
       "2                XGB-Classifier  0.809756  0.982712  0.999315\n",
       "3  Gradient Boosting Classifier  0.783019  0.968568  0.999192\n",
       "4        K-Neighbors Classifier  0.700000  0.943512  0.998736\n",
       "5      Decision Tree Classifier  0.278075  0.906905  0.992890\n",
       "6           AdaBoost Classifier  0.154386  0.967600  0.983076\n",
       "7           Logistic Regression  0.100727  0.973997  0.971788"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results = test_results.sort_values(by='Accuracy', ascending=False).reset_index(drop = True)\n",
    "test_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb2bec3",
   "metadata": {},
   "source": [
    "As per the above results, we can see that Random Forest Classifier is the best models with accuracy of 99.95% and ROC AUC score of 96.34%. So, let us choose **Random Forest Classifier** as our final model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa5e0e7",
   "metadata": {},
   "source": [
    "### Training the final model on the entire dataset with the best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e42f408f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 100,\n",
       " 'min_samples_split': 2,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_depth': None,\n",
       " 'bootstrap': True}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params_df[best_params_df['Model'] == 'Random Forest Classifier']['Best Parameters'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2af216f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=100, min_samples_split=2, min_samples_leaf=1, max_depth=None, bootstrap=True)\n",
    "model.fit(X_train_resampled, y_train_resampled)\n",
    "y_pred = model.predict(X_test_preprocessed)\n",
    "y_pred_proba = model.predict_proba(X_test_preprocessed)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c991c7e",
   "metadata": {},
   "source": [
    "### Visualizing the results using classification report, Confusion Matrix, and ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "146187b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy Score:  0.9995084442259752\n",
      "f1 Score:  0.8494623655913979\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56864\n",
      "           1       0.90      0.81      0.85        98\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.95      0.90      0.92     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1kAAAIjCAYAAADxz9EgAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjUsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvWftoOwAAAAlwSFlzAAAPYQAAD2EBqD+naQAAkLtJREFUeJzs3Xd4FOXCxuFns6QSktBrIFTpvUivCggIioCAUkWRTihSIkVK6MGCohQBDygIyIcHxAIWuihFuvQOUpOQkEJ2vj84rIQkkMAmk/K7ryvXyc7OzD5ZE06evO+8YzEMwxAAAAAAwCGczA4AAAAAAOkJJQsAAAAAHIiSBQAAAAAORMkCAAAAAAeiZAEAAACAA1GyAAAAAMCBKFkAAAAA4ECULAAAAABwIEoWAAAAADgQJQsAUpifn5+6detmdowMp0GDBmrQoIHZMR5r3LhxslgsunbtmtlRUh2LxaJx48Y55FynT5+WxWLRokWLHHI+AHgQJQtAurJo0SJZLBb7R6ZMmZQ/f35169ZNFy5cMDteqhYWFqYJEyaofPny8vDwkLe3t+rWraslS5bIMAyz4yXKoUOHNG7cOJ0+fdrsKHHExMTo888/V4MGDZQtWza5urrKz89P3bt31x9//GF2PIdYtmyZZs+ebXaMWFJjJgDpXyazAwBAcnjvvfdUuHBhRUREaMeOHVq0aJG2bNmiAwcOyM3NzdRsR48elZNT6vob15UrV9S4cWMdPnxYr776qvr166eIiAitWrVKXbt21fr167V06VJZrVazoz7SoUOHNH78eDVo0EB+fn6xnvvhhx/MCSXpzp07evnll7VhwwbVq1dPo0aNUrZs2XT69GmtWLFCixcv1tmzZ1WgQAHTMjrCsmXLdODAAQ0aNChZzn/nzh1lypS0X10SylSoUCHduXNHzs7ODkwIAPdQsgCkS82bN1fVqlUlSW+88YZy5MihqVOnau3atWrfvr2p2VxdXVP8NSMiIuTi4pJguevatasOHz6sb775Ri+++KJ9+4ABAzRs2DDNmDFDlSpV0jvvvJNSkSXdG13LnDmzQ87l4uLikPM8iWHDhmnDhg0KCgqK88v+2LFjFRQUlKJ5DMNQRESE3N3dU/R1n4TNZlNUVJTc3Nwc+gcSi8Vi+h9cAKRfqetPqQCQTOrWrStJOnHiRKztR44c0SuvvKJs2bLJzc1NVatW1dq1a+Mcf+vWLQ0ePFh+fn5ydXVVgQIF1KVLl1jXzURGRmrs2LEqVqyYXF1d5evrq+HDhysyMjLWuR68JuuPP/6QxWLR4sWL47zm999/L4vFov/+97/2bRcuXFCPHj2UO3duubq6qkyZMlq4cGGs43755RdZLBZ99dVXCggIUP78+eXh4aGQkJB435sdO3bo+++/V7du3WIVrPsCAwNVvHhxTZ06VXfu3JH07/UsM2bMUFBQkAoVKiR3d3fVr19fBw4ciHOOxLzP96d6/vrrr+rTp49y5cplH9k5c+aM+vTpo2eeeUbu7u7Knj272rVrF2ta4KJFi9SuXTtJUsOGDe1TRn/55RdJca/Juv8+rVixQpMmTVKBAgXk5uamxo0b6/jx43G+hjlz5qhIkSJyd3dX9erVtXnz5kRd53X+/Hl9+umneu655+Id4bFarRo6dGicUaxbt26pW7du8vHxkbe3t7p3767w8PBY+3z++edq1KiRcuXKJVdXV5UuXVqffPJJnNfw8/NTy5Yt9f3336tq1apyd3fXp59+mqRzSNJ3332n+vXrK0uWLPLy8lK1atW0bNkySffe33Xr1unMmTP29/7B0cTE/nxYLBb169dPS5cuVZkyZeTq6qoNGzbYn3vwmqzQ0FANGjTI/nOZK1cuPffcc9q9e/djMyV0TdaRI0fUvn175cyZU+7u7nrmmWc0evToeN8PAEgII1kAMoT7v4xnzZrVvu3gwYOqXbu28ufPrxEjRihz5sxasWKF2rRpo1WrVumll16SJN2+fVt169bV4cOH1aNHD1WuXFnXrl3T2rVrdf78eeXIkUM2m00vvviitmzZojfffFOlSpXS/v37FRQUpL///ltr1qyJN1fVqlVVpEgRrVixQl27do313PLly5U1a1Y1bdpU0r0pfc8++6z9l9CcOXPqu+++U8+ePRUSEhLnF/gJEybIxcVFQ4cOVWRkZIIjOd9++60kqUuXLvE+nylTJnXq1Enjx4/X1q1b1aRJE/tzS5YsUWhoqPr27auIiAi9//77atSokfbv36/cuXMn6X2+r0+fPsqZM6fGjBmjsLAwSdKuXbu0bds2vfrqqypQoIBOnz6tTz75RA0aNNChQ4fk4eGhevXqacCAAfrggw80atQolSpVSpLs/5uQKVOmyMnJSUOHDlVwcLCmTZumzp07a+fOnfZ9PvnkE/Xr109169bV4MGDdfr0abVp00ZZs2Z97BS/7777Tnfv3tXrr7/+yP0e1r59exUuXFiBgYHavXu35s+fr1y5cmnq1KmxcpUpU0YvvviiMmXKpG+//VZ9+vSRzWZT3759Y53v6NGj6tixo9566y316tVLzzzzTJLOsWjRIvXo0UNlypTRyJEj5ePjoz179mjDhg3q1KmTRo8ereDgYJ0/f94+Mufp6SlJSf752LRpk1asWKF+/fopR44ccaZ+3te7d2+tXLlS/fr1U+nSpXX9+nVt2bJFhw8fVuXKlR+ZKT5//fWX6tatK2dnZ7355pvy8/PTiRMn9O2332rSpEmJ+w8HAJJkAEA68vnnnxuSjJ9++sm4evWqce7cOWPlypVGzpw5DVdXV+PcuXP2fRs3bmyUK1fOiIiIsG+z2WxGrVq1jOLFi9u3jRkzxpBkrF69Os7r2Ww2wzAM44svvjCcnJyMzZs3x3p+7ty5hiRj69at9m2FChUyunbtan88cuRIw9nZ2bhx44Z9W2RkpOHj42P06NHDvq1nz55G3rx5jWvXrsV6jVdffdXw9vY2wsPDDcMwjJ9//tmQZBQpUsS+7VHatGljSDJu3ryZ4D6rV682JBkffPCBYRiGcerUKUOS4e7ubpw/f96+386dOw1JxuDBg+3bEvs+3/9vV6dOHePu3buxXj++r2P79u2GJGPJkiX2bV9//bUhyfj555/j7F+/fn2jfv369sf336dSpUoZkZGR9u3vv/++IcnYv3+/YRj3/ltkz57dqFatmhEdHW3fb9GiRYakWOeMz+DBgw1Jxp49ex65331jx441JMX6b28YhvHSSy8Z2bNnj7UtvveladOmRpEiRWJtK1SokCHJ2LBhQ5z9E3OOW7duGVmyZDFq1Khh3LlzJ9a+938GDMMwWrRoYRQqVCjO+ZLy8yHJcHJyMg4ePBjnPJKMsWPH2h97e3sbffv2jbPfgxLKdP97+PPPP7dvq1evnpElSxbjzJkzCX6NAJAYTBcEkC41adJEOXPmlK+vr1555RVlzpxZa9eutY863LhxQ5s2bVL79u0VGhqqa9eu6dq1a7p+/bqaNm2qY8eO2VcjXLVqlSpUqBBnxEW6N31Jkr7++muVKlVKJUuWtJ/r2rVratSokSTp559/TjBrhw4dFB0drdWrV9u3/fDDD7p165Y6dOgg6d41NKtWrVKrVq1kGEas12jatKmCg4PtU6Tu69q1a6KuuQkNDZUkZcmSJcF97j/38JTDNm3aKH/+/PbH1atXV40aNbR+/XpJSXuf7+vVq1ecBTYe/Dqio6N1/fp1FStWTD4+PnG+7qTq3r17rFG++1NLT548KenelM7r16+rV69esRZd6Ny5c6yR0YTcf88e9f7Gp3fv3rEe161bV9evX4/13+DB9yU4OFjXrl1T/fr1dfLkSQUHB8c6vnDhwvZR0Qcl5hw//vijQkNDNWLEiDjXMd3/GXiUpP581K9fX6VLl37seX18fLRz505dvHjxsfs+ztWrV/Xbb7+pR48eKliwYKznEvM1AsCDmC4IIF2aM2eOSpQooeDgYC1cuFC//fZbrAUnjh8/LsMw9O677+rdd9+N9xz//POP8ufPrxMnTqht27aPfL1jx47p8OHDypkzZ4LnSkiFChVUsmRJLV++XD179pR0b6pgjhw57L+EXr16Vbdu3dJnn32mzz77LFGvUbhw4Udmvu/+L/+hoaHy8fGJd5+Eiljx4sXj7FuiRAmtWLFCUtLe50flvnPnjgIDA/X555/rwoULsZaUf7hMJNXDv1DfL043b96UdO96MEkqVqxYrP0yZcqU4DS2B3l5eUn69z10RK7759y6davGjh2r7du3x7leKzg4WN7e3vbHCX0/JOYc969lLFu2bJK+hvuS+vOR2O/dadOmqWvXrvL19VWVKlX0wgsvqEuXLipSpEiSM94v1U/6NQLAgyhZANKl6tWr21cXbNOmjerUqaNOnTrp6NGj8vT0lM1mkyQNHTo03r/uS3F/qX4Um82mcuXKadasWfE+7+vr+8jjO3TooEmTJunatWvKkiWL1q5dq44dO9pHTu7nfe211+Jcu3Vf+fLlYz1O7MpxpUqV0po1a/TXX3+pXr168e7z119/SVKiRhce9CTvc3y5+/fvr88//1yDBg1SzZo15e3tLYvFoldffdX+Gk8qoWXpDQfdG6xkyZKSpP3796tixYqJPu5xuU6cOKHGjRurZMmSmjVrlnx9feXi4qL169crKCgozvsS3/ua1HM8qaT+fCT2e7d9+/aqW7euvvnmG/3www+aPn26pk6dqtWrV6t58+ZPnRsAnhQlC0C6Z7VaFRgYqIYNG+qjjz7SiBEj7H/pdnZ2jrWQQ3yKFi0a74p5D++zb98+NW7c+ImmFnXo0EHjx4/XqlWrlDt3boWEhOjVV1+1P58zZ05lyZJFMTExj82bVC1btlRgYKCWLFkSb8mKiYnRsmXLlDVrVtWuXTvWc8eOHYuz/99//20f4UnK+/woK1euVNeuXTVz5kz7toiICN26dSvWfskxratQoUKS7o3KNWzY0L797t27On36dJxy+7DmzZvLarXqP//5T5IXv3iUb7/9VpGRkVq7dm2sUa9HTU190nMULVpUknTgwIFH/vEhoff/aX8+HiVv3rzq06eP+vTpo3/++UeVK1fWpEmT7CUrsa93/3v1cT/rAJAYXJMFIENo0KCBqlevrtmzZysiIkK5cuVSgwYN9Omnn+rSpUtx9r969ar987Zt22rfvn365ptv4ux3f1Shffv2unDhgubNmxdnnzt37thXyUtIqVKlVK5cOS1fvlzLly9X3rx5YxUeq9Wqtm3batWqVfH+Evhg3qSqVauWmjRpos8//zzWcvH3jR49Wn///beGDx8eZ4RhzZo1sa6p+v3337Vz5077L7hJeZ8fxWq1xhlZ+vDDDxUTExNr2/17aj1cvp5G1apVlT17ds2bN0937961b1+6dKl9SuGj+Pr6qlevXvrhhx/04YcfxnneZrNp5syZOn/+fJJy3R/penjq5Oeff+7wczz//PPKkiWLAgMDFREREeu5B4/NnDlzvNM3n/bnIz4xMTFxXitXrlzKly9frGXhE8r0sJw5c6pevXpauHChzp49G+s5R41qAsg4GMkCkGEMGzZM7dq106JFi9S7d2/NmTNHderUUbly5dSrVy8VKVJEV65c0fbt23X+/Hnt27fPftzKlSvVrl079ejRQ1WqVNGNGze0du1azZ07VxUqVNDrr7+uFStWqHfv3vr5559Vu3ZtxcTE6MiRI1qxYoX9/kSP0qFDB40ZM0Zubm7q2bNnnBsHT5kyRT///LNq1KihXr16qXTp0rpx44Z2796tn376STdu3Hji92bJkiVq3LixWrdurU6dOqlu3bqKjIzU6tWr9csvv6hDhw4aNmxYnOOKFSumOnXq6O2331ZkZKRmz56t7Nmza/jw4fZ9Evs+P0rLli31xRdfyNvbW6VLl9b27dv1008/KXv27LH2q1ixoqxWq6ZOnarg4GC5urra7wH1pFxcXDRu3Dj1799fjRo1Uvv27XX69GktWrRIRYsWTdRIycyZM3XixAkNGDBAq1evVsuWLZU1a1adPXtWX3/9tY4cORJr5DIxnn/+ebm4uKhVq1Z66623dPv2bc2bN0+5cuWKt9A+zTm8vLwUFBSkN954Q9WqVVOnTp2UNWtW7du3T+Hh4fb7vFWpUkXLly+Xv7+/qlWrJk9PT7Vq1cohPx8PCw0NVYECBfTKK6+oQoUK8vT01E8//aRdu3bFGvFMKFN8PvjgA9WpU0eVK1fWm2++qcKFC+v06dNat26d9u7dm6R8ADI4U9Y0BIBkcn8Z8F27dsV5LiYmxihatKhRtGhR+xLhJ06cMLp06WLkyZPHcHZ2NvLnz2+0bNnSWLlyZaxjr1+/bvTr18/Inz+/4eLiYhQoUMDo2rVrrOXUo6KijKlTpxplypQxXF1djaxZsxpVqlQxxo8fbwQHB9v3e3gJ9/uOHTtmSDIkGVu2bIn367ty5YrRt29fw9fX13B2djby5MljNG7c2Pjss8/s+9xfmvzrr79O0nsXGhpqjBs3zihTpozh7u5uZMmSxahdu7axaNGiOEtY31/+evr06cbMmTMNX19fw9XV1ahbt66xb9++OOdOzPv8qP92N2/eNLp3727kyJHD8PT0NJo2bWocOXIk3vdy3rx5RpEiRQyr1RprOfeElnB/+H2Kb2lvwzCMDz74wChUqJDh6upqVK9e3di6datRpUoVo1mzZol4dw3j7t27xvz58426desa3t7ehrOzs1GoUCGje/fusZZ3v7+E+9WrV2Mdf//9OXXqlH3b2rVrjfLlyxtubm6Gn5+fMXXqVGPhwoVx9itUqJDRokWLeHMl9hz3961Vq5bh7u5ueHl5GdWrVze+/PJL+/O3b982OnXqZPj4+BiSYi2dntifD0kJLsuuB5Zwj4yMNIYNG2ZUqFDByJIli5E5c2ajQoUKxscffxzrmIQyJfTf+cCBA8ZLL71k+Pj4GG5ubsYzzzxjvPvuu/HmAYCEWAyDMXAAQNKcPn1ahQsX1vTp0zV06FCz45jCZrMpZ86cevnll+OdBgcAyLi4JgsAgMeIiIiIc13OkiVLdOPGDTVo0MCcUACAVItrsgAAeIwdO3Zo8ODBateunbJnz67du3drwYIFKlu2rNq1a2d2PABAKkPJAgDgMfz8/OTr66sPPvhAN27cULZs2dSlSxdNmTJFLi4uZscDAKQyXJMFAAAAAA7ENVkAAAAA4ECULAAAAABwoAx3TZbNZtPFixeVJUuWRN1AEgAAAED6ZBiGQkNDlS9fPjk5OW78KcOVrIsXL8rX19fsGAAAAABSiXPnzqlAgQIOO1+GK1lZsmSRdO+N9PLyMjkNAAAAALOEhITI19fX3hEcJcOVrPtTBL28vChZAAAAABx+GRELXwAAAACAA1GyAAAAAMCBKFkAAAAA4ECULAAAAABwIEoWAAAAADgQJQsAAAAAHIiSBQAAAAAORMkCAAAAAAeiZAEAAACAA1GyAAAAAMCBKFkAAAAA4ECULAAAAABwIEoWAAAAADgQJQsAAAAAHIiSBQAAAAAOZGrJ+u2339SqVSvly5dPFotFa9aseewxv/zyiypXrixXV1cVK1ZMixYtSvacAAAAAJBYppassLAwVahQQXPmzEnU/qdOnVKLFi3UsGFD7d27V4MGDdIbb7yh77//PpmTAgAAAEDiZDLzxZs3b67mzZsnev+5c+eqcOHCmjlzpiSpVKlS2rJli4KCgtS0adPkigkAAAAgjbDZDEXF2O593H3g43+PIx94fP3a9WTJYGrJSqrt27erSZMmsbY1bdpUgwYNSvCYyMhIRUZG2h+HhIQkVzwAAAAgQzEMI3aZeeDzyLsJF52ouzZFxtgU/fA+8RShqLsxCZ47Op7zR8cYj899N0ohu9YodN+GZHlf0lTJunz5snLnzh1rW+7cuRUSEqI7d+7I3d09zjGBgYEaP358SkUEAAAAksXDhSY6xvhfsYj5t5TEU1oSei46JnFF6N7nMfHul5hCYzZnq0UuVie5ZHKSs9WikEObdea7eYq4eTnZXjNNlawnMXLkSPn7+9sfh4SEyNfX18REAAAASO0Mw7hXYuIUi3uFxl5w/rct7uhLAqMzMf8WnMQUoYc/T+0yOVnkkuleoblfbO5/7prJKZ7nrP/73PLQ/tZ/P8/kJFdrfMc+9Di+7VYnOTlZJEm7du3S4MGDdXTrVklS/vz5NWbMGL311luOfx8cfsZklCdPHl25ciXWtitXrsjLyyveUSxJcnV1laura0rEAwAAwBMwDEN3bUb8pSRO0YhR1N2Hy09MAqMvCY/sPFxyHtz//vGp3YOFxtn6qCIT+3PXOM9Z5fy/khP7eGuc410fVXQeKDSpic1mU48ePbR48WJJkoeHh4YPH66hQ4cqJiaGklWzZk2tX78+1rYff/xRNWvWNCkRAABA2nP3oUUB4kwZe+R1NTH2EZ7Yoy8xiSxJ/16H8+DzRiqfdWZ1enikJXYhuV9ykjL68qjjXeMZzXmw6DhbnWRNhYUmNXJycpKT071F1V9//XVNnjxZBQoUkJR86zWYWrJu376t48eP2x+fOnVKe/fuVbZs2VSwYEGNHDlSFy5c0JIlSyRJvXv31kcffaThw4erR48e2rRpk1asWKF169aZ9SUAAAA8UqxCk4jRk8ddVxPfCMy/RSjuAgHxHW9L5YXGyaIHSoU1/tGTBEZSEioljxvZcY5nypnrAyWHQpN22Gw2LVu2TDVq1FDx4sUlSZMmTdLbb7+tatWqpUgGU0vWH3/8oYYNG9of3792qmvXrlq0aJEuXbqks2fP2p8vXLiw1q1bp8GDB+v9999XgQIFNH/+fJZvBwAAkqSYB6acRcYzshIdZ/QlgcKS0HU1jylC/x7/7/S1tFJonK3xTCOL59qZhKaLxXv8o0Z2EtrX6qRMVlNv5Yo0bNu2bRo8eLB+//13tW7dWmvWrJEk5c2bV3nz5k2xHKaWrAYNGsh4xNjwokWL4j1mz549yZgKAAAkxv170SRcSmKveHZvitm/xSfxq5o9MILzmCluMam80Vgsij26Yo1dUh4/+vLvyMqjjn/UdTkPP0ehQXpw5swZvfPOO1q+fLkkydPTUzVq1JDNZrNPFUxJaeqaLAAAMqqk3Fwz/mtk4q6ElpRVzSLjKTl3U3mhkZTo0ZOEpovFf12NNd7SkpiSlMnJIouFaWeAo4SGhiowMFCzZs1SZGSkLBaLevbsqQkTJihPnjym5aJkAQDwEMMwElxqOamjL1ExMfalnhN7c834zpsmCk1C08QeuapZ/NPFHn1dTfwrnjk/dC5nK4UGSO8+++wzBQYGSpIaNmyoWbNmqWLFiuaGEiULAGCyh2+uGV/piI6nfCTlupqHj08PN9eMr5w4Wy32UZZEr2oWz3SzRxWhhFY8o9AASCmhoaHKkiWLJKlPnz767rvv1L9/f7344oup5t8hShYAZCCPu7nmI6eMJeLmmok+Po3dXNPZaklgdCVuobEXnSSsavZvSXr0tTMPfp5afpEAgJRy/PhxDRs2TCdOnNCePXtktVrl7u6un376yexocVCyACCZJP3mmnGfi37kNLTHj+zEd3xq9+DNNR93wf6DK579O2XMEndKWRJGdh4uOqn15poAkFHcunVLEydO1AcffKDo6GhZrVZt375dderUMTtagihZANKFhApNUm6u+fB0sui7sVdCe9zNNR8sQJEx9wpOar+5ZryF5omuq3nwGhlLAtsfMbJDoQEAPOTu3buaN2+exowZo2vXrkmSmjVrppkzZ6p06dImp3s0ShaAJxLr5prxlJb7IyhJG315uNDcn9b2+JtrRqWBQmN1siRqZObBkZREX1fzQKG5P5KT0LUzDy4SwM01AQCp0ZUrV9S4cWMdPHhQklSqVCnNnDlTzZs3NzlZ4lCygDTgcTfXfHg6WHQ8IyyPvLlmrJIU879zGPEcn/Zurnn/upnHXRfzYKGJM10s0dfVxC459875b8mh0AAAkDi5cuWSj4+PsmfPrvHjx+vNN9+Us7Oz2bESjZIFPCSpN9dMygIBiRnZiW9bar+55sOFJtZ0sXiunXnkdLFEFqF4i84DJYebawIAkHZcv35dU6dO1ejRo+Xt7S2LxaIlS5Yoa9asypo1q9nxkoyShTTDZjN06nqYjlwK1e3I6ARXNbt/s8zE3lwzrRUai0WxR1fiKR3Ojxx9+XdkJaFlmp0fs6rZw89RaAAAwJOIiorSnDlz9N577+nWrVuyWCyaOnWqJKlIkSImp3tylCykSlF3bTr2T6gOXgzRwQvBOngxRIcuhSg8KibFszxu9CS+6WTOjxp9eWDZ54RKy6NKUiYn7kUDAADSNsMw9O2332ro0KE6duyYJKl8+fJq2rSpyckcg5IF092JitHhy/+WqQMXg/X35dvx3jvH3dmqknmzKJuHyyOnkz1ccuIWoUeveOZsLzsUGgAAAEf666+/NHjwYG3atEnSveuvJk6cqB49eshqtZqczjEoWUhRwXeidfBisA5dDNGB/5WqE1dvx7uIgpdbJpXJ562y+b1UNr+3yuTzUuEcniweAAAAkIYFBQVp06ZNcnFx0eDBgzVq1Ch5eXmZHcuhKFlINv+ERsSa7nfgYrDO3bgT7745s7iqbD4ve6kqk89bBbK6M4oEAACQxkVERCg0NFQ5c+aUJE2aNEnR0dGaMGGCChcubHK65GExjNR+ZxnHCgkJkbe3t4KDg9NdYzaLYRg6f/OODl78X5n6X6n6JzQy3v19s7mrTN5/y1SZfF7K5eWWwqkBAACQnAzD0KpVqzRs2DBVqlRJq1evNjtSHMnVDRjJQpLE2AyduhYWp1AF34mOs6+TRSqS09M+QlUmv5fK5PWWt0fauccBAAAAku7PP//U4MGDtXnzZkn3VhG8du2acuTIYXKylEHJQoKi7tr095XQe9dP/a9UHboYojvRcVf4c7Za9EyeLPYRqtL5vFUqbxZ5uPAtBgAAkFFcvHhRo0aN0uLFiyVJ7u7uGjZsmIYPH67MmTObnC7l8BswJEnhUXd1+FLovRGqC/9b4e9KqKJj4s4mdXe2qnQ+L5XJ56Wy/xuhKp4ri1wyca8kAACAjGrLli1q2rSpwsPDJUmdO3dWYGCgfH19TU6W8ihZGVBwePS/0/3+978nE1jhz9vd+V6Z+t/qfmXyeatwjsys8AcAAIBYqlSpouzZs6tChQoKCgpSjRo1zI5kGkpWOvdPSESsa6cOXAzW+Zvxr/CXK4trrDJVJp8XK/wBAAAgXtu3b9e8efM0b948Wa1Wubu7a+vWrSpQoECG//2RkpVO3F/h78EydfBiiK4msMJfwWwe9hGq+1P/cmVhhT8AAAA82pkzZzRixAh99dVXkqTatWurZ8+ekpQhpwbGh5KVBt1b4e+2DlwI0cGLwfb/DYm4G2dfJ4tUNKdn7ELFCn8AAABIotDQUE2ZMkWzZs1SRESELBaLunfvrhdeeMHsaKkOJSuVi7wbo2NXbscqU4cvhca7wp+L1Ukl8njeW4win5fK5PdWqTxecnexmpAcAAAA6YHNZtPixYs1atQoXb58WZLUoEEDzZo1S5UqVTI5XepEyXKQM9fDNOzrv3T2RrjDzmnI0I2wqHhX+PNwsap0Xi97mSqTjxX+AAAA4HgWi0Xz5s3T5cuXVbRoUc2YMUOtW7fO8NddPQolywFOXQtTx8926HJIRLKc38fD2b5ceun/Tfvzy84KfwAAAEgeJ06cUM6cOeXl5SWLxaLZs2dr8+bN6tevn1xdXc2Ol+pRsp7Siau31WneDl0JiVTxXJ6a+kp5uVgdN5rk4+Gs/D6s8AcAAIDkFxwcrEmTJun999+Xv7+/AgMDJUnVq1dX9erVTU6XdlCynsLxf0LVcd5OXQ2N1DO5s2hprxrK4UmzBwAAQNpy9+5dzZ8/X2PGjNHVq1clSYcOHZJhGPyx/wlwAc8TOnYlVK9+dq9glcyTRcsoWAAAAEiDfvzxR1WqVElvv/22rl69qpIlS2rdunVas2YNBesJUbKewNHLoXr1sx26djtSpfN6aVmvZ5WdggUAAIA0JigoSM8//7wOHDigbNmy6cMPP9Rff/2lF154gYL1FChZSXT4Uog6ztuh62FRKpPPS8t61VC2zC5mxwIAAACSrF27dvL29tagQYN07Ngx9evXT87O3E/1aXFNVhIcvBis1+bv1M3waJUv4K0vetTgpr4AAABIE6Kjo/Xxxx/rwIEDmjdvniSpQIECOnPmjLy9vU1Ol75QshLpwIVgvbZgp26FR6uCr4+W9Kgub3cKFgAAAFI3wzC0bt06DRkyRH///bckqWfPnnr22WcliYKVDChZkvaeu6WBX+1RWOTdBPcJuXNXUTE2VSroo8U9qsvLjYIFAACA1G3//v3y9/fXTz/9JEnKmTOnJk6cqGrVqpmcLH2jZEn6YvsZnbke/tj9qvll1cJu1ZSFggUAAIBU7NatWxoxYoTmzZsnm80mFxcXDRo0SKNGjWLkKgVk+JJlsxn69e9/JEmz2ldQmXzxf9NZnSwqmjMzq6wAAAAg1XNxcdG6detks9n0yiuvaOrUqSpSpIjZsTKMDF+yDlwM1rXbUfJ0zaSW5fPJJRMLLgIAACBtMQxD33//vZ577jlZrVZ5eHho3rx58vDwUL169cyOl+Fk2EaxbOcZLd52Wr2/+FOSVKdYDgoWAAAA0pzdu3erYcOGat68uZYsWWLf3qxZMwqWSTLsSNbk9Ufk5Ophf9zgmZwmpgEAAACS5tKlSxo9erQWLVokwzDk5uamW7dumR0LysAlS5JalM8rScrp6ao2lfKbnAYAAAB4vDt37mjWrFkKDAxUWFiYJKlTp04KDAxUwYIFTU4HKQOXrCI5M2tOp8pmxwAAAACSpEuXLlq5cqUk6dlnn1VQUJD9nldIHTLsRUiZnFglEAAAAGmDYRj2z4cMGaKCBQtq2bJl2rZtGwUrFcqwI1lOlCwAAACkcufOndOIESPk5+enSZMmSbo3enX8+HE5O3Pv1tQqw45kHbkUanYEAAAAIF63b9/WmDFjVKJECS1btkxBQUG6ceOG/XkKVuqWYUtWdb9sZkcAAAAAYrHZbFq8eLFKlCihCRMmKCIiQvXq1dOWLVuULRu/v6YVGXi6oNkJAAAAgH8dOHBA3bp1059/3ruPa5EiRTR9+nS99NJLsli41CUtybAlyyK+UQEAAJB6eHt769ChQ/Ly8lJAQIAGDBggV1dXs2PhCWTYkhUeddfsCAAAAMjAQkJCtHbtWr322muSJF9fX61YsULVq1dXrly5TE6Hp5FhJ805MeQKAAAAE8TExOizzz5TsWLF9Prrr2vLli3251q2bEnBSgcy7EhWybxZzI4AAACADOann36Sv7+/9u/fL0kqUaKEbDabyangaBl2JAsAAABIKUePHlWrVq303HPPaf/+/cqaNatmz56tAwcOqF69embHg4Nl2JEsAAAAICXExMSoWbNmOn36tDJlyqQ+ffpo7NixLMmejlGyAAAAAAeLjo6W1WqVk5OTrFar3nvvPS1fvlwzZsxQyZIlzY6HZMZ0QQAAAMBBDMPQ+vXrVb58eX3xxRf27a+99pr++9//UrAyCEoWAAAA4AAHDx5Us2bN1KJFCx05ckRBQUEyDEOSuJlwBkPJAgAAAJ7C1atX1adPH5UvX14//PCDnJ2dNWzYMP3666+UqwyKa7IAAACAJ/TVV1+pd+/eCg4OliS9/PLLmjZtmooWLWpyMpiJkgUAAAA8oYIFCyo4OFiVKlXSrFmz1KBBA7MjIRWgZAEAAACJtHfvXu3bt09du3aVJNWqVUsbN25U/fr1ZbVaTU6H1IJrsgAAAIDHuHTpknr27KnKlSurd+/eOnPmjP25Ro0aUbAQCyNZAAAAQALu3LmjoKAgTZ48WWFhYZKkNm3aKFMmfo1GwvjuAAAAAB5iGIaWL1+ud955R2fPnpUk1ahRQ0FBQapZs6bJ6ZDaUbIAAACAh1y6dEndu3dXRESEChQooClTpqhjx45ycuJqGzweJQsAAACQdPPmTWXNmlWSlC9fPo0ZM0Z3797VkCFD5OHhYXI6pCVUcQAAAGRoYWFhGjt2rAoUKKBt27bZt48cOVLvvvsuBQtJlmFL1u2Iu2ZHAAAAgIlsNpuWLFmiEiVK6L333lN4eLiWLVtmdiykAxl2uuBdm2F2BAAAAJhky5YtGjx4sP744w9JUuHChTV9+nS9/PLLJidDepBhS1ZeH3ezIwAAAMAEAwYM0IcffihJypIliwICAjRgwAC5ubmZnAzpRYYtWRl2niQAAEAGV6VKFTk5OemNN97Qe++9p9y5c5sdCelMxi1ZFovZEQAAAJDMYmJitHDhQmXNmlWvvPKKJOn1119X9erVVapUKZPTIb3KsCXr/K1wsyMAAAAgGW3atEmDBw/WX3/9pXz58ql58+bKnDmznJycKFhIVhl21lyRHJ5mRwAAAEAyOHbsmNq0aaPGjRvrr7/+ko+Pj4YNGyZnZ2ezoyGDyLAjWcwWBAAASF9u3rypCRMm6KOPPlJ0dLSsVqv69OmjsWPHKnv27GbHQwZCyQIAAEC6cOjQIQUFBUmSXnjhBc2YMYNpgTAFJQsAAABp1smTJ1WkSBFJUu3atTVy5EjVr19fTZs2NTkZMrIMe02WRbQsAACAtOrQoUNq3ry5ypYtq3Pnztm3T548mYIF02XYkgUAAIC059q1a+rXr5/Kly+vDRs26O7du9qyZYvZsYBYMmzJYrogAABA2hEVFaVZs2apWLFimjNnjmJiYtSmTRsdOnRIHTt2NDseEIvpJWvOnDny8/OTm5ubatSood9///2R+8+ePVvPPPOM3N3d5evrq8GDBysiIiLJr0vHAgAASBvu3r2ratWqaciQIQoODlbFihW1adMmffPNNypWrJjZ8YA4TC1Zy5cvl7+/v8aOHavdu3erQoUKatq0qf75559491+2bJlGjBihsWPH6vDhw1qwYIGWL1+uUaNGJfm1LwcnvZgBAAAg5WXKlEktW7ZU7ty5NX/+fP3xxx9q2LCh2bGABJlasmbNmqVevXqpe/fuKl26tObOnSsPDw8tXLgw3v23bdum2rVrq1OnTvLz89Pzzz+vjh07Pnb0Kz75s7o/bXwAAAAkg8uXL6tXr17avn27fduoUaN07Ngx9ezZU1ar1cR0wOOZVrKioqL0559/qkmTJv+GcXJSkyZNYv1APahWrVr6888/7aXq5MmTWr9+vV544YUEXycyMlIhISGxPgAAAJD6REREKDAwUMWLF9f8+fM1ePBgGYYhScqcObOyZMlickIgcUy7T9a1a9cUExOj3Llzx9qeO3duHTlyJN5jOnXqpGvXrqlOnToyDEN3795V7969HzldMDAwUOPHj3dodgAAADiOYRhauXKlhg8frtOnT0uSqlWrppkzZ8rCamVIg0xf+CIpfvnlF02ePFkff/yxdu/erdWrV2vdunWaMGFCgseMHDlSwcHB9o/791EIvXM3pWIDAAAgAbt371a9evXUvn17nT59Wvnz59cXX3yhHTt2qHbt2mbHA56IaSNZOXLkkNVq1ZUrV2Jtv3LlivLkyRPvMe+++65ef/11vfHGG5KkcuXKKSwsTG+++aZGjx4tJ6e4ndHV1VWurq5xtrs4p6l+CQAAkC7t27dPW7ZskYeHh4YPH66hQ4cqc+bMZscCnoppTcPFxUVVqlTRxo0b7dtsNps2btyomjVrxntMeHh4nCJ1/8LH+/N1EyuLm2n9EgAAIMMKDw/Xvn377I+7du2qgIAAHT16VGPHjqVgIV0wtWn4+/ura9euqlq1qqpXr67Zs2crLCxM3bt3lyR16dJF+fPnV2BgoCSpVatWmjVrlipVqqQaNWro+PHjevfdd9WqVaskrzLD/F4AAICUY7PZ7LfjkaSjR48qc+bMcnJyeuSlH0BaZGrJ6tChg65evaoxY8bo8uXLqlixojZs2GBfDOPs2bOxRq4CAgJksVgUEBCgCxcuKGfOnGrVqpUmTZqU5NemYgEAAKSMbdu2adCgQdq1a5ckqVChQjp16pTKli1rcjIgeViMpM6zS+NCQkLk7e2tKWt2653WlcyOAwAAkG6dOXNG77zzjpYvXy5J8vT01OjRozVo0CC5ubmZnA74txsEBwfLy8vLYefNsBcm5fGOuxgGAAAAHOP8+fMqWbKkIiIiZLFY1LNnT02YMCHBBc6A9CTDliwAAAAknwIFCqhly5a6fv26goKCVKFCBbMjASmGdcwBAADw1H755RfVqVNH58+ft29bvHixNm7cSMFChkPJAgAAwBM7fvy4XnrpJTVs2FBbt27V+PHj7c95eHiwojMypAxbsviBBwAAeHK3bt3S0KFDVbp0aa1Zs0ZWq1V9+/a133oHyMi4JgsAAABJMn/+fI0cOVLXrl2TJDVr1kwzZ85U6dKlTU4GpA4ZtmQxjgUAAPBkTpw4oWvXrqlUqVKaOXOmmjdvbnYkIFXJsCULAAAAiXP48GHFxMTYbx48cuRI+fn5qUePHnJ2djY5HZD6ZOBrssxOAAAAkLpdv35d/fv3V7ly5dSrVy8ZhiFJ8vLy0ltvvUXBAhKQYUsWAAAA4hcVFaWgoCAVK1ZMH330kWJiYpQrVy6FhoaaHQ1IE5guCAAAAEmSYRj69ttvNXToUB07dkySVL58eQUFBalRo0YmpwPSjgxbspguCAAAENt///tftW7dWpKUK1cuTZo0Sd27d5fVajU5GZC2ZNiSBQAAAMlms8nJ6d4VJC+88IKeffZZNWjQQCNHjpSXl5fJ6YC0iZIFAACQAUVEROj999/XF198od9//10eHh6yWq3asmULI1fAU2LhCwAAgAzEMAytXLlSpUuX1ogRI3Tw4EEtWbLE/jwFC3h6lCwAAIAM4s8//1T9+vXVrl07nTp1Svny5dOiRYv05ptvmh0NSFeYLggAAJDO3b17V2+88YYWL14sSXJ3d9ewYcM0fPhwZc6c2eR0QPpDyQIAAEjnMmXKpJCQEEnSa6+9psmTJ8vX19fkVED6xXRBAACAdMZms2np0qW6cOGCfdvMmTO1c+dOffHFFxQsIJlRsgAAANKR7du3q1atWnrttdc0atQo+/bChQurevXqJiYDMg5KFgAAQDpw5swZdezYUbVq1dLOnTvl6empUqVKyTAMs6MBGQ7XZAEAAKRht2/f1pQpUzRz5kxFRETIYrGoR48emjhxovLkyWN2PCBDomQBAACkYTNmzNCkSZMkSQ0aNFBQUJAqVqxobiggg2O6IAAAQBoTHh5u/9zf31+1atXSN998o02bNlGwgFSAkSwAAIA04sSJExo+fLiuXLmizZs3y2KxyMvLS1u3bjU7GoAHULIAAABSueDgYE2cOFEffPCBoqKi5OTkpN27d6tKlSpmRwMQjww7XdAii9kRAAAAHunu3buaO3euihcvrhkzZigqKkrPP/+89u3bR8ECUjFGsgAAAFKh8+fPq1mzZjp48KAk6ZlnntGsWbPUvHlzWSz8sRhIzTLuSBb/NgEAgFQsb968slqtypYtmz744APt379fL7zwAgULSAMYyQIAAEgFbty4odmzZ2vkyJFyd3eX1WrVV199pdy5cytbtmxmxwOQBJQsAAAAE0VHR+uTTz7RuHHjdPPmTbm6umr06NGSpFKlSpmcDsCToGQBAACYwDAMrV+/XkOGDNHRo0clSeXKlVPNmjVNTgbgaWXYa7IAAADMcuDAATVt2lQtW7bU0aNHlTNnTn366afas2ePGjVqZHY8AE+JkSwAAIAUNnbsWP34449ycXHRoEGDNGrUKHl7e5sdC4CDULIAAACSWWRkpO7cuSMfHx9J0tSpU5UpUyYFBgaqSJEi5oYD4HBMFwQAAEgmhmFo1apVKl26tAYPHmzfXqxYMS1fvpyCBaRTjGQBAAAkg927d2vw4MH67bffJN0bzQoJCZGXl5fJyQAkN0ayAAAAHOjixYvq3r27qlatqt9++01ubm569913deTIEQoWkEEwkgUAAOAgGzduVOvWrRUWFiZJ6tSpkwIDA1WwYEGTkwFISZQsAAAAB6latao8PDxUrlw5BQUF6dlnnzU7EgATMF0QAADgCe3cuVP9+/eXYRiSJG9vb23fvl3btm2jYAEZGCULAAAgic6dO6fOnTvr2Wef1UcffaSVK1fanytatKgsFouJ6QCYjemCAAAAiXT79m1NmzZN06dPV0REhCwWi7p166Y6deqYHQ1AKkLJAgAAeAybzaYvvvhCI0eO1KVLlyRJ9erVU1BQkCpXrmxyOgCpDdMFAQAAHsMwDM2cOVOXLl1S4cKFtWrVKv3yyy8ULADxYiQLAAAgHidPnlS+fPnk5uYmq9Wq999/X3/88YcGDBggV1dXs+MBSMUYyQIAAHhASEiI3nnnHZUqVUpBQUH27Q0bNtSwYcMoWAAei5EsAAAASTExMVqwYIECAgJ09epVSdKuXbtkGAarBQJIEkayAABAhrdx40ZVqlRJb731lq5evaoSJUro22+/1apVqyhYAJKMkgUAADK0wMBANWnSRPv371fWrFk1e/ZsHThwQC1btqRgAXgilCwAAJChvfLKK/Lw8NCAAQN0/PhxDRw4UM7OzmbHApCGcU0WAADIMKKjozV37lydOXNGM2bMkCQVL15c586dU7Zs2UxOByC9oGQBAIB0zzAMrV+/XkOHDtWRI0dksVjUpUsXlS9fXpIoWAAc6qmmC0ZERDgqBwAAQLI4cOCAmjVrppYtW+rIkSPKkSOHPv74Y5UuXdrsaADSqSSXLJvNpgkTJih//vzy9PTUyZMnJUnvvvuuFixY4PCAAAAAT+LmzZvq06ePKlSooB9++EHOzs4aOnSojh07pt69eytTJib0AEgeSS5ZEydO1KJFizRt2jS5uLjYt5ctW1bz5893aDgAAIAnZbFYtGLFCtlsNr300ks6dOiQpk+fLh8fH7OjAUjnklyylixZos8++0ydO3eW1Wq1b69QoYKOHDni0HAAAACJZRiGNm3aJMMwJEk+Pj769NNP9fPPP2v16tUqVqyYyQkBZBRJLlkXLlyI9x8pm82m6Ohoh4QCAABIij179qhhw4Zq3LixVq9ebd/etm1bNWjQwLxgADKkJJes0qVLa/PmzXG2r1y5UpUqVXJIKAAAgMS4dOmSevbsqSpVqujXX3+Vm5ubLl68aHYsABlckq/4HDNmjLp27aoLFy7IZrNp9erVOnr0qJYsWaL//ve/yZERAAAgljt37igoKEiBgYG6ffu2JKljx46aMmWKChYsaHI6ABldkktW69at9e233+q9995T5syZNWbMGFWuXFnffvutnnvuueTICAAAEMsrr7yi9evXS5Jq1KihoKAg1axZ0+RUAHDPE61dWrduXf3444+OzgIAAJAgwzBksVgkSQMGDNBff/2lKVOmqGPHjnJyeqpbfwKAQyX5X6QiRYro+vXrcbbfunVLRYoUcUgoAACA+86dO6fXXntN06dPt29r2rSpjh8/rs6dO1OwAKQ6Sf5X6fTp04qJiYmzPTIyUhcuXHBIKAAAgLCwMI0dO1bPPPOMli5dqsmTJ9uvv5IkV1dXE9MBQMISPV1w7dq19s+///57eXt72x/HxMRo48aN8vPzc2g4AACQ8dhsNn3xxRcaNWqUfaXAOnXqKCgoSJ6enianA4DHS3TJatOmjaR7d0/v2rVrrOecnZ3l5+enmTNnOjQcAADIWPbt26c33nhDf/zxhySpcOHCmjZtmtq2bWu/HgsAUrtElyybzSbp3j92u3btUo4cOZItFAAAyJjc3Ny0d+9eZcmSRQEBARowYIDc3NzMjgUASZLk1QVPnTqVHDkAAEAGFBISop9++kkvv/yyJNmvv6pfv75y585tcjoAeDJPtIR7WFiYfv31V509e1ZRUVGxnhswYIBDggEAgPQrJiZGn3/+uQICAvTPP/9o9+7dqlixoiSpffv25oYDgKeU5JK1Z88evfDCCwoPD1dYWJiyZcuma9euycPDQ7ly5aJkAQCAR9q0aZP8/f21b98+SVKJEiUUFhZmcioAcJwkL+E+ePBgtWrVSjdv3pS7u7t27NihM2fOqEqVKpoxY0ZyZAQAAOnAsWPH1KZNGzVu3Fj79u2Tj4+PgoKCtH//ftWuXdvseADgMEkeydq7d68+/fRTOTk5yWq1KjIyUkWKFNG0adPUtWtX+5xqAACA+6KiolSvXj1dvnxZVqtVffr00dixY5U9e3azowGAwyV5JMvZ2dl+Z/VcuXLp7NmzkiRvb2+dO3fOsekAAECadffuXRmGIUlycXHR6NGj9cILL2j//v364IMPKFgA0q0kl6xKlSpp165dkqT69etrzJgxWrp0qQYNGqSyZcs6PCAAAEh7vvvuO5UvX15r1qyxb+vbt6/WrVunUqVKmRcMAFJAkkvW5MmTlTdvXknSpEmTlDVrVr399tu6evWqPv30U4cHBAAAacfBgwfVrFkzvfDCCzp8+LCmTZtmf46bCQPIKJJ8TVbVqlXtn+fKlUsbNmxwaCAAAJD2XLt2TWPHjtWnn36qmJgYOTs7a8CAAQoICDA7GgCkuCSPZCVk9+7datmypaNOBwAA0oilS5eqWLFi+vjjjxUTE6M2bdro0KFDmjFjhnx8fMyOBwApLkkl6/vvv9fQoUM1atQonTx5UpJ05MgRtWnTRtWqVZPNZktygDlz5sjPz09ubm6qUaOGfv/990fuf+vWLfXt21d58+aVq6urSpQoofXr1yf5dQEAgGNkz55dwcHBqlixojZt2qRvvvlGxYoVMzsWAJgm0dMFFyxYoF69eilbtmy6efOm5s+fr1mzZql///7q0KGDDhw4kOQLWZcvXy5/f3/NnTtXNWrU0OzZs9W0aVMdPXpUuXLlirN/VFSUnnvuOeXKlUsrV65U/vz5debMGf5KBgBACtq3b5+OHTumV155RZLUrFkzrVu3Tk2bNpXVajU5HQCYz2LcX1v1McqXL6/XX39dw4YN06pVq9SuXTs9++yzWrFihQoUKPBEL16jRg1Vq1ZNH330kSTJZrPJ19dX/fv314gRI+LsP3fuXE2fPl1HjhyRs7PzE71mSEiIvL299Z/fDqlzXVY3AgAgsa5cuaKAgAAtWLBAWbJk0bFjx+L9oygApBX3u0FwcLC8vLwcdt5ETxc8ceKE2rVrJ0l6+eWXlSlTJk2fPv2JC1ZUVJT+/PNPNWnS5N8wTk5q0qSJtm/fHu8xa9euVc2aNdW3b1/lzp1bZcuW1eTJkxUTE5Pg60RGRiokJCTWhySFRSV8DAAA+FdERISmTJmi4sWLa/78+TIMQ82aNXvk//8CQEaW6JJ1584deXh4SLq3BKurq6t9Kfcnce3aNcXExCh37tyxtufOnVuXL1+O95iTJ09q5cqViomJ0fr16/Xuu+9q5syZmjhxYoKvExgYKG9vb/uHr6+vJCmru8sTZwcAICMwDENff/21SpUqpZEjRyo0NFTVqlXTli1btHz58qf6PQAA0rMkLeE+f/58eXp6Srp3F/dFixYpR44csfYZMGCA49I9xGazKVeuXPrss89ktVpVpUoVXbhwQdOnT9fYsWPjPWbkyJHy9/e3Pw4JCbEXLQAAkLBTp06pU6dOunv3rvLnz68pU6aoU6dOcnJy2OLEAJAuJbpkFSxYUPPmzbM/zpMnj7744otY+1gslkSXrBw5cshqterKlSuxtl+5ckV58uSJ95i8efPK2dk51kW1pUqV0uXLlxUVFSUXl7ijU66urnJ1dU1UJgAAMrqQkBD7dQlFihTRkCFD5O7urqFDhypz5swmpwOAtCHRJev06dMOfWEXFxdVqVJFGzduVJs2bSTdG6nauHGj+vXrF+8xtWvX1rJly2Sz2ex/Rfv777+VN2/eeAsWAABInPDwcE2fPl0zZszQ1q1bVb58eUnSlClTTE4GAGmPqeP9/v7+mjdvnhYvXqzDhw/r7bffVlhYmLp37y5J6tKli0aOHGnf/+2339aNGzc0cOBA/f3331q3bp0mT56svn37mvUlAACQptlsNv3nP/9RiRIlNG7cON2+fVuLFy82OxYApGlJuibL0Tp06KCrV69qzJgxunz5sipWrKgNGzbYF8M4e/ZsrHnfvr6++v777zV48GCVL19e+fPn18CBA/XOO++Y9SUAAJBmbdu2TYMGDdKuXbskSYUKFdK0adPsqwkDAJ5Mou+TlV7cXwt/xdajalerhNlxAAAwxdtvv625c+dKkjw9PTV69GgNGjRIbm5uJicDgJSTXPfJMnUkCwAAmKNUqVKyWCzq2bOnJkyYkOCiUwCApKNkAQCQzsXExGjRokUqUKCAmjZtKuneSFbDhg1Vrlw5k9MBQPrzRAtfnDhxQgEBAerYsaP++ecfSdJ3332ngwcPOjQcAAB4Oj///LOqVq2qN954Q/369VNUVJQkydnZmYIFAMkkySXr119/Vbly5bRz506tXr1at2/fliTt27cvwRsCAwCAlHX8+HG99NJLatSokfbu3Stvb2+9/fbbZscCgAwhySVrxIgRmjhxon788cdY96Zq1KiRduzY4dBwAAAgaW7duqWhQ4eqdOnSWrNmjaxWq/r06aPjx4/L39+f+0oCQApI8jVZ+/fv17Jly+Jsz5Url65du+aQUAAA4Mls375dM2fOlCQ1a9ZMM2fOVOnSpU1OBQAZS5JHsnx8fHTp0qU42/fs2aP8+fM7JBQAAEi88+fP2z9v1qyZ+vbtq/Xr1+u7776jYAGACZJcsl599VW98847unz5siwWi2w2m7Zu3aqhQ4eqS5cuyZERAADE4/Dhw2rRooXKli2rq1evSpIsFos++ugjNW/e3OR0AJBxJblkTZ48WSVLlpSvr69u376t0qVLq169eqpVq5YCAgKSIyMAAHjA9evX1b9/f5UrV07r169XWFiYfvvtN7NjAQD+J8nXZLm4uGjevHl69913deDAAd2+fVuVKlVS8eLFkyMfAAD4n6ioKH388ccaP368bt26JUlq3bq1pk+fzv8PA0AqkuSStWXLFtWpU0cFCxZUwYIFkyMTAAB4SGRkpCpXrqxDhw5JksqXL6+goCA1atTI5GQAgIclebpgo0aNVLhwYY0aNcr+Dz0AAEherq6uatiwoXLlyqXPPvtMu3fvpmABQCqV5JJ18eJFDRkyRL/++qvKli2rihUravr06bFWNgIAAE/nypUreuutt7R//377tokTJ+rYsWPq1auXrFariekAAI+S5JKVI0cO9evXT1u3btWJEyfUrl07LV68WH5+fvxFDQCApxQREaGpU6eqePHi+uyzzzRkyBD7cz4+PvLy8jIxHQAgMZJ8TdaDChcurBEjRqhChQp699139euvvzoqFwAAGYphGFq1apWGDx+uU6dOSZKqVq2qMWPGmJwMAJBUSR7Jum/r1q3q06eP8ubNq06dOqls2bJat26dI7MBAJAh/Pnnn6pfv77atWunU6dOKV++fFq8eLF27typOnXqmB0PAJBESR7JGjlypL766itdvHhRzz33nN5//321bt1aHh4eyZEPAIB0b/Pmzdq8ebPc3d01fPhwDRs2TJkzZzY7FgDgCSW5ZP32228aNmyY2rdvrxw5ciRHJgAA0rXw8HCdPXtWJUuWlCT16dNH58+f16BBg1SgQAGT0wEAnlaSS9bWrVuTIwcAAOmezWbTl19+qREjRsjDw0P79++Xi4uLXFxcNGPGDLPjAQAcJFEla+3atWrevLmcnZ21du3aR+774osvOiQYAADpyfbt2zV48GDt3LlTklSoUCGdOnVKzzzzjMnJAACOlqiS1aZNG12+fFm5cuVSmzZtEtzPYrEoJibGUdkAAEjzzpw5oxEjRuirr76SJHl6emrUqFEaNGiQ3N3dTU4HAEgOiSpZNpst3s8BAEDCjh07pvLlyysiIkIWi0U9evTQxIkTlSdPHrOjAQCSUZKXcF+yZIkiIyPjbI+KitKSJUscEgoAgPSgWLFiqlOnjho0aKA///xT8+fPp2ABQAaQ5JLVvXt3BQcHx9keGhqq7t27OyQUAABp0a+//qpGjRrp2rVrku5No1+1apU2bdqkSpUqmZwOAJBSklyyDMOQxWKJs/38+fPy9vZ2SKiUEM+XAADAEzlx4oTatm2rBg0a6Oeff9bkyZPtz3l5ecX7/5sAgPQr0Uu4V6pUSRaLRRaLRY0bN1amTP8eGhMTo1OnTqlZs2bJEhIAgNQoODhYkyZN0vvvv6+oqCg5OTnprbfe0siRI82OBgAwUaJL1v1VBffu3aumTZvK09PT/pyLi4v8/PzUtm1bhwcEACA1mj9/vkaNGqWrV69Kkp5//nnNmjVLZcqUMTkZAMBsiS5ZY8eOlST5+fmpQ4cOcnNzS7ZQAACkdrt379bVq1dVsmRJzZw5U82bN2daIABAUhJK1n1du3ZNjhwAAKRqR48eldVqVbFixSRJ48ePV5kyZfTmm2/K2dnZ5HQAgNQkUQtfZMuWzb5SUtasWZUtW7YEPwAASE9u3LihgQMHqmzZsurXr599e86cOdW3b18KFgAgjkSNZAUFBSlLliz2z5kOAQBI76Kjo/XJJ59o3LhxunnzpqR71yCHh4fLw8PD5HQAgNQsUSXrwSmC3bp1S64sAACYzjAMrVu3TkOHDtXRo0clSeXKldOsWbPUpEkTk9MBANKCJN8na/fu3dq/f7/98f/93/+pTZs2GjVqlKKiohwaDgCAlPb111+rVatWOnr0qHLmzKlPP/1Ue/bsoWABABItySXrrbfe0t9//y1JOnnypDp06CAPDw99/fXXGj58uMMDAgCQ3AzDsH/epk0blSlTRsOHD9exY8f05ptvymq1mpgOAJDWJLlk/f3336pYsaKke3/tq1+/vpYtW6ZFixZp1apVjs6XbLiqDAAQGRmp6dOn69lnn1V0dLSke9dd7dmzR1OnTpW3t7fJCQEAaVGSS5ZhGLLZbJKkn376SS+88IIkydfX174CIQAAqZlhGFq9erVKly6t4cOH6/fff9dXX31lf54VAwEATyPJJatq1aqaOHGivvjiC/36669q0aKFJOnUqVPKnTu3wwMCAOBIu3fvVsOGDdW2bVudPHlSefPm1aJFi9S5c2ezowEA0okk34x49uzZ6ty5s9asWaPRo0fbb8q4cuVK1apVy+EBAQBwhMjISL399ttatGiRDMOQm5ubhg0bpuHDh8vT09PseACAdCTJJat8+fKxVhe8b/r06VwYDABItVxcXHT27FkZhqHOnTsrMDBQvr6+ZscCAKRDSS5Z9/355586fPiwJKl06dKqXLmyw0IBAPC0DMPQ8uXL9dxzzyl79uyyWCz68MMPFRISoho1apgdDwCQjiW5ZP3zzz/q0KGDfv31V/n4+EiSbt26pYYNG+qrr75Szpw5HZ0RAIAk2bFjhwYPHqwdO3aof//++uCDDyRJpUqVMjkZACAjSPLCF/3799ft27d18OBB3bhxQzdu3NCBAwcUEhKiAQMGJEdGAAAS5ezZs+rcubNq1qypHTt2KHPmzMqXL5/ZsQAAGUySR7I2bNign376KdZfA0uXLq05c+bo+eefd2g4AAAS4/bt25o6dapmzJihiIgIWSwWdevWTRMnTqRkAQBSXJJLls1mi/f+Ic7Ozvb7ZwEAkJLGjx+vGTNmSJLq1aunoKAgrhUGAJgmydMFGzVqpIEDB+rixYv2bRcuXNDgwYPVuHFjh4YDACAhkZGR9s+HDRumSpUqadWqVfrll18oWAAAUyV5JOujjz7Siy++KD8/P/vSt+fOnVPZsmX1n//8x+EBk43F7AAAgCdx8uRJDR8+XOHh4Vq/fr0kKVeuXPrzzz9lsfCPOwDAfEkuWb6+vtq9e7c2btxoX8K9VKlSatKkicPDAQBwX0hIiCZNmqTZs2crKipKTk5OOnTokEqXLi1JFCwAQKqRpJK1fPlyrV27VlFRUWrcuLH69++fXLkAAJAkxcTEaMGCBQoICNDVq1clSU2aNNGsWbPsBQsAgNQk0SXrk08+Ud++fVW8eHG5u7tr9erVOnHihKZPn56c+QAAGdipU6fUunVr7d+/X5JUokQJzZw5Uy1atGDkCgCQaiV64YuPPvpIY8eO1dGjR7V3714tXrxYH3/8cXJmAwBkcPny5VN4eLiyZs2q2bNn68CBA2rZsiUFCwCQqiW6ZJ08eVJdu3a1P+7UqZPu3r2rS5cuJUswAEDGc+PGDU2cOFHR0dGSJFdXV3399dc6duyYBg4cGO8tRAAASG0SPV0wMjJSmTNntj92cnKSi4uL7ty5kyzBAAAZR3R0tObOnatx48bpxo0b8vHxUb9+/SRJlSpVMjkdAABJk6SFL9599115eHjYH0dFRWnSpEny9va2b5s1a5bj0gEA0jXDMLR+/XoNHTpUR44ckSSVKVOGBS0AAGlaoktWvXr1dPTo0VjbatWqpZMnT9ofM0ceAJBYBw4c0JAhQ/TDDz9IknLkyKEJEybojTfeUKZMSb7DCAAAqUai/1/sl19+ScYYAICMxt/fXz/++KOcnZ01aNAgjR49OtbMCAAA0qpEL3wBAMDTiIyM1O3bt+2Pp0+frrZt2+rw4cOaNm0aBQsAkG5QsgAAycowDH3zzTcqU6aMAgIC7NsrVKiglStXqmjRoiamAwDA8ShZAIBks2fPHjVq1Egvv/yyTpw4odWrV7MqLQAg3aNkAQAc7tKlS+rZs6eqVKmiX375RW5ubho9erQOHjwod3d3s+MBAJCsWL4JAOBQ3333ndq3b2+//urVV1/VlClTVKhQIZOTAQCQMp5oJGvz5s167bXXVLNmTV24cEGS9MUXX2jLli0ODQcASHsqV64si8WiGjVqaNu2bfryyy8pWACADCXJJWvVqlVq2rSp3N3dtWfPHkVGRkqSgoODNXnyZIcHBACkbr///rtGjhxpf5w7d27t3LlT27ZtU82aNU1MBgCAOZJcsiZOnKi5c+dq3rx5cnZ2tm+vXbu2du/e7dBwAIDU6/z583r99ddVo0YNTZkyxX5TYUkqVaqUnJy47BcAkDEl+Zqso0ePql69enG2e3t769atW47IBABIxcLCwjRt2jRNnz7dvlJg165dVaZMGZOTAQCQOiS5ZOXJk0fHjx+Xn59frO1btmxRkSJFHJULAJDK2Gw2LV26VCNGjNDFixclSXXr1lVQUJCqVKlicjoAAFKPJM/l6NWrlwYOHKidO3fKYrHo4sWLWrp0qYYOHaq33347OTICAFKB6OhojRs3ThcvXlThwoW1cuVK/frrrxQsAAAekuSRrBEjRshms6lx48YKDw9XvXr15OrqqqFDh6p///7JkREAYJIzZ84of/78ypQpk1xdXTV79mwdPnxYAwYMkJubm9nxAABIlSyGYRhPcmBUVJSOHz+u27dvq3Tp0vL09HR0tmQREhIib29vrdx+VG2fLWF2HABIlUJCQhQYGKigoCDNmjVLffr0MTsSAAAOd78bBAcHy8vLy2HnfeKln1xcXFS6dGlVr149zRQsAMCjxcTEaN68eSpevLimTJmiyMhI/fbbb2bHAgAgTUnydMGGDRvKYrEk+PymTZueKhAAwBybNm3S4MGD9ddff0mSihcvrhkzZqhVq1YmJwMAIG1JcsmqWLFirMfR0dHau3evDhw4oK5duzoqFwAgBY0bN07jx4+XJPn4+Gjs2LHq06ePXFxcTE4GAEDak+SSFRQUFO/2cePG6fbt208dCACQ8lq3bq3Jkyfrrbfe0rhx45Q9e3azIwEAkGY98cIXDzt+/LiqV6+uGzduOOJ0yYaFLwBkdNHR0fr0009148YNjRkzxr798uXLypMnj4nJAABIWcm18EWSR7ISsn37dpbzBYBUbsOGDfL399fhw4eVKVMmderUScWKFZMkChYAAA6S5JL18ssvx3psGIYuXbqkP/74Q++++67DggEAHOfQoUMaMmSINmzYIEnKnj27JkyYID8/P3ODAQCQDiW5ZHl7e8d67OTkpGeeeUbvvfeenn/+eYcFAwA8vftTAufOnauYmBg5OztrwIABCggIkI+Pj9nxAABIl5JUsmJiYtS9e3eVK1dOWbNmTa5MAAAHiYqK0uLFixUTE6M2bdpo+vTp9umBAAAgeSTpZsRWq1XPP/+8bt265dAQc+bMkZ+fn9zc3FSjRg39/vvviTruq6++ksViUZs2bRyaBwDSKsMwtG3bNvvjPHnyaM6cOdq0aZO++eYbChYAACkgSSVLksqWLauTJ086LMDy5cvl7++vsWPHavfu3apQoYKaNm2qf/7555HHnT59WkOHDlXdunUdlgUA0rJ9+/apcePGql27tn766Sf79i5duqhhw4YmJgMAIGNJcsmaOHGihg4dqv/+97+6dOmSQkJCYn0k1axZs9SrVy91795dpUuX1ty5c+Xh4aGFCxcmeExMTIw6d+6s8ePHq0iRIkl+TQBITy5fvqxevXqpUqVK+vnnn+Xq6qpjx46ZHQsAgAwr0SXrvffeU1hYmF544QXt27dPL774ogoUKKCsWbMqa9as8vHxSfJ1WlFRUfrzzz/VpEmTfwM5OalJkybavn37I7PkypVLPXv2fOxrREZGPnURBIDUKCIiQoGBgSpevLjmz58vwzDUoUMHHTlyRG+//bbZ8QAAyLASvfDF+PHj1bt3b/38888Oe/Fr164pJiZGuXPnjrU9d+7cOnLkSLzHbNmyRQsWLNDevXsT9RqBgYEaP37800YFgFSnRYsW2rRpkySpWrVqCgoKUu3atU1OBQAAEl2yDMOQJNWvXz/ZwjxOaGioXn/9dc2bN085cuRI1DEjR46Uv7+//XFISIh8fX2TKyIApJjevXvr6NGjmjJlijp16iQnpyTPAAcAAMkgSUu4WywWh754jhw5ZLVadeXKlVjbr1y5ojx58sTZ/8SJEzp9+rRatWpl32az2SRJmTJl0tGjR1W0aNFYx7i6usrV1dWhuQEgpV24cEGjRo1S7dq19eabb0qSXnnlFbVo0UIeHh4mpwMAAA9KUskqUaLEY4vWjRs3En0+FxcXValSRRs3brQvw26z2bRx40b169cvzv4lS5bU/v37Y20LCAhQaGio3n//fUaoAKQ74eHhmj59uqZNm6bw8HBt2LBBXbp0kZubmywWCwULAIBUKEkla/z48fL29nZoAH9/f3Xt2lVVq1ZV9erVNXv2bIWFhal79+6S7i09nD9/fgUGBsrNzU1ly5aNdbyPj48kxdkOAGmZzWbT0qVLNXLkSF24cEGSVLt2bQUFBcnNzc3kdAAA4FGSVLJeffVV5cqVy6EBOnTooKtXr2rMmDG6fPmyKlasqA0bNtgXwzh79izXGQDIUPbs2aO33npLu3btkiQVKlRI06ZNU7t27Rw+bRsAADiexbi/osVjWK1WXbp0yeElK6WFhITI29tbK7cfVdtnS5gdBwDi+PPPP1WtWjVlzpxZo0eP1qBBgxi9AgAgGdzvBsHBwfLy8nLYeZO8uiAAwLFCQ0O1ZcsWNW/eXJJUpUoVLVy4UM2aNYt3ESAAAJC6JXoens1mS/OjWACQmsTExGjBggUqXry4WrdurePHj9uf69atGwULAIA0ioudAMAEP//8s6pWrao33nhDV65cUaFChXT16lWzYwEAAAegZAFACjp+/LheeuklNWrUSHv37pW3t7dmzpypgwcPqmbNmmbHAwAADpCk1QUBAE8uPDxcNWrU0I0bN2S1WvXWW29p/PjxypEjh9nRAACAA1GyACAZ2Ww2+20oPDw8NGTIEG3evFkzZ85U6dKlTU4HAACSA9MFASCZfP/99ypfvrw2bdpk3zZixAh99913FCwAANIxShYAONjhw4f1wgsvqFmzZjp48KAmTpxof46bqwMAkP7x//YA4CDXr19X//79Va5cOX333XfKlCmTBg8erFWrVpkdDQAApCCuyQIAB1iyZIkGDhyoW7duSZJefPFFTZ8+XSVKlDA3GAAASHGULABwAFdXV926dUvly5dXUFCQGjVqZHYkAABgEkoWADyBv/76S+fPn9cLL7wgSWrfvr2cnZ3VunVrWa1Wk9MBAAAzcU0WACTBlStX9Oabb6pSpUrq3r27QkJCJEkWi0Uvv/wyBQsAAFCyACAxIiIiNHXqVBUvXlzz5s2TzWZT/fr1defOHbOjAQCAVIbpggDwCIZhaNWqVRo+fLhOnTolSapataqCgoJUp04dk9MBAIDUiJIFAI9w6NAhtWvXTpKUP39+BQYGqnPnztzvCgAAJIiSBQAPCQ8Pl4eHhySpTJky6t27t3Lnzq1hw4Ypc+bMJqcDAACpHSULAP4nPDxcM2bM0OzZs7Vr1y4VLVpUkvTJJ5+YnAwAAKQlzHcBkOHZbDYtXbpUzzzzjMaOHaubN29q4cKFZscCAABpFCNZADK07du3a9CgQfr9998lSQULFtS0adPUvn17k5MBAIC0ipIFIMPq1auX5s+fL0ny9PTUyJEjNXjwYLm7u5ucDAAApGWULAAZVsGCBWWxWNS9e3dNnDhRefPmNTsSAABIByhZADIEm82mxYsXq3jx4vb7Ww0ZMkStWrVSxYoVzQ0HAADSFRa+AJDu/fbbb6pWrZp69Oih/v37KyYmRpLk4eFBwQIAAA5HyQKQbp04cUJt27ZV/fr1tXv3bnl7e+u1116TzWYzOxoAAEjHmC4IIN0JDg7WpEmT9P777ysqKkpOTk566623NH78eOXMmdPseAAAIJ2jZAFIdzZs2KDp06dLkp5//nnNnDlTZcuWNTkVAADIKChZANKFy5cvK0+ePJKk9u3ba926dXr11VfVvHlzWSwWk9MBAICMhGuyAKRpR44cUcuWLVWhQgWFhIRIkiwWi5YsWaIXXniBggUAAFIcJQtAmnT9+nUNGDBA5cqV07p163Tjxg399ttvZscCAACgZAFIW6Kjo/X++++rePHi+vDDD3X37l21atVKBw4cUMuWLc2OBwAAwDVZANKOsLAwVa1aVUeOHJEklStXTrNmzVKTJk1MTgYAAPAvRrIApBmZM2dW1apVlTNnTn366afas2cPBQsAAKQ6lCwAqdbVq1fVt29fnTx50r5t1qxZOnbsmN58801ZrVYT0wEAAMSP6YIAUp3IyEh98MEHmjhxokJCQvTPP//o66+/liRuJgwAAFI9ShaAVMMwDH3zzTcaNmyYffSqcuXK6t+/v8nJAAAAEo/pggBShd27d6thw4Zq27atTp48qbx58+rzzz/Xrl27VK9ePbPjAQAAJBojWQBShW+//Va//vqr3NzcNGzYMA0fPlyenp5mxwIAAEgyShYAU9y5c0eXLl1SkSJFJEnDhg3T1atXNXz4cBUsWNDkdAAAAE+O6YIAUpRhGPryyy/1zDPP6JVXXlFMTIwkycPDQx999BEFCwAApHmULAApZseOHapVq5Y6deqkc+fO6dq1azp79qzZsQAAAByKkgUg2Z07d06dO3dWzZo1tWPHDmXOnFkTJkzQ0aNHVbhwYbPjAQAAOBTXZAFIVvv371eNGjV0584dWSwWdevWTRMnTlS+fPnMjgYAAJAsKFkAklWZMmVUvnx5ubq6KigoSJUrVzY7EgAAQLJiuiAAh9q8ebNatGih0NBQSZKTk5PWr1+vX375hYIFAAAyBEoWAIc4efKkXnnlFdWrV0/r16/X9OnT7c9ly5ZNFovFxHQAAAAph+mCAJ5KSEiIJk2apNmzZysqKkpOTk7q1auX+vXrZ3Y0AAAAU1CyADyxefPmafTo0bp69aokqUmTJpo1a5bKlStncjIAAADzULIAPLFffvlFV69eVYkSJTRz5ky1aNGCaYEAACDDo2QBSLSjR4/Kw8NDvr6+kqQpU6aoevXq6tOnj5ydnU1OBwAAkDqw8AWAx7px44YGDRqksmXLaujQofbtvr6+GjhwIAULAADgAYxkAUhQdHS05s6dq3HjxunGjRuSpPDwcEVFRcnFxcXkdAAAAKkTI1kA4jAMQ+vXr1f58uU1YMAA3bhxQ2XLltUPP/ygb7/9loIFAADwCIxkAYhjyZIl6tatmyQpR44cmjBhgt544w1lysQ/GQAAAI/DSBYASfdGr+575ZVXVLhwYQ0bNkzHjx9X7969KVgAAACJxG9NQAYXGRmpDz/8UBs2bNAPP/wgJycnZc6cWYcPH5arq6vZ8QAAANIcRrKADMowDH3zzTcqU6aMhg0bpo0bN2rNmjX25ylYAAAAT4aSBWRAe/bsUaNGjfTyyy/rxIkTypMnjxYuXKjWrVubHQ0AACDNY7ogkIGEhYVpwIAB+vzzz2UYhtzc3DRkyBCNGDFCnp6eZscDAABIFyhZQAbi7u6u/fv3yzAMdezYUVOmTFHBggXNjgUAAJCuULKAdMwwDK1atUrNmjWTp6ennJycNHfuXEVGRqpmzZpmxwMAAEiXuCYLSKd+//131alTR+3atdPUqVPt2ytXrkzBAgAASEaULCCdOX/+vF5//XXVqFFD27Ztk4eHh7y8vMyOBQAAkGEwXRBIJ8LCwjRt2jRNnz5dd+7ckSR17dpVkydPVr58+UxOBwAAkHFQsoB0YtiwYfrkk08kSXXq1FFQUJCqVq1qcioAAICMh+mCQBoWHR1t//ydd95R6dKl9fXXX+u3336jYAEAAJiEkSwgDTp16pTeeecdWa1Wffnll5KkQoUK6cCBA7JYLCanAwAAyNgYyQLSkJCQEI0cOVKlSpXS119/rRUrVujUqVP25ylYAAAA5qNkAWlATEyM5s+frxIlSmjKlCmKjIxU48aNtWfPHhUuXNjseAAAAHgA0wWBVO7YsWNq166d9u3bJ0kqUaKEZsyYoZYtWzJyBQAAkAoxkgWkcnnz5tU///wjHx8fBQUFaf/+/WrVqhUFCwAAIJViJAtIZW7duqUFCxZo8ODBcnJykqenp1avXq3ixYsre/bsZscDAADAY1CygFTi7t27+vTTTzV27Fhdv35duXLl0uuvvy5JevbZZ01OBwAAgMSiZAGpwIYNG+Tv76/Dhw9LkkqXLq0CBQqYnAoAAABPgmuyABMdOnRIzZs3V/PmzXX48GFlz55dH3/8sfbt26eGDRuaHQ8AAABPgJEswEQ9e/bUjh075OzsrAEDBiggIEA+Pj5mxwIAAMBTYCQLSEFRUVG6c+eO/fH06dPVpk0bHTp0SDNmzKBgAQAApAOpomTNmTNHfn5+cnNzU40aNfT7778nuO+8efNUt25dZc2aVVmzZlWTJk0euT+QGhiGof/7v/9TmTJlFBgYaN9ep04dffPNNypWrJiJ6QAAAOBIppes5cuXy9/fX2PHjtXu3btVoUIFNW3aVP/880+8+//yyy/q2LGjfv75Z23fvl2+vr56/vnndeHChRRODiTOvn371LhxY7Vp00bHjx/Xf/7zH0VHR5sdCwAAAMnEYhiGYWaAGjVqqFq1avroo48kSTabTb6+vurfv79GjBjx2ONjYmKUNWtWffTRR+rSpctj9w8JCZG3t7dWbj+qts+WeOr8QEKuXLmigIAALViwQIZhyNXVVUOGDNGIESOUJUsWs+MBAABkePe7QXBwsLy8vBx2XlMXvoiKitKff/6pkSNH2rc5OTmpSZMm2r59e6LOER4erujoaGXLli3e5yMjIxUZGWl/HBIS8nShgURYu3atXnvtNYWGhkqSOnTooClTpsjPz8/cYAAAAEh2pk4XvHbtmmJiYpQ7d+5Y23Pnzq3Lly8n6hzvvPOO8uXLpyZNmsT7fGBgoLy9ve0fvr6+T50beJwKFSooKipK1atX19atW/XVV19RsAAAADII06/JehpTpkzRV199pW+++UZubm7x7jNy5EgFBwfbP86dO5fCKZER7Nq1S5MnT7Y/LlSokHbu3Knt27erVq1aJiYDAABASjN1umCOHDlktVp15cqVWNuvXLmiPHnyPPLYGTNmaMqUKfrpp59Uvnz5BPdzdXWVq6urQ/ICDzt//rxGjRqlL774QpLUqFEjPfvss5LujWYBAAAg4zF1JMvFxUVVqlTRxo0b7dtsNps2btyomjVrJnjctGnTNGHCBG3YsEFVq1ZNiahALGFhYRo/frxKlChhL1ivv/4601EBAABg7kiWJPn7+6tr166qWrWqqlevrtmzZyssLEzdu3eXJHXp0kX58+e331to6tSpGjNmjJYtWyY/Pz/7tVuenp7y9PQ07etAxmCz2bR06VKNHDnSftuA2rVrKygoSNWqVTM5HQAAAFID00tWhw4ddPXqVY0ZM0aXL19WxYoVtWHDBvtiGGfPnpWT078Dbp988omioqL0yiuvxDrP2LFjNW7cuJSMjgwoPDxcw4cP1+XLl1WoUCFNmzZN7dq1k8ViMTsaAAAAUgnT75OV0rhPFpLq/Pnzypcvn73sL1u2TGfPntWgQYMSXHAFAAAAqV9y3ScrTa8uCCSn0NBQjRo1SsWKFdOXX35p396pUyeNGDGCggUAAIB4UbKAh8TExGjBggUqXry4AgMDFRkZqQ0bNpgdCwAAAGkEJQt4wM8//6yqVavqjTfe0JUrV1SsWDGtWbNGS5YsMTsaAAAA0ghKFvA/o0aNUqNGjbR37155e3tr5syZOnjwoFq3bs3CFgAAAEg0ShbwP82aNZPValWfPn10/Phx+fv7y8XFxexYAAAASGNMX8IdMMPdu3f12WefKSoqSoMGDZIk1atXT6dOneKGwgAAAHgqlCxkON9//738/f116NAheXh4qF27dsqfP78kUbAAAADw1JguiAzj8OHDeuGFF9SsWTMdOnRI2bNn17Rp0+w3vgYAAAAcgZEspHs3btzQ2LFj9cknnygmJkbOzs7q37+/AgIClDVrVrPjAQAAIJ2hZCHdCw4O1meffaaYmBi1bt1a06dPV/Hixc2OBQAAgHSKkoV0xzAM7dmzR5UrV5YkFS5cWEFBQSpZsqQaNWpkcjoAAACkd1yThXTlr7/+0nPPPacqVaro999/t2/v06cPBQsAAAApgpKFdOHKlSt68803ValSJW3cuFEuLi7at2+f2bEAAACQATFdEGlaRESE3n//fU2aNEmhoaGSpHbt2mnq1KkqXLiwyekAAACQEVGykGYZhqFGjRpp+/btkqQqVaooKChIdevWNTkZAAAAMjKmCyLNslgs6tGjh/Lly6fFixfr999/p2ABAADAdJQspBkXL15Ut27d9NVXX9m3de/eXX///be6dOkiJye+nQEAAGA+fitFqhceHq4JEyaoePHiWrx4sUaMGKHo6GhJktVqVebMmU1OCAAAAPyLa7KQatlsNn355ZcaMWKEzp8/L0mqVauWgoKC5OzsbHI6AAAAIH6ULKRKu3fvVp8+fbRz505JUqFChTR16lS1b99eFovF5HQAAABAwihZSJVCQkK0c+dOeXp6atSoURo0aJDc3d3NjgUAAAA8FiULqcLt27e1a9cuNWzYUJLUoEEDzZkzRy+//LLy5MljcjoAAAAg8Vj4Aqay2Wz6/PPPVbx4cbVs2VIXLlywP9enTx8KFgAAANIcShZM8+uvv6pq1arq0aOHLl++rLx58+rixYtmxwIAAACeCiULKe7EiRNq27atGjRooD179sjLy0vTp0/XwYMHVa1aNbPjAQAAAE+Fa7KQokJCQlSpUiWFhobKyclJb731lsaPH6+cOXOaHQ0AAABwCEoWkp1hGPZl1728vNS7d2/t27dPM2fOVNmyZU1OBwAAADgW0wWRrH744QdVqFBBu3btsm+bPHmyNmzYQMECAABAukTJQrI4cuSIWrZsqaZNm2r//v1677337M9lypSJGwoDAAAg3aJkwaFu3LihgQMHqly5clq3bp0yZcqkQYMGacmSJWZHAwAAAFIE12TBYRYtWiR/f3/dvHlTktSqVStNnz5dzzzzjMnJAAAAgJRDyYLDREVF6ebNmypbtqyCgoLUpEkTsyMBAAAAKY6ShSd24MABXb16VQ0bNpQk9ezZU56enmrfvr0yZeJbCwAAABkT12Qhyf755x/17t1bFSpUULdu3XTnzh1JktVqVadOnShYAAAAyND4bRiJFhkZqffff1+TJk1SSEiIJKlatWq6ffu23N3dTU4HAAAApA6ULDyWYRhavXq1hg8frpMnT0qSKleurKCgINWrV8/kdAAAAEDqQsnCY/3xxx965ZVXJEl58+bV5MmT1aVLFzk5MdsUAAAAeBglC/GKjIyUq6urpHtTAjt27KhixYpp+PDh8vT0NDkdAAAAkHpRshDLnTt3NGvWLH300UfavXu38ubNK0launSpLBaLyekAAACA1I/5XpB077qrL7/8UiVLllRAQIAuX76sBQsW2J+nYAEAAACJw0gWtGPHDg0ePFg7duyQJPn6+mratGnq0KGDyckAAACAtIeSlYEZhqEePXpo0aJFkqTMmTNrxIgRGjJkCEuyAwAAAE+IkpWBWSwWZc+eXRaLRd26ddPEiROVL18+s2MBAAAAaRrXZGUgNptNixYt0p49e+zbAgICtGvXLi1cuJCCBQAAADgAJSuD+O2331StWjV1795dAwcOlGEYkiQfHx9VqVLF5HQAAABA+kHJSudOnjypV155RfXr19fu3buVJUsWtWrVSjExMWZHAwAAANIlrslKp4KDgzVp0iS9//77ioqKkpOTk3r16qX33ntPuXLlMjseAAAAkG5RstKpr7/+WtOnT5ckNWnSRLNmzVK5cuVMTgUAAACkf5SsdOTGjRvKli2bJKlbt27asGGDunXrphYtWnAzYQAAUhnDMHT37l2m8APJzNnZWVarNUVfk5KVDvz9998aOnSo9u/fr8OHD8vNzU2ZMmXSypUrzY4GAADiERUVpUuXLik8PNzsKEC6Z7FYVKBAAXl6eqbYa1Ky0rAbN27ovffe05w5c3T37l1ZrVZt2bJFTZo0MTsaAABIgM1m06lTp2S1WpUvXz65uLgw4wRIJoZh6OrVqzp//ryKFy+eYiNalKw0KDo6WnPnztW4ceN048YNSVKLFi00Y8YMlSxZ0uR0AADgUaKiomSz2eTr6ysPDw+z4wDpXs6cOXX69GlFR0dTshC/W7duqWbNmjpy5IgkqWzZspo1a5aee+45k5MBAICkcHLiTjpASjBjpJif7jTGx8dHxYsXV44cOfTJJ59oz549FCwAAAAgFaFkpXJXr17VgAEDdPnyZfu2uXPn6vjx4+rdu7cyZWIwEgAAAEhNKFmpVGRkpGbMmKFixYrpww8/VEBAgP25fPnyydvb28R0AAAASIqjR48qT548Cg0NNTtKuhIVFSU/Pz/98ccfZkeJhZKVyhiGoW+++UZlypTRsGHDFBISokqVKun11183OxoAAMjgunXrJovFIovFImdnZxUuXFjDhw9XREREnH3/+9//qn79+sqSJYs8PDxUrVo1LVq0KN7zrlq1Sg0aNJC3t7c8PT1Vvnx5vffee/YFvtKDkSNHqn///sqSJYvZUZLNnDlz5OfnJzc3N9WoUUO///77I/ePjo7We++9p6JFi8rNzU0VKlTQhg0bYu3j5+dn/5578KNv376SJBcXFw0dOlTvvPNOsn1dT4KSlYrs3btXjRo10ssvv6wTJ04oT548WrhwoXbt2qX69eubHQ8AAEDNmjXTpUuXdPLkSQUFBenTTz/V2LFjY+3z4YcfqnXr1qpdu7Z27typv/76S6+++qp69+6toUOHxtp39OjR6tChg6pVq6bvvvtOBw4c0MyZM7Vv3z598cUXKfZ1RUVFJdu5z549q//+97/q1q3bU50nOTM+reXLl8vf319jx47V7t27VaFCBTVt2lT//PNPgscEBATo008/1YcffqhDhw6pd+/eeumll7Rnzx77Prt27dKlS5fsHz/++KMkqV27dvZ9OnfurC1btujgwYPJ9wUmlZHBBAcHG5KMlduPmh0ljsGDBxuSDDc3NyMgIMAIDQ01OxIAAHCwO3fuGIcOHTLu3Llj32az2YywyGhTPmw2W6Kzd+3a1WjdunWsbS+//LJRqVIl++OzZ88azs7Ohr+/f5zjP/jgA0OSsWPHDsMwDGPnzp2GJGP27Nnxvt7NmzcTzHLu3Dnj1VdfNbJmzWp4eHgYVapUsZ83vpwDBw406tevb39cv359o2/fvsbAgQON7NmzGw0aNDA6duxotG/fPtZxUVFRRvbs2Y3FixcbhmEYMTExxuTJkw0/Pz/Dzc3NKF++vPH1118nmNMwDGP69OlG1apVY227du2a8eqrrxr58uUz3N3djbJlyxrLli2LtU98GQ3DMPbv3280a9bMyJw5s5ErVy7jtddeM65evWo/7rvvvjNq165teHt7G9myZTNatGhhHD9+/JEZn1b16tWNvn372h/HxMQY+fLlMwIDAxM8Jm/evMZHH30Ua9vLL79sdO7cOcFjBg4caBQtWjTO923Dhg2NgICAeI+J72fuvvvdIDg4OMHXfBKsmmCiO3fu6Pr16ypQoIAk6d1331VoaKjeffddFSxY0OR0AAAgpdyJjlHpMd+b8tqH3msqD5cn+5XwwIED2rZtmwoVKmTftnLlSkVHR8cZsZKkt956S6NGjdKXX36pGjVqaOnSpfL09FSfPn3iPb+Pj0+822/fvq369esrf/78Wrt2rfLkyaPdu3fLZrMlKf/ixYv19ttva+vWrZKk48ePq127drp9+7Y8PT0lSd9//73Cw8P10ksvSZICAwP1n//8R3PnzlXx4sX122+/6bXXXlPOnDkTnHm0efNmVa1aNda2iIgIValSRe+88468vLy0bt06vf766ypatKiqV6+eYMZbt26pUaNGeuONNxQUFKQ7d+7onXfeUfv27bVp0yZJUlhYmPz9/VW+fHndvn1bY8aM0UsvvaS9e/cmeOuAyZMna/LkyY98vw4dOhTv76hRUVH6888/NXLkSPs2JycnNWnSRNu3b0/wfJGRkXJzc4u1zd3dXVu2bIl3/6ioKP3nP/+Rv79/nGXZq1evrs2bNz8yf0qiZJnAMAwtX75c77zzjgoXLqyff/5ZFotFWbNm1bx588yOBwAAkKD//ve/8vT01N27dxUZGSknJyd99NFH9uf//vtveXt7K2/evHGOdXFxUZEiRfT3339Lko4dO6YiRYrI2dk5SRmWLVumq1evateuXcqWLZskqVixYkn+WooXL65p06bZHxctWlSZM2fWN998Y78eftmyZXrxxReVJUsWRUZGavLkyfrpp59Us2ZNSVKRIkW0ZcsWffrppwmWrDNnzsQpWfnz549VRPv376/vv/9eK1asiFWyHs44ceJEVapUKVYhWrhwoXx9ffX333+rRIkSatu2bazXWrhwoXLmzKlDhw6pbNmy8Wbs3bu32rdv/8j3K1++fPFuv3btmmJiYpQ7d+5Y23Pnzm2/t2t8mjZtqlmzZqlevXoqWrSoNm7cqNWrVysmJibe/desWaNbt27FO+0yX758OnPmzCPzpyRKVgr7/fffNXjwYG3btk2SZLPZdPHiReXPn9/kZAAAwCzuzlYdeq+paa+dFA0bNtQnn3yisLAwBQUFKVOmTHF+qU8swzCe6Li9e/eqUqVK9oL1pKpUqRLrcaZMmdS+fXstXbpUr7/+usLCwvR///d/+uqrryTdG+kKDw+Pc4/SqKgoVapUKcHXuXPnTpwRm5iYGE2ePFkrVqzQhQsXFBUVpcjISHl4eDwy4759+/Tzzz/bR9oedOLECZUoUULHjh3TmDFjtHPnTl27ds0+wnf27NkES1a2bNme+v1Mqvfff1+9evVSyZIlZbFYVLRoUXXv3l0LFy6Md/8FCxaoefPm8ZY9d3d3hYeHJ3fkRKNkpZBz585p5MiRWrp0qSTJw8NDI0aM0JAhQ+L8MAEAgIzFYrE88ZS9lJY5c2b7qNHChQtVoUIFLViwQD179pQklShRQsHBwbp48WKcX4ajoqJ04sQJNWzY0L7vli1bFB0dnaTRLHd390c+7+TkFKfARUdHx/u1PKxz586qX7++/vnnH/34449yd3dXs2bNJN2bpihJ69ati/MHcldX1wTz5MiRQzdv3oy1bfr06Xr//fc1e/ZslStXTpkzZ9agQYPiLG7xcMbbt2+rVatWmjp1apzXuT962KpVKxUqVEjz5s1Tvnz5ZLPZVLZs2UcunPE00wVz5Mghq9WqK1euxNp+5coV5cmTJ8Hz5cyZU2vWrFFERISuX7+ufPnyacSIESpSpEicfc+cOaOffvpJq1evjvdcN27cUM6cOR+ZPyWxumAK+OOPP/TMM8/YC1bXrl31999/691336VgAQCANMvJyUmjRo1SQECA7ty5I0lq27atnJ2dNXPmzDj7z507V2FhYerYsaMkqVOnTrp9+7Y+/vjjeM9/69ateLeXL19ee/fuTXCJ95w5c+rSpUuxtu3duzdRX1OtWrXk6+ur5cuXa+nSpWrXrp29AJYuXVqurq46e/asihUrFuvD19c3wXNWqlRJhw4dirVt69atat26tV577TVVqFAh1jTKR6lcubIOHjwoPz+/OBkyZ86s69ev6+jRowoICFDjxo1VqlSpOAUvPr1799bevXsf+ZHQdEEXFxdVqVJFGzdutG+z2WzauHGjfVrlo7i5uSl//vy6e/euVq1apdatW8fZ5/PPP1euXLnUokWLeM9x4MCBR44mpjRKVgqoWLGiihQpojp16mjXrl1atGgR0wMBAEC60K5dO1mtVs2ZM0eSVLBgQU2bNk2zZ8/W6NGjdeTIEZ04cUKzZs3S8OHDNWTIENWoUUOSVKNGDfu24cOHa/v27Tpz5ow2btyodu3aafHixfG+ZseOHZUnTx61adNGW7du1cmTJ7Vq1Sr7IguNGjXSH3/8oSVLlujYsWMaO3asDhw4kOivqVOnTpo7d65+/PFHde7c2b49S5YsGjp0qAYPHqzFixfrxIkT2r17tz788MMEs0r3rj3avn17rGuNihcvrh9//FHbtm3T4cOH9dZbb8UZCYpP3759dePGDXXs2FG7du3SiRMn9P3336t79+6KiYlR1qxZlT17dn322Wc6fvy4Nm3aJH9//8eeN1u2bHFK28MfmTIlPNrq7++vefPmafHixTp8+LDefvtthYWFqXv37vZ9unTpEmtxjJ07d2r16tU6efKkNm/erGbNmslms2n48OGxzm2z2fT555+ra9euCWbYvHmznn/++cd+nSnGoWsVpgEpsYT7li1bjLZt28ZaJvLKlStJWiIVAACkT49aTjq1i29pdMMwjMDAQCNnzpzG7du37dv+7//+z6hbt66ROXNmw83NzahSpYqxcOHCeM+7fPlyo169ekaWLFmMzJkzG+XLlzfee++9Ry7hfvr0aaNt27aGl5eX4eHhYVStWtXYuXOn/fkxY8YYuXPnNry9vY3Bgwcb/fr1i7OE+8CBA+M996FDhwxJRqFCheL8/maz2YzZs2cbzzzzjOHs7GzkzJnTaNq0qfHrr78mmDU6OtrIly+fsWHDBvu269evG61btzY8PT2NXLlyGQEBAUaXLl1ivb8JZfz777+Nl156yfDx8THc3d2NkiVLGoMGDbJn/fHHH41SpUoZrq6uRvny5Y1ffvnFkGR88803CWZ0hA8//NAoWLCg4eLiYlSvXt2+pP6DX0/Xrl3tj3/55Rd7zuzZsxuvv/66ceHChTjn/f777w1JxtGj8f/+vm3bNsPHx8cIDw+P93kzlnC3GMYTXnGYRoWEhMjb21srtx9V22dLOPTcp0+f1jvvvKMVK1ZIujfXNr7lSwEAQMYVERGhU6dOqXDhwnEWQ0D6NWfOHK1du1bff2/OUv3pWYcOHVShQgWNGjUq3ucf9TN3vxsEBwfLy8vLYZnSxhWWqVxISIgCAwMVFBRkX8r0jTfesC/9CQAAgIztrbfe0q1btxQaGqosWbKYHSfdiIqKUrly5TR48GCzo8RCyXoKhmFowYIFCggIsM+hbdy4sWbNmqXy5cubnA4AAACpRaZMmTR69GizY6Q7Li4uCggIMDtGHJSsp2CxWLRmzRpduXJFxYsX18yZM9WyZcs4d6AGAAAAkHFQspLo2LFj8vb2Vq5cuSRJM2bMUJMmTdSnTx+5uLiYnA4AAACA2VjCPZFu3rwpf39/lSlTJtZQb8mSJTVo0CAKFgAASJIMtvYYYBozftYYyXqM6Ohoffrppxo3bpyuX78uSbp8+bJiYmJktVpNTgcAANKa+ze2DQ8Pl7u7u8lpgPQvKipKklL0d3dK1iN89913GjJkiA4fPizp3l2+Z82apaZNm5qcDAAApFVWq1U+Pj76559/JEkeHh5czw0kE5vNpqtXr8rDw+ORN1N2NEpWAubOnau3335bkpQ9e3ZNmDBBvXr1StH/OAAAIH3KkyePJNmLFoDk4+TkpIIFC6boHzNoDAno0KGD3nvvPXXq1EkBAQHy8fExOxIAAEgnLBaL8ubNq1y5cik6OtrsOEC65uLiIienlF2KgpKle/M058yZo82bN2vVqlWyWCzKmjWrjh8/Lg8PD7PjAQCAdMpqtXKNN5AOpYrVBefMmSM/Pz+5ubmpRo0a+v333x+5/9dff62SJUvKzc1N5cqV0/r165/odQ3D0P/93/+pbNmy8vf31zfffKMffvjB/jwFCwAAAEBSmV6yli9fLn9/f40dO1a7d+9WhQoV1LRp0wTnKG/btk0dO3ZUz549tWfPHrVp00Zt2rTRgQMHkvS6p48dVpMmTdSmTRsdO3ZMuXPn1vz589WkSRNHfFkAAAAAMiiLYfJNGmrUqKFq1arpo48+knRvBRBfX1/1799fI0aMiLN/hw4dFBYWpv/+97/2bc8++6wqVqyouXPnPvb1QkJC5O3tbX/s6uoqf39/jRw5UlmyZHHAVwQAAAAgLbjfDYKDg+Xl5eWw85p6TVZUVJT+/PNPjRw50r7NyclJTZo00fbt2+M9Zvv27fL394+1rWnTplqzZk28+0dGRioyMtL+ODg42P75yy+/rHHjxqlQoUIyDEMhISFP8dUAAAAASEvu//7v6HEnU0vWtWvXFBMTo9y5c8fanjt3bh05ciTeYy5fvhzv/pcvX453/8DAQI0fPz7e51avXq3Vq1c/QXIAAAAA6cX169djzXZ7Wul+dcGRI0fGGvm6deuWChUqpLNnzzr0jQQeFhISIl9fX507d86hw8/Aw/heQ0rhew0phe81pJTg4GAVLFhQ2bJlc+h5TS1ZOXLkkNVq1ZUrV2Jtv3Lliv0mfQ/LkydPkvZ3dXWVq6trnO3e3t780CJFeHl58b2GFMH3GlIK32tIKXyvIaU4+j5apq4u6OLioipVqmjjxo32bTabTRs3blTNmjXjPaZmzZqx9pekH3/8McH9AQAAACAlmT5d0N/fX127dlXVqlVVvXp1zZ49W2FhYerevbskqUuXLsqfP78CAwMlSQMHDlT9+vU1c+ZMtWjRQl999ZX++OMPffbZZ2Z+GQAAAAAgKRWUrA4dOujq1asaM2aMLl++rIoVK2rDhg32xS3Onj0ba/iuVq1aWrZsmQICAjRq1CgVL15ca9asUdmyZRP1eq6urho7dmy8UwgBR+J7DSmF7zWkFL7XkFL4XkNKSa7vNdPvkwUAAAAA6Ymp12QBAAAAQHpDyQIAAAAAB6JkAQAAAIADUbIAAAAAwIHSZcmaM2eO/Pz85Obmpho1avx/e/ceFXP6xwH83ZSpZEJLasglFIdcIjaX46eNsi651tJJyGVVsqxLx61i5bJkcdxvWdsqOS4dpQitil2ksGSSCrvCwa5rbZd5fn/sMWdHF6YdtZP365z5Y555nu/3/Z397PA5z8wXLly4UOn86OhotGvXDkZGRrCzs0NcXFw1JSVdp0mt7dixA3379kXDhg3RsGFDODs7v7M2id7Q9HPtjcjISOjp6WH48OEfNiDVGprW2p9//gk/Pz9YWlrC0NAQNjY2/HOU3oumtfbdd9/B1tYWxsbGsLKywqxZs1BYWFhNaUlXnT17FkOHDoVcLoeenh6OHDnyzjVJSUmwt7eHoaEh2rRpg/DwcI3PW+uarKioKMyePRtBQUG4fPkyOnfuDBcXFzx69Kjc+efOncPYsWPh4+OD9PR0DB8+HMOHD8evv/5azclJ12haa0lJSRg7dizOnDmD8+fPw8rKCgMHDsTvv/9ezclJ12haa2/k5eVhzpw56Nu3bzUlJV2naa0VFRVhwIAByMvLw8GDB6FQKLBjxw40bdq0mpOTrtG01n788UcEBgYiKCgImZmZ2LVrF6KiorBgwYJqTk665tWrV+jcuTM2bdr0XvNzc3MxePBg9O/fHxkZGfjqq68wefJkJCQkaHZiUcv06NFD+Pn5qZ6XlpYKuVwuVqxYUe58d3d3MXjwYLWxnj17imnTpn3QnKT7NK21t5WUlAiZTCb27t37oSJSLVGVWispKRG9evUSO3fuFN7e3sLNza0akpKu07TWtmzZIqytrUVRUVF1RaRaQtNa8/PzE05OTmpjs2fPFr179/6gOal2ASAOHz5c6Zx58+aJDh06qI15eHgIFxcXjc5Vq3ayioqKkJaWBmdnZ9WYRCKBs7Mzzp8/X+6a8+fPq80HABcXlwrnEwFVq7W3vX79GsXFxTAzM/tQMakWqGqtLV26FObm5vDx8amOmFQLVKXWYmJi4OjoCD8/PzRp0gQdO3ZEaGgoSktLqys26aCq1FqvXr2Qlpam+kphTk4O4uLi8Pnnn1dLZvp4aKs3MNBmqJr2+PFjlJaWokmTJmrjTZo0wc2bN8td8+DBg3LnP3jw4IPlJN1XlVp72/z58yGXy8v8j0z0T1WptZSUFOzatQsZGRnVkJBqi6rUWk5ODk6fPg1PT0/ExcUhOzsbvr6+KC4uRlBQUHXEJh1UlVobN24cHj9+jD59+kAIgZKSEnz55Zf8uiBpXUW9wfPnz1FQUABjY+P3Ok6t2ski0hUrV65EZGQkDh8+DCMjo5qOQ7XIixcv4OXlhR07dqBRo0Y1HYdqOaVSCXNzc2zfvh3dunWDh4cHFi5ciK1bt9Z0NKplkpKSEBoais2bN+Py5cs4dOgQYmNjsWzZspqORlSuWrWT1ahRI+jr6+Phw4dq4w8fPoSFhUW5aywsLDSaTwRUrdbeWLNmDVauXInExER06tTpQ8akWkDTWrt9+zby8vIwdOhQ1ZhSqQQAGBgYQKFQoHXr1h82NOmkqnyuWVpaok6dOtDX11eNtW/fHg8ePEBRURGkUukHzUy6qSq1tnjxYnh5eWHy5MkAADs7O7x69QpTp07FwoULIZFw34C0o6LewNTU9L13sYBatpMllUrRrVs3nDp1SjWmVCpx6tQpODo6lrvG0dFRbT4AnDx5ssL5REDVag0AVq9ejWXLliE+Ph7du3evjqik4zSttXbt2uHatWvIyMhQPYYNG6a6S5KVlVV1xicdUpXPtd69eyM7O1vVyANAVlYWLC0t2WBRhapSa69fvy7TSL1p7v++nwGRdmitN9Dsnhz/fZGRkcLQ0FCEh4eLGzduiKlTp4oGDRqIBw8eCCGE8PLyEoGBgar5qampwsDAQKxZs0ZkZmaKoKAgUadOHXHt2rWaugTSEZrW2sqVK4VUKhUHDx4U+fn5qseLFy9q6hJIR2haa2/j3QXpfWlaa3fv3hUymUz4+/sLhUIhjh07JszNzcU333xTU5dAOkLTWgsKChIymUzs379f5OTkiBMnTojWrVsLd3f3mroE0hEvXrwQ6enpIj09XQAQYWFhIj09Xdy5c0cIIURgYKDw8vJSzc/JyRF169YVc+fOFZmZmWLTpk1CX19fxMfHa3TeWtdkCSHExo0bRfPmzYVUKhU9evQQP//8s+q1fv36CW9vb7X5Bw4cEDY2NkIqlYoOHTqI2NjYak5MukqTWmvRooUAUOYRFBRU/cFJ52j6ufZPbLJIE5rW2rlz50TPnj2FoaGhsLa2FsuXLxclJSXVnJp0kSa1VlxcLIKDg0Xr1q2FkZGRsLKyEr6+vuKPP/6o/uCkU86cOVPu37/e1Je3t7fo169fmTVdunQRUqlUWFtbiz179mh8Xj0huMdKRERERESkLbXqN1lEREREREQ1jU0WERERERGRFrHJIiIiIiIi0iI2WURERERERFrEJouIiIiIiEiL2GQRERERERFpEZssIiIiIiIiLWKTRUREREREpEVssoiIqErCw8PRoEGDmo5RZXp6ejhy5EilcyZMmIDhw4dXSx4iIqo92GQREX3EJkyYAD09vTKP7Ozsmo6G8PBwVR6JRIJmzZph4sSJePTokVaOn5+fj0GDBgEA8vLyoKenh4yMDLU569evR3h4uFbOV5Hg4GDVderr68PKygpTp07F06dPNToOG0Iiov8Og5oOQERENcvV1RV79uxRG2vcuHENpVFnamoKhUIBpVKJK1euYOLEibh//z4SEhL+9bEtLCzeOad+/fr/+jzvo0OHDkhMTERpaSkyMzMxadIkPHv2DFFRUdVyfiIi0i7uZBERfeQMDQ1hYWGh9tDX10dYWBjs7OxgYmICKysr+Pr64uXLlxUe58qVK+jfvz9kMhlMTU3RrVs3XLp0SfV6SkoK+vbtC2NjY1hZWSEgIACvXr2qNJuenh4sLCwgl8sxaNAgBAQEIDExEQUFBVAqlVi6dCmaNWsGQ0NDdOnSBfHx8aq1RUVF8Pf3h6WlJYyMjNCiRQusWLFC7dhvvi7YqlUrAEDXrl2hp6eH//3vfwDUd4e2b98OuVwOpVKpltHNzQ2TJk1SPT969Cjs7e1hZGQEa2trhISEoKSkpNLrNDAwgIWFBZo2bQpnZ2eMGTMGJ0+eVL1eWloKHx8ftGrVCsbGxrC1tcX69etVrwcHB2Pv3r04evSoalcsKSkJAHDv3j24u7ujQYMGMDMzg5ubG/Ly8irNQ0RE/w6bLCIiKpdEIsGGDRtw/fp17N27F6dPn8a8efMqnO/p6YlmzZrh4sWLSEtLQ2BgIOrUqQMAuH37NlxdXTFq1ChcvXoVUVFRSElJgb+/v0aZjI2NoVQqUVJSgvXr12Pt2rVYs2YNrl69ChcXFwwbNgy3bt0CAGzYsAExMTE4cOAAFAoFIiIi0LJly3KPe+HCBQBAYmIi8vPzcejQoTJzxowZgydPnuDMmTOqsadPnyI+Ph6enp4AgOTkZIwfPx4zZ87EjRs3sG3bNoSHh2P58uXvfY15eXlISEiAVCpVjSmVSjRr1gzR0dG4ceMGlixZggULFuDAgQMAgDlz5sDd3R2urq7Iz89Hfn4+evXqheLiYri4uEAmkyE5ORmpqamoV68eXF1dUVRU9N6ZiIhIQ4KIiD5a3t7eQl9fX5iYmKgeo0ePLndudHS0+OSTT1TP9+zZI+rXr696LpPJRHh4eLlrfXx8xNSpU9XGkpOThUQiEQUFBeWuefv4WVlZwsbGRnTv3l0IIYRcLhfLly9XW+Pg4CB8fX2FEELMmDFDODk5CaVSWe7xAYjDhw8LIYTIzc0VAER6erraHG9vb+Hm5qZ67ubmJiZNmqR6vm3bNiGXy0VpaakQQojPPvtMhIaGqh1j3759wtLSstwMQggRFBQkJBKJMDExEUZGRgKAACDCwsIqXCOEEH5+fmLUqFEVZn1zbltbW7X34K+//hLGxsYiISGh0uMTEVHV8TdZREQfuf79+2PLli2q5yYmJgD+3tVZsWIFbt68iefPn6OkpASFhYV4/fo16tatW+Y4s2fPxuTJk7Fv3z7VV95at24N4O+vEl69ehURERGq+UIIKJVK5Obmon379uVme/bsGerVqwelUonCwkL06dMHO3fuxPPnz3H//n307t1bbX7v3r1x5coVAH9/1W/AgAGwtbWFq6srhgwZgoEDB/6r98rT0xNTpkzB5s2bYWhoiIiICHzxxReQSCSq60xNTVXbuSotLa30fQMAW1tbxMTEoLCwED/88AMyMjIwY8YMtTmbNm3C7t27cffuXRQUFKCoqAhdunSpNO+VK1eQnZ0NmUymNl5YWIjbt29X4R0gIqL3wSaLiOgjZ2JigjZt2qiN5eXlYciQIZg+fTqWL18OMzMzpKSkwMfHB0VFReU2C8HBwRg3bhxiY2Nx/PhxBAUFITIyEiNGjMDLly8xbdo0BAQElFnXvHnzCrPJZDJcvnwZEokElpaWMDY2BgA8f/78nddlb2+P3NxcHD9+HImJiXB3d4ezszMOHjz4zrUVGTp0KIQQiI2NhYODA5KTk7Fu3TrV6y9fvkRISAhGjhxZZq2RkVGFx5VKpar/BitXrsTgwYMREhKCZcuWAQAiIyMxZ84crF27Fo6OjpDJZPj222/xyy+/VJr35cuX6Natm1pz+8Z/5eYmRES1EZssIiIqIy0tDUqlEmvXrlXt0rz5/U9lbGxsYGNjg1mzZmHs2LHYs2cPRowYAXt7e9y4caNMM/cuEomk3DWmpqaQy+VITU1Fv379VOOpqano0aOH2jwPDw94eHhg9OjRcHV1xdOnT2FmZqZ2vDe/fyotLa00j5GREUaOHImIiAhkZ2fD1tYW9vb2qtft7e2hUCg0vs63LVq0CE5OTpg+fbrqOnv16gVfX1/VnLd3oqRSaZn89vb2iIqKgrm5OUxNTf9VJiIien+88QUREZXRpk0bFBcXY+PGjcjJycG+ffuwdevWCucXFBTA398fSUlJuHPnDlJTU3Hx4kXV1wDnz5+Pc+fOwd/fHxkZGbh16xaOHj2q8Y0v/mnu3LlYtWoVoqKioFAoEBgYiIyMDMycORMAEBYWhv379+PmzZvIyspCdHQ0LCwsyv0HlM3NzWFsbIz4+Hg8fPgQz549q/C8np6eiI2Nxe7du1U3vHhjyZIl+P777xESEoLr168jMzMTkZGRWLRokUbX5ujoiE6dOiE0NBQA0LZtW1y6dAkJCQnIysrC4sWLcfHiRbU1LVu2xNWrV6FQKPD48WMUFxfD09MTjRo1gpubG5KTk5Gbm4ukpCQEBATgt99+0ygTERG9PzZZRERURufOnREWFoZVq1ahY8eOiIiIULv9+dv09fXx5MkTjB8/HjY2NnB3d8egQYMQEhICAOjUqRN++uknZGVloW/fvujatSuWLFkCuVxe5YwBAQGYPXs2vv76a9jZ2SE+Ph4xMTFo27YtgL+/arh69Wp0794dDg4OyMvLQ1xcnGpn7p8MDAywYcMGbNu2DXK5HG5ubhWe18nJCWZmZlAoFBg3bpzaay4uLjh27BhOnDgBBwcHfPrpp1i3bh1atGih8fXNmjULO3fuxL179zBt2jSMHDkSHh4e6NmzJ548eaK2qwUAU6ZMga2tLbp3747GjRsjNTUVdevWxdmzZ9G8eXOMHDkS7du3h4+PDwoLC7mzRUT0AekJIURNhyAiIiIiIqotuJNFRERERESkRWyyiIiIiIiItIhNFhERERERkRaxySIiIiIiItIiNllERERERERaxCaLiIiIiIhIi9hkERERERERaRGbLCIiIiIiIi1ik0VERERERKRFbLKIiIiIiIi0iE0WERERERGRFv0fMvLuurMkFmIAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix, roc_curve, roc_auc_score\n",
    "\n",
    "\n",
    "print(\"accuracy Score: \", accuracy_score(y_test, y_pred))\n",
    "print(\"f1 Score: \", f1_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc_score(y_test, y_pred_proba))\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d37b2c",
   "metadata": {},
   "source": [
    "### Confusion Matrix Interpretation\n",
    "From the confusion matrix:\n",
    "\n",
    "- True Negatives (TN): 56,855 (Class 0 correctly predicted)\n",
    "\n",
    "- False Positives (FP): 9 (Class 0 incorrectly predicted as fraud)\n",
    "\n",
    "- False Negatives (FN): 19 (Fraud missed)\n",
    "\n",
    "- True Positives (TP): 79 (Fraud correctly detected)\n",
    "\n",
    "#### Key Observations:\n",
    "- Accuracy is extremely high but this is expected due to the large class imbalance.\n",
    "\n",
    "- Recall (Sensitivity) for fraud cases:\n",
    "    Recall = TP/(TP+FN) = 79/(79+19) = 0.81\n",
    "\n",
    "    Meaning the model identifies ~81% of actual fraud cases.\n",
    "\n",
    "- Precision for fraud cases:\n",
    "    Precision = TP/(TP+FP) = 79/(79+9) = 0.90\n",
    "\n",
    "    The model has strong precision, minimizing false alarms for fraud.\n",
    "\n",
    "Very low number of false positives and false negatives means the model is both accurate and effective in flagging fraud, with minimal impact on genuine transactions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806ae243",
   "metadata": {},
   "source": [
    "### ROC AUC Plot Interpretation\n",
    "- AUC (Area Under Curve): 0.97. This is an excellent result—your model is able to distinguish between fraud and non-fraud transactions very well.\n",
    " \n",
    "- ROC curve sits well above the diagonal, showing high separability.\n",
    "\n",
    "- This metric is especially important for imbalanced data: a high AUC confirms the model's robustness, not just its accuracy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7caafe46",
   "metadata": {},
   "source": [
    "After thorough feature engineering, class imbalance handling, and hyperparameter tuning, Random Forest emerged as the best-performing model for fraud detection.\n",
    "\n",
    "The confusion matrix shows extremely high accuracy in identifying non-fraudulent transactions, with only 19 missed fraudulent cases (false negatives) and 79 correctly identified (true positives). Importantly, only 9 legitimate transactions were incorrectly flagged as fraud (false positives), indicating strong precision.\n",
    "\n",
    "The model's ROC curve yields an outstanding AUC score of 0.97, demonstrating excellent capability in distinguishing fraudulent activity from normal behavior, even in the presence of severe class imbalance.\n",
    "\n",
    "These metrics validate that the system is both reliable and suitable for real-world deployment: it minimizes risk to genuine users while detecting the vast majority of true fraud cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd27093",
   "metadata": {},
   "source": [
    "### Feature Importance Analysis and Explainability for Random Forest\n",
    "\n",
    "Feature Importance and Explainability:\n",
    "Using the Random Forest model’s native feature importances gives a quick view of the key predictors. However, to understand nuanced interactions and individual predictions, SHAP analysis was employed. SHAP summary plots reveal the top features driving fraud detections, correlate feature values with impact, and show how time-based features (Hour_sin, Hour_cos), scaled Amount, and select PCA components contribute to model decisions. Local explanation plots provide actionable insights at the individual transaction level, crucial for trust and operational use in fraud analytics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ca0d7c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "feature_names = numeric_features + pcs_features + cyclic_features\n",
    "\n",
    "# Extract feature importances\n",
    "importances = model.feature_importances_\n",
    "\n",
    "# Crate a Dataframe for better visualization\n",
    "feat_importances = pd.Series(importances, index = feature_names)\n",
    "\n",
    "# Sort and plot top 15 features\n",
    "top_features = feat_importances.sort_values(ascending= False).head(15)\n",
    "\n",
    "# Visualize top 15 features\n",
    "plt.figure(figsize=(10,6))\n",
    "top_features.plot(kind='barh')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.title(\"Top 15 Feature Importances from Randon Forest Classifier\")\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726a21a9",
   "metadata": {},
   "source": [
    "### Interpretation of Feature Importances\n",
    "\n",
    "#### What the Chart Shows\n",
    "\n",
    "- Top 15 Features: The plot displays the 15 most impactful variables according to Random Forest classifier.\n",
    "\n",
    "- Horizontal Bars: The length of each bar depicts the relative importance of each feature in deciding whether a transaction is fraud or not.\n",
    "\n",
    "#### Key Insights\n",
    "\n",
    "- Dominant Features\n",
    "\n",
    "    - V14, V4, and V12 are the most influential features, with V14 contributing the most to model decisions.\n",
    "\n",
    "    - These principal components (from PCA) capture statistical patterns in the data and seem highly predictive for fraud.\n",
    "\n",
    "#### Temporal Feature Impact\n",
    "\n",
    "- Features like V8, V27, V19, and others, but if time-based engineered features (Hour_sin, Hour_cos, etc.) didn’t make it to the top 15, this suggests the PCA features remain stronger predictors.\n",
    "\n",
    "#### Why PCA Features Dominate\n",
    "\n",
    "- The original dataset’s anonymized PCA components contain condensed fraud patterns identified by domain experts.\n",
    "\n",
    "- Time and Amount features might still add value, but for this dataset, the PCA-derived features are the \"heavy lifters.\"\n",
    "\n",
    "#### Implications for Modeling & Business Use\n",
    "\n",
    "- Explainability: Knowing which features drive fraud predictions helps analysts focus their investigations and understand model reasoning.\n",
    "\n",
    "- Further Analysis: For reporting, highlight that while the new time features can boost detection in some contexts, the anonymized statistical patterns (PCA features) are most influential in this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6d87a4",
   "metadata": {},
   "source": [
    "The Random Forest model’s feature importance plot reveals that the principal components V14, V4, and V12 are most critical for the detection of fraudulent transactions in this dataset. These top-ranked features significantly outweigh others, indicating that statistical patterns captured through PCA are highly predictive. This aligns with research using this dataset, where certain components consistently correlate with fraud. While engineered time and amount features were included, the PCA features contributed the most signal for our model. These insights provide clarity for model deployment, focusing investigator efforts on transactions with pronounced anomalies in these key components."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3017e3dd",
   "metadata": {},
   "source": [
    "### Let us save the model as a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5ce182e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessor and model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "# Ensure the directory exists\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "# Save the preprocessor\n",
    "with open('models/preprocessor.pkl', 'wb') as f:\n",
    "    pickle.dump(preprocessor, f)\n",
    "\n",
    "# Save the trained model\n",
    "with open('models/model.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "print(\"Preprocessor and model saved successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
